[Person4]: Künstliche Intelligenz, KI: für die einen die wichtigste techno- logische Erfindung der Menschheit. Für die anderen eine reale Gefahr, die Kontrolle über die Maschinen zu verlieren. KI und wir - was bringt es uns, was nicht? Über das müssen wir reden.

[Person2]: Mit Live-Untertiteln von SWISS TXT Heute in der "Arena": Pascal Kaufmann, KI-Unternehmer und Neurowissenschaftler. Er sagt: "Künstliche Intelligenz bietet enorme Chancen." "Die Schweiz ist weltweit führend in der Forschung." "Das müssen wir nutzen." "Dabei hilft eine liberale Gesetzgebung." Peter G. Kirchschläger, Ethiker Universität Luzern und ETH Zürich, sagt: "Weil künstliche Intelligenz auch mit Risiken verbunden ist, muss sie reguliert werden." "Die Einhaltung der Menschenrechte ist zentral, um das Vertrauen in die Technologie zu stärken." Monika Rühl, Direktorin economiesuisse, sagt: "KI ist eine Riesenchance für Gesellschaft und Wirtschaft." "Wenn wir diese mutig nutzen, profitiert auch die Arbeitswelt." "Die Schweiz ist dafür in einer exzellenten Ausgangsposition." Mirjam Hostetmann, Präsidentin Juso, sagt: "Wir dürfen die Entwicklung von KI-Technologien nicht privaten, profitorientierten Techfirmen überlassen." "Diese Firmen müssen verstaatlicht und zu voller Transparenz verpflichtet werden." Ausserdem im Studio: Marcel Salathé, Co-Direktor KI-Zentrum EPFL Lausanne und Epidemiologe. Die "Arena" - moderiert von Sandro Brotz.

[Person4]: Guten Abend, herzlich willkommen, liebe Zuschauer/-innen. Vielen Dank. Herzlich willkommen zu Hause, in dieser Runde und im Publikum. Wir haben u.a. junge Menschen von der Fachmittelschule Muttenz, vom Bildungszentrum für Wirtschaft in Weinfelden und von den Kantis Frauenfeld und Zürich Oberland. Ist Ihnen am Anfang dieser Sendung etwas aufgefallen? Da hat doch irgendetwas nicht gestimmt mit dem seltsamen Moderator. Schauen wir uns doch noch einmal kurz den Ausschnitt an. KI und wir - was bringt das uns, was nicht? Darüber müssen wir reden. Der Anfang dieser "Arena" war KI-generiert, also von künstlicher Intelligenz. Erstellt wurde der Ausschnitt mit einem einzigen Bild aus dem Internet und meiner Stimme, die man natürlich in früheren Sendungen findet. All das kann man mit einem einfachen Programm per Knopfdruck machen. Irgendetwas hat nicht gestimmt, ich trage keinen Ring. Vermutlich denkt die KI, dass jemand, der einen Anzug trägt, automatisch auch einen Ring tragen muss. Ich weiss es nicht. Eine diese Woche veröffentlichte Untersuchung der Universität Zürich zeigt, dass 54 % der Befragten KI nutzen, obwohl es Tools wie ChatGPT erst seit zwei Jahren gibt. Weil wir junge Menschen hier haben, möchte ich einmal nachfragen. Gehört ChatGPT bei Ihnen bereits zum Alltag?

[Person1]: Ja, v.a. in der Schule. Ich benutze es häufig für Hausaufgaben oder auch zum Lernen vor einer Prüfung. Damit fülle ich Lücken auf.

[Person12]: Wie ist es bei Ihnen? Ich benutze es tagtäglich, v.a. in der Vorbereitung auf Prüfungen. Wenn man viel Stoff lernen muss, kann man ihn mit diesen Tools zusammenfassen. Da muss ich Sie also nicht fragen, ob KI eher eine Chance oder ein Risiko ist? Für mich ist es definitiv eine Chance.

[Person4]: Für mich auch. Zwei junge Stimmen. Wir werden heute noch viele hören. Dankeschön. Wir sind bereits bei der Ausgangslage der heutigen Sendung. Die "Arena" anlässlich der SRF-Themenwoche KI. Heute diskutieren wir in einer gemischten Runde mit Vertreter/-innen der Politik, Wirtschaft, Ethik und Forschung. Monika Rühl, Direktorin des Wirtschafts- dachverbands economiesuisse: Was lösen die beiden Buchstaben K und I bei Ihnen persönlich aus?

[Person8]: Begeisterung. Ich finde KI eine ganz tolle Sache. Ich bin nicht mehr ganz 20, aber wir haben damit eine riesige Herausforderung und gleichzeitig eine riesige Chance. Wir betreten eine neue Welt und haben die Chance, all das zu erleben. Die Schweiz ist extrem gut aufgestellt, wir haben alle Voraussetzungen, diese Reise gemeinsam zu unternehmen. Und das zu unser aller Gewinn, der Gesellschaft und Wirtschaft. Ich bin begeistert.

[Person4]: Peter G. Kirchschläger, Ethikprofessor, u.a. Leiter des Instituts für Sozialethik an der Universität Luzern. Die grosse Frage gleich zum Anfang: Ist KI ein Segen oder ein Fluch? Gehen Sie mit auf die von Frau Rühl beschriebene Reise?

[Person3]: Z.T. schon, es gibt durchaus ein ethisch positives Potenzial der sog. KI. Gleichzeitig müssen wir auch ethisch negative Risiken betrachten. Wir können so wie bisher nicht weitermachen. Beides muss sehr präzise identifiziert werden, um die ethischen Chancen zu fördern und die ethischen Risiken zu minimieren oder auch wirklich zu vermeiden. Ich gebe Ihnen ein Beispiel: Heute kann man eine Kinderbilder sexualisierende App auf den Markt bringen, so etwas Widerliches, und das als legal eingetragenes Unternehmen. Das einzige was passiert, ist, dass ich damit unglaublich viel Geld verdiene. Hier gibt es Handlungsbedarf.

[Person4]: Sie beschreiben ein Spannungsfeld, und das geht dann wieder in Richtung der Regulierung. Das wird ein wichtiges Thema in dieser Sendung. Ich begrüsse ebenfalls Pascal Kaufmann, KI-Unternehmer und Neurowissenschaftler. Geben Sie uns eine Vorstellung Ihres Unternehmens: Woran arbeiten Sie in Ihrem Unternehmen gerade ganz konkret im Zusammenhang mit der viel zitierten KI?

[Person10]: Wir bauen an SwissGPT. Wir finden es nicht so gut, wenn alle auf ChatGPT setzen. In der Schweiz verfügen wir über das Know-how und ziehen Talente aus der ganzen Welt an. Das Beste Know-how aus den USA und aus China können wir hier kombinieren. Mit unseren Produkten und Technologien können wir eine Führungsposition in der Welt übernehmen.

[Person10]: Was verändert sich für mich, wenn ich SwissGPT statt ChatGPT nutze? Z.B. ist SwissGPT legal. Wenn Sie z.B. in einem Spital arbeiten und Medizinalakten durch ChatGPT schicken würden, wäre das nicht so gut. Das gilt ebenfalls für Behörden oder andere hochregulierte Umgebungen.

[Person4]: Dort sollten Sie ChatGPT nicht verwenden. Mirjam Hostetmann, Präsidentin der JUSO - Sehen Sie neben all den Risiken, die es so gibt, auch Chancen?

[Person6]: Absolut, ich sehe sehr viele Chancen. KI kann uns helfen, unser Zusammenleben besser zu organisieren. Ich sehe eine Chance bei der Unterstützung von Menschen.

[Person4]: Unterstützung von Menschen - und Sie möchten Geld damit machen? Wir möchten Geld damit machen, indem wir etwas bauen, was der Kunde möchte.

[Person10]: Es ist ein gutes Zeichen, wenn Kunden bereit sind, Geld dafür zu bezahlen. Dann baut man etwas, was der Markt braucht.

[Person6]: Das sehe ich anders. Es ist ein riesiges Problem, dass alles darauf ausgerichtet ist, mit KI Profit zu machen. Das sind v.a. die fünf grossen Big-Tech-Firmen, die mit KI maximalen Profit scheffeln, während wir keine Ahnung haben, was mit unseren Daten passiert, an wen sie weitergegeben werden. Das ist ein grosses Risiko für uns und unsere Demokratie. Das kann ganze politische Systeme destabilisieren. Das ist ein grosses Risiko.

[Person4]: Kurz die Replik, bevor wir einen Schritt weitergehen.

[Person10]: Das Monopol ist deswegen problematisch, weil wir offenbar in Europa so schlechte Software entwickeln, dass alle doch wieder auf WhatsApp oder ChatGPT zurückgreifen. Die Ursache eines Monopols ist eigentlich, dass es nicht so viele andere Konkurrenzprodukte gibt. Dabei hätten wir ausreichend Kompetenz, solche Tools auch in Europa zu bauen.

[Person3]: Dann gäbe es auch diese Monopole nicht mehr. Der Staat könnte dabei schon eine Rolle spielen. Wenn auffällt, dass es in einem Markt ein Monopol gibt - und bei den Suchmaschinen hatten sie 25-30 Jahre Zeit, das zu merken -, könnte man schon einmal intervenieren. Das ist nicht einmal nur eine ethische, sondern auch eine ökonomische Überlegung. Alle, nicht nur die Konsument/-innen und Nutzer/-innen, sondern auch die Unternehmen, sollten sich eigentlich nicht ausbeuten lassen müssen von diesen fünf bis neun multi- nationalen Technologiekonzernen.

[Person8]: Ein freier Markt funktioniert allerdings gerade ohne oder mit möglichst geringer staatliche Intervention. Der Staat ist nicht zwingend ein guter wirtschaftlicher Akteur. Welches Know-how hat der Staat? Das Know-how liegt bei den Unternehmen, bei denen fünf grossen und bei vielen anderen. Es ist nicht so, dass nur diese vier oder fünf grossen Techfirmen dieses Know-how haben. Das haben auch viele weitere Akteure, u.a. in der Wissenschaft. Mich stört Verteufelung der wirtschaftlichen Kräfte, die hier spielen, denn es besteht eine ganz klare Nachfrage und eine Nachfrage generiert ein Angebot.

[Person3]: Das sind die Kräfte des Marktes. Das ist keine Verteufelung der Wirtschaft, im Gegenteil. Eigentlich müssen wir uns um unseren Markt kümmern. Es kann in einem Markt zu Monopolbildungen kommen. Etwas wie das Suchmaschinenmonopol wird sich nicht von alleine auflösen. Wenn wir das träumen, wird es ein Albtraum. Wir müssen aus dieser Situation wieder herauskommen und zwar im Dienste der wirtschaftlichen Kräfte. Der Markt wird es aber nicht alleine bewerkstelligen, dass wir z.B. aus dem Suchmaschinenmonopols rauskommen. Das ist eine Illusion. Die letzten 25, 30 Jahren haben wir das beobachtet und gemerkt: Es wird nicht funktionieren. Da gibt es Handlungsbedarf, wie auch bei den Biases, mit denen wir zu tun haben. In den Niederlanden beispielsweise verhielt sich eine sog. KI diskriminierend. Menschen, die über Jahre Kinder- betreuungsgelder bezogen haben, mussten diese plötzlich wieder zurückzahlen, nur, weil die KI diskriminierend war. Wir können nicht so tun, als ob es diese Probleme nicht gäbe. Es gibt natürlich insbesondere in der Forschung riesige Chancen. Bei der EPFL, bei der ETH Zürich - fantastisch. Aber wir können nicht so tun, als gäbe es die Probleme nicht.

[Person4]: Das halte ich für unverantwortlich. Es geht ja schon fast mehr ab als in einer regulären "Arena". Herr Kirchschläger erwähnte Bias - wenn es also zu Vorurteilen oder Diskriminierung kommt - darüber werden wir sprechen. Wir werden auch über die Wirtschaftlichkeit reden. Aber er hat soeben den Pass schön an die EPFL weitergegeben. Das ist mein Stichwort. "Die KI ist die wichtigste techno- logische Erfindung der Menschheit." Das sage nicht ich, sondern ein Mann, der bei uns heute Abend eine Expertenrolle einnimmt und sich von der Vis-à-Vis-Position immer mal wieder in die Debatte einschalten wird. Marcel Salathé ist Professor an der EPFL Lausanne und Co-Chef des dortigen neuen KI-Zentrums. Sie kennen ihn wahrscheinlich noch als Epidemiologen und Gesicht aus der Corona-Zeit. Heute ist aber KI das Thema. Ich habe von Ihnen gelesen, dass sie ChatGPT am Tag 40-50-mal benutzen. Wofür?

[Person11]: Ja, mind. so oft und für alle möglichen Zwecke. Um Fragen zu stellen, um mir Wissen zu holen. Ich verbessere Texte damit, mache Analysen und generiere Bilder. Eigentlich nonstop.

[Person4]: Warum sind Sie sicher, dass die Texte dadurch besser werden?

[Person11]: Ich habe das Original ja vor mir. Ich kann ja beurteilen, ob es am Schluss besser ist.

[Person4]: Sie sagen, die künstliche Intelligenz bedeute eine Revolution, die alle Bereiche betreffen wird. Wir schauen das noch vertieft an. Um es zum Anfang aber auf den Punkt zu bringen: Wo wird sich diese Revolution am meisten bemerkbar machen?

[Person11]: Es ist eine ähnliche Revolution wie die Industrielle Revolution. Man baute Maschinen, die in ihrer Kraft der menschlichen Kraft weit überlegen waren. Nun bauen wir Maschinen, die weit über das hinausgehen, was die menschliche Intelligenz kann. Da wir in einer Wissensgesellschaft leben, wird die ganze Gesellschaft davon betroffen sein.

[Person4]: Vielen Dank für den Moment. Bevor wir weiter in die Welt dieser KI-Technologie abtauchen, und uns fragen, was sie für den Menschen bedeutet und wo man vielleicht auch Grenzen setzen muss, schauen wir uns zunächst ein Erklärvideo dazu an, was KI eigentlich bedeutet.

[Person2]: KI - kurz für künstliche Intelligenz - steht für Systeme, die Aufgaben erledigen können, für die sonst menschliche Fähigkeiten nötig wären. Damit eine KI funktioniert, muss sie mit Daten trainiert werden - sog. maschinellen Lernen. Ein KI-System analysiert eine grosse Menge an Daten und findet selbständig Muster. Für das Training und die Anwendung der KI werden oft grosse Rechenzentren benötigt. Schon heute kommt künstliche Intelligenz zum Einsatz. Beispielsweise im Verkehr von San Francisco - mit selbstfahrenden Autos als Taxis. In der Medizin kann KI Ärztinnen und Ärzte dabei unterstützen, Krankheiten zu erkennen, z.B. Krebs. Eine bekannte KI ist ChatGPT. Dieser sog. Chatbot kann in Form einer natürlichen Unterhaltung Fragen beantworten, Informationen suchen, Texte verfassen und bearbeiten oder Bilder generieren. Künstliche Intelligenz wird nebst zivilen Zwecken auch für militärische Absichten eingesetzt: Im Ukrainekrieg sollen z.B. auch KI-Drohnen zum Einsatz kommen. Wie wird die künstliche Intelligenz die Zukunft von uns allen beeinflussen?

[Person4]: Die KI wird natürlich einen grossen Einfluss auf die Arbeitswelt haben. In einer Studie der economiesuisse, einem sog. Whitepaper, heisst es: Wenn ich optimieren höre, Frau Rühl, klingt das durchaus positiv, aber übersetzt heisst das doch: mehr KI, weniger Arbeitsplätze.

[Person8]: Das kann es heissen, muss es aber nicht. Es heisst effizienter werden, die Produktivität steigern, damit man die so freigespielten Arbeitskräfte anderswo einsetzen kann. Für die Arbeitsmarktdiskussion finde ich es wichtig, dass wir sie als Chancendiskussion führen. Es wird immer argumentiert, wenn Unternehmen aus dem Ausland in die Schweiz kommen und Arbeitsplätze schaffen, dass das - oh Hilfe - Zuwanderung mit sich bringt. Und dann sieht man Risiken ohne Ende. Doch wir haben eigentlich Chancen, effizienter zu werden, die Produktivität zu steigern und Arbeitsplätze einzusparen. Auch da heisst es wieder, das seien Risiken. Wir haben aber auch eine andere Studie durchgeführt, laut der uns bis in 10 Jahren für benötigte Arbeitsplätze 460'000 Menschen fehlen. Diese Menschen können wir über KI ersetzen und die Arbeitsplätze in der Schweiz halten. Das ist schliesslich unser Ziel.

[Person4]: Eine Studie, die ich mir diese Woche u.a. angeschaut habe, sagt, das KI bis zu 3,9 Mio. Arbeitsplätze beeinflusst und dass 8 % der heute bestehenden Arbeitsplätze durch generative KI, wie z.B. ChatGPT, ganz oder teilweise wegfallen. Ist das eine gute Entwicklung?

[Person8]: Das sind 8 %. Das bedeutet, wir haben 92 % andere Fälle. Ein grosser Wert der KI, an den ich fest glaube, ist die Zusammenarbeit zwischen der KI und dem Menschen. Auch die Schülerin und der Schüler haben es gesagt: Man fragt ChatGPT nach Informationen, am Schluss muss doch immer der Mensch verifizieren und prüfen, weil ChatGPT momentan noch immer sehr viele Fehler macht. Zur Arbeitsplatzsituation: Ich finde die Synergien zwischen Mensch und Maschine extrem spannend.

[Person4]: Synergien, optimieren, Frau Hostetmann - machen Sie da mit?

[Person6]: Das klingt sehr harmonisch. Ich kann auch verstehen, wo Sie die Chancen sehen, nämlich für die Unternehmen. Für die Angestellten sieht es anders aus. 40'000 Jobs stehen auf dem Spiel. Auch die Digitalisierung wurde als grosse Chance betrachtet. Sie hat auch viel Gutes gebracht. Allerdings führte sie auch dazu, dass es jetzt Firmen wie Uber gibt, die unser Sozialversicherungssystem austricksen, Menschen in die Scheinselbstständigkeit treiben. Das sind die Gefahren, die von Ihnen einfach verdrängt werden. V.a. werden Sie ja dann keine Arbeitszeitverkürzung bei gleich bleibendem Lohn einführen, denn dann würden die Angestellten tatsächlich davon profitieren. Aber das streben Sie in Ihrer Utopie ja nicht an.

[Person10]: Ich finde, künstliche Intelligenz ist super für Arbeitnehmer/-innen. Es ist doch ideal, wenn Roboter oder KI langweilige und repetitive Routinearbeiten übernehmen. Dann gibt es eben 10 % weniger Jobs. Wenn wir dafür aber 20-30 % produktiver sind, ist das ein super Steuersubstrat. Davon können alle profitieren. Und wieso sollte man nicht die Tagesarbeitszeit von 8 Std. auf 6 Std. reduzieren, wenn man dabei noch produktiver wird? Die Produktivitätsgewinne müssen schliesslich irgendwohin. Sie sollten den Arbeitnehmer/-innen weitergegeben werden.

[Person4]: Habe ich das richtig verstanden:

[Person3]: Dank KI müssen wir in Zukunft weniger arbeiten? Das ist doch eine tolle Sache, Herr Kirchschläger? Aus ethischer Sicht wäre das tatsächlich nicht so schlecht. Die Problemlage ist allerdings anders. Das Problem ist, dass wir so tun, als ginge alles so weiter wie bisher, und das nur ein paar bezahlte berufliche Aufgaben wegfallen. In Wirklichkeit wird es aber zu einer massiven Reduktion bezahlter beruflicher Aufgaben kommen, weil das die Zielsetzung ist. Man möchte mit KI ja Menschen am Arbeitsplatz ersetzen, und nicht ihnen die Arbeit erleichtern. Man will sie wegbekommen und es betrifft alle beruflichen Aufgaben. Das verstärkt den Effekt noch. Wenn Arbeitsplätze wegfallen, muss das nicht von Anfang an eine schlechte Nachricht sein, auch nicht aus ethischer Sicht. Schlecht ist, wenn man weiterhin vorgibt, nach Vollbeschäftigung zu streben, dies aber nicht die Wirklichkeit ist. Wir stehen vor einer systemischen Veränderung. Ich höre oft Politiker/-innen und Entscheidungsträger/-innen in Wirtschaft und Gesellschaft, die sagen, man müsse sich einfach nur weiterbilden und sich für die Veränderung fit machen - das geht in meinen Augen so nicht. Man kann nicht ein systemisches Problem auf den Schultern der Individuen ablegen. Man muss es systemisch angehen. Z.B. müsste man das Wirtschaftssystem so anpassen, dass es das Streben nach Vollbeschäftigung nicht mehr gibt.

[Person4]: Da macht wohl Frau Rühl nicht mit.

[Person8]: Teils, teils. Das Ziel ist sicher nicht, Arbeitsplätze zu vernichten. Das wäre völlig falsch. In den nächsten zehn Jahren sind wir damit konfrontiert, dass wir 460'000 Arbeitsplätze nicht werden besetzen können.

[Person3]: Das ist ja auch zyklisch bedingt. Das kann sich auch wieder verändern. Ich finde das ein schwieriges Argument. Bei einem automatisierten Kassensystem frage ich mich schon, wo da der Job entsteht.

[Person8]: Lassen Sie Frau Rühl bitte ausreden. Schauen Sie sich die Demographie an. Wir werden immer älter, immer mehr Ältere verlassen den Arbeitsmarkt, immer weniger Jüngere kommen auf den Arbeitsmarkt. Das wird über längere Zeit so bleiben, daran kann man kurzfristig nichts ändern. Die Ansprüche der Gesellschaft und der Nutzen verändern sich. Menschen, die heute stark repetitive Arbeiten durchführen und und ihren Job verlieren ... Wir brauchen mehr Leute in der Pflege, die sich um Menschen kümmern. Das ist eine sehr sinnstiftende Arbeit. Man kann nicht einfach sagen, es gibt einen Arbeitsplatzverlust und damit eine riesige Katastrophe. Es wird Verlagerungen geben. Dennoch glaube ich, dass wie nach früheren Evolutionsschritten, unter dem Strich alle weiterhin einen Arbeitsplatz haben werden.

[Person3]: Es sind aber alle beruflichen Aufgaben davon betroffen. Es ist nicht so, dass die Pflege oder Medizin davon nicht betroffen wären. Wir schaffen Pflegeroboter, die Pflegefachpersonen überflüssig machen. Das geht also nicht ganz auf. Ich fände es auch korrekter, zu sagen, dass die Zielsetzung tatsächlich so ist, dass man eine Effizienzsteigerung anstrebt über die Reduktion von bezahlten beruflichen Aufgaben von Menschen. Das muss man zugeben und dann gemeinsam darüber nachdenken, wie man darauf reagieren kann. Was kann man machen, damit für alle ein menschenwürdiges Dasein möglich ist?

[Person10]: Eine Ärztin oder ein Arzt befasst sich zu 40 % mit Dokumentation. Schon heute gibt es künstliche Intelligenz, die eingesetzt werden kann, um Ärztinnen und Ärzte freizuspielen. Das wäre etwas extrem Sinnvolles, es würde unser Gesundheitssystem entlasten. Dort finde ich den Einsatz von KI sehr plastisch und logisch.

[Person3]: Sie wissen ja auch, dass z.B. Bilderkennungsoftware heute schon medizinische Aufgaben erfüllen kann, die über das Administrative hinausgehen. Der Roboterchirurg kann heute schon medizinische Aufgaben erfüllen, die über die repetitiven Aufgaben hinausgehen. Ich finde es nicht ehrlich, nicht einfach zu sagen, dass es zu einer massiven Reduktion bezahlter beruflicher Aufgaben kommen wird, um dann gemeinsam darüber nachzudenken, wie es gelingen kann, dass trotzdem allen ein menschenwürdiges Dasein ermöglicht wird. Auch die Entkopplung von Einkommen und Arbeit wäre ein Weg, das ethisch positiv zu gestalten.

[Person8]: Mein Beispiel wäre ein anderes. Sie arbeiten als Kassierer bei Coop. Das ist eine extrem repetitive und langweilige Arbeit. Dieser Job wird verschwinden. Schon jetzt kann man im Coop und der Migros selber auschecken. Eine Person kann sich dann weiterbilden, in die Pflege gehen, mit Menschen arbeiten. Es sind solche Verlagerungen, damit der Mensch mit Menschen arbeitet, von der Maschine wegkommt, das müssen wir auch im Auge behalten.

[Person4]: Moment schnell. Ich möchte kurz anknüpfen und zwei, drei andere Beispiele von Branchen reinbringen, die durch die KI besonders unter Druck geraten. Das ist sicher auch eine Realität. Gefährdet sind z.B. Jobs im Büro und in Verwaltungen, in Callcentern oder in der Grafik- branche, dort z.B. Illustratoren. Aber diese Seite sagt auch, da kämen neue Jobs, neue Berufsbilder. Warum schauen Sie da einfach weg, Frau Hostetmann?

[Person6]: Bei Frau Rühl hört es sich so an, als könnte man heute das eine sein und morgen das andere. KI entwickelt sich enorm schnell. Es geht nachher darum, dass Leute sehr schnell umgeschult werden müssten. Es ist nicht so, dass diese Angebote von Ihrer Seite jeweils kommen. Das ist das Problem. Sie tun so, als könne man ganz einfach den Job wechseln, aber ich glaube, Ihnen sind diese Menschen etwas egal.

[Person8]: Das stimmt überhaupt nicht. Ich habe gerade versucht zu erklären, dass uns die Menschen überhaupt nicht egal sind. Ich glaube, es ist eine Chance, dass Menschen, die heute repetitive Arbeiten machen müssen, sinnstiftendere Arbeiten machen können. Gewisse dieser sinnstiftenden Arbeiten kann man durchaus auch ohne fünfjähriges Studium erledigen.

[Person6]: Super, dann sind Sie auch für die Arbeitszeitverkürzung bei gleichbleibenden Lohn, nehme ich an?

[Person8]: Ich verstehe nicht, was dieses Argu- ment mit der Diskussion zu tun hat.

[Person4]: Das wäre eine andere "Arena" - eine interessante, aber diese machen wir heute nicht. Heute Abend sprechen wir über KI, deren Möglichkeiten und Risiken. Wir fragen auch Marcel Salathé immer wieder, den Co-Chef am neuen KI-Zentrum der EPFL Lausanne. Eine solche neue Technologie löst natürlich Ängste aus. Sind diese berechtigt?

[Person11]: Ich glaube schon. Wir haben gehört, dass es eine gewaltige Entwicklung ist. Sie passiert auch extrem schnell. Das Tempo muss durchaus realistisch betrachtet werden. Ich glaube, der richtige Ansatz, zumindest mein persönlicher, ist ein gewisser kritischer Optimismus. Man will dem irgendwie offen gegenüberstehen, will Chancen sehen, aber man darf nicht ganz blauäugig reingehen - das werfe ich auch niemandem vor. Es ist eine enorme Veränderung, wie wir sie zuletzt wohl vor 200 Jahren gesehen haben. Niemand kann sich genau erinnern, wie das gelaufen ist.

[Person4]: Kritischer Optimismus, das ist schon fast das Jobprofil eines "Arena"-Moderators, dabei bleiben wir. Die Hochschule für Wirtschaft Zürich hat bei Mitgliedern von acht unabhängigen Angestellten- und Berufsverbänden eine Umfrage gemacht. Das waren z.B. kaufmännische Angestellte, Personalfachleute und Anwält/-innen. Folgendes konnte man ausgehend von dieser Umfrage lesen: 80 % der Befragten sagten, sie bräuchten mehr Fachwissen, um KI effektiv in ihre Arbeit integrieren zu können. Fehlt das nun einfach an Know-how, oder wird das Wissen zu wenig vermittelt?

[Person11]: Ich glaube, es hat effektiv damit zu tun, wie man heute Wissen vermittelt. Unsere ganzen schulischen Systeme, universitären Systeme, Weiterbildungssysteme stammen noch aus einer Zeit, in der sich Technologie über Jahrzehnte verändert hat. Heute leben wir aber in einer Zeit, wo sich die Welt innerhalb von zwei Jahren unter unseren Füssen verändern kann. Wir müssen neue Ausbildungsmodelle finden, um damit umzugehen. Es scheint mir, dass diese Diskussion effektiv in der Schweiz noch zu wenig aktiv geführt wird.

[Person4]: Und wenn man auf dieser Seite davon spricht, dass die KI ein Jobkiller ist - wie nehmen Sie das entgegen und beurteilen es?

[Person11]: Beim Tempo bin ich einverstanden, das ist heikel. Sonst würde ich aber auch sagen, dass wir immer wieder neue Wege gefunden haben. Eine Technologie kommt, ersetzt einen gewissen Teil der Arbeit, schafft aber neue Gebiete. Jedes Mal, wenn eine solche technologische Entwicklung kommt, haben wir noch weniger Arbeitslosigkeit, noch höheren Fachkräftemangel. Da bin ich also eher optimistisch.

[Person4]: Also eine Art industrielle Revolution auf einem neuen Level. Sind Sie etwas entspannter, Herr Kirchschläger?

[Person3]: Nein, überhaupt nicht. Das ist überhaupt nicht respektlos gemeint, aber ich glaube, man riskiert einen Denkfehler. Nur weil technologischer Wandel in anderen Epochen so abgelaufen ist, heisst es nicht, dass es wieder genau gleich abläuft. Es kann auch sein, dass diese Epoche einzigartig ist. Es gibt auch Gründe dafür. Es geht erstens um Ersatz, nicht um Erleichterung. Es geht auch darum, selbstständige Systeme zu entwickeln, die es eben genau schaffen, sich ohne menschlichen Input weiterzuentwickeln. Zweitens betrifft es alle beruflichen Aufgaben, nicht nur diejenigen, die keine oder wenig Qualifikation voraussetzen. Deshalb sollten wir das ernst nehmen und sagen: Okay, es gibt weniger bezahlte Jobs für Menschen. Was können wir machen, damit wir unser Wirtschaftssystem so umstellen, dass ein menschen- würdiges Dasein möglich wird? Mein Vorschlag wäre erstens die Ent- koppelung von Einkommen und Arbeit - dass alle ein Grundeinkommen erhalten, aber kein bedingungsloses. Zweitens sollen alle Society Time leisten, also Zeit für die Gesellschaft, wo sie sich in gesamtgesellschaft- lichen Aufgaben einbringen. Alle gleich viel, aber frei und selbstbestimmt gewählt. Und dann soll drittens ein Anreiz gesetzt werden für Innovation und Unternehmertum, indem man Unternehmer, innovative Leute von dieser Society Time befreit.

[Person4]: Das waren einige Schlagwörter. Was meinen Sie konkret mit Society Time?

[Person3]: Ich meine das in Anlehnung an den schweizerischen Zivildienst. Man kann sich z.B. für Bergbauern und Bergbäuerinnen engagieren oder für Menschen auf der Flucht - dann kann ich meine Gesellschaftszeit dafür einsetzen. Mir geht es weniger um die finanzielle Absicherung als darum, dass ein Arbeitsplatz nicht nur finanzielle Absicherung sondern Sinnstiftung ist. Auch der Job als Kassierer/-in. Ich finde es nicht okay zu sagen, gewisse Arbeiten seien nicht sinnvoll, deshalb können die weg. Nein, das kann für jemanden sehr sinnerfüllend sein. (Rühl) Das habe ich nicht gesagt. Nein, aber von wegen repetitive Aufgaben. Ich finde das etwas heikel. Das ist Sinnstiftung. Wenn ich nie in einen bezahlten Job komme, dann hat man noch die Gesellschafts- zeit, um das einmal zu erleben.

[Person4]: Sie haben es wohl anders gemeint und nicht so sehr zugespitzt, wie Sie es gesagt haben, oder? Nein, absolut.

[Person8]: Ich weiss nicht, ob Sie schon einen ganzen Tag Kasse gesessen haben und Kunden bedienten. Sie schon? Meine Berufskarriere begann in einem Migros-Selbstbedienungsrestaurant. Dort habe ich den Geschirrspüler eingeräumt, das war auch ziemlich repetitiv. Für zwei Wochen ist das lustig, aber irgendwann nicht mehr. So habe ich es gemeint. Dann gehen Sie noch davon aus, dass es keine neuen Jobs geben wird. Unsere These ist, dass gewisse Berufe, gewisse Aufgaben wegfallen werden, ja. Aber es werden andere dazukommen. Unter dem Strich bin ich weiterhin überzeugt, dass wir gleich viele Jobs wie jetzt haben werden.

[Person4]: Herr Kaufmann, was sind das für neue Jobs?

[Person10]: Ich möchte noch etwas grundsätzlich infrage stellen. Und zwar das Ziel, dass alle Menschen immer schön 8 Std. pro Tag arbeiten müssen, 100 % Vollbeschäftigung. Was ist das für eine Vision unserer Gesellschaft? Für mich ist künstliche Intelligenz, so, wie ich das auch in der letzten Woche gesehen habe - das KI-Format des SRF fand ich übrigens super -, etwas wie die Erfindung des Feuers oder des Buchdrucks. Es gibt eine neue Perspektive auf unsere Gesellschaft. Es ist wie ein Vergrösserungsglas. Ein Beispiel bezüglich Bias: Plötzlich sehen wir, wie rassistisch und sexistisch die Gesellschaft in den letzten 100 Jahren war, weil man das mit KI extrem deutlich sieht. Wir haben die Chance, die Gesellschaft zu verbessern. Es wird uns eine Art Spiegel vorgehalten. In der Renaissance damals wurden die ersten Teleskope und Spiegel erfunden, und es kam zu enormen Umwälzungen. Ich glaube, wenn wir es richtig machen, haben wir die Chance, eine neue Gesellschaft und ein neues Zeitalter einzuläuten. Dort arbeitet man vielleicht nicht mehr 8 Std. pro Tag, sondern nur 6 oder 5 Std. und ist mind. so produktiv wie vorher. Und was sind das für neue Jobs, die kommen? Ich finde übrigens, die neuen Jobs könnte man auch der Maschine geben. Falls es neue Jobs gibt, sind das vielleicht Datensammler, das haben wir auch in der Dokumentation gesehen. Aber eigentlich ist es gar nicht das Ziel, dass man die Menschen vom einen in den anderen Job verfrachtet. Es ist doch super, wenn man etwas weniger arbeiten muss, weil uns das die Maschine abnimmt.

[Person6]: Langsam tönt es wie eine Lobbyveranstaltung. Ich sehe auch Chancen für die Privatwirtschaft, das haben jetzt lange genug gehört. Die Frage ist aber, was mit der geopolitischen Lage passiert. KI wird enorm Schnell mit enorm vielen Informationen gefüttert. Ich glaube, der Wettbewerb ist v.a. ein Wettbewerb um Macht und nicht nur um Sicherheit und sichere Systeme. Alle Programme wie ChatGPT wurden zuvor nicht getestet. Das muss man sich einmal vorstellen. Wenn das bei einer Impfung der Fall wäre, wenn man einfach ein Produkt auf dem Markt brächte, ohne vorher lang daran geforscht zu haben, dann würden die Leute das wohl so nicht akzeptieren. Aber bei diesen Programmen ist es so. Niemand kann garantieren, dass man damit nicht sehr Gefährliches machen kann. Im Gegenteil. Dass man dann immer noch naiv nur von den Chancen für die Wirtschaft spricht, das finde ich wirklich bedenklich.

[Person10]: Kurz etwas zu Geopolitik. Mir ist lieber, wenn die Schweizer im Bereich AI ganz vorne sind, als dass man in Zürich einen Punkt Abzug kriegt, wenn man bei Rot über die Strasse geht, wie das in China der Fall ist. Oder ein Grosskonzern, der sagt, was wir glauben müssen. Eigentlich müssen wir als Europa ... - Social Scoring. Genau, Social Scoring. Wenn uns unsere Werte etwas bedeu- ten, müssen wir etwas dafür tun und in diesem Thema ganz vorne mit dabei sein. Hier zu versuchen, zu bremsen und die Privatwirtschaft abzuklemmen, das interessiert die Chinesen und Amerikaner überhaupt nicht.

[Person3]: Es geht überhaupt nicht darum, die Privatwirtschaft abzuklemmen. Schön zu hören war, dass Sie eigentlich bestätigt haben, dass es zu einer Reduktion von be- zahlten beruflichen Aufgaben kommt. Das andere ist: Es geht gar nicht darum, die Wirtschaft abzuklemmen, sondern darum, dass wir merken, dass es neben vielen ethischen positiven Chancen auch Risiken gibt. Diese sind auch entsprechend adressiert. Wir können nicht so tun, als gäbe es sie nicht. Es gibt schon einen Unterschied in Bezug auf Vorurteile und Verzerrungen bei Menschen. Wir Menschen sind dazu fähig, selbstkritisch zu merken, dass wir Vorurteile haben und daran arbeiten. Wenn ich z.B. einen Rekrutierungs- prozess für eine neue Stelle starte und jemanden suche ... Wenn das eine KI macht, kann es sein, dass Frauen einfach aussortiert werden. Wir haben die Daten, dass das passiert. (Rühl) Das haben wir aber auch bei den Menschen, dass Frauen aussortiert werden.

[Person3]: Ja, aber der entscheidende Unterschied ist, dass mir als Mensch das Vorurteil bewusst sein kann und dass ich entsprechend reagieren kann. Ich kann den Bewerbungsprozess umbauen, z.B. ein Vieraugenprinzip einführen oder mögliche Vorurteile von mir gezielt adressieren. Das kann eine Maschine nicht.

[Person4]: Zum Bereich Human Resources, den Sie erwähnen, haben wir auch eine Schlagzeile vorbereitet: Ist das eine Gefahr, die Sie sehen, oder etwas, was sich regeln lässt?

[Person8]: Ich glaube, man muss die KI so trainieren, dass sie das eben nicht macht. Was mich stört in der ganzen Diskussion: Wir tun, als ob wir Menschen perfekt wären. Wir Menschen sind nicht perfekt. In der Musik hat man eingeführt, dass Musiker/-innen hinter einem Vorhang spielen müssen, damit man nicht sieht, ob es ein Mann oder eine Frau ist, weil man diesen Gender Bias hatte. Menschen lügen, Menschen machen Fehler. Es ist also nicht so, dass wir Menschen perfekt wären und die Maschine nicht perfekt. Wenn die Maschine diskriminierend vorgeht, dann ist das ein Spiegelbild davon, wie wir als Menschen sind. Das sollte eigentlich eine heilsame Wirkung haben.

[Person4]: Ein kleines Beispiel für dieses Spiegelbild. Wir sagten ChatGPT diese Woche: "Zeig uns das 'Arena'-Studio mit Moderator." Das kam dabei raus. Man kann darüber reden, ob das futuristisch toll ist, oder nicht und was der Typ in der Mitte mit der Krawatte macht, die er sonst nicht hat. Wenn man genau hinschaut - wie viele Frauen sehen Sie? Ich sehe eine rechts aussen irgendwo. Ist das nicht auch ein Beispiel der Diskriminierung und des Sexismus? Da wird uns allen völlig bewusst, dass das so nicht geht.

[Person10]: Es war in den letzten 100 Jahren so. In diesem Sinne hält uns KI einen Spiegel vor und hilft uns, diese Fehler zu korrigieren.

[Person3]: Wir haben schon vorher herausgefunden, dass das nicht geht. Wir brauchten das nicht, um zu merken, dass man Frauen nicht diskriminieren soll. Diese Beschönigung ... Ich sehe das positive Potenzial, aber wir müssen auch bremsen. Wir haben drängende Probleme im Bereich der künstlichen Intelligenz, die wir angehen müssen. Das sind Biases, die Bedrohung demokratischer Prozesse, Attacken auf Menschen, auf die Natur - wir haben einen enormen Energie- verbrauch im Bereich der sog. KI. Ich plädiere ja auch für positive Chancen, aber wir können nicht so tun, als gäbe es die Probleme nicht.

[Person10]: Wir müssen sie adressieren. Das ist aber kein Problem der Technologie, sondern der Gesellschaft. Dann würde ich eher dort nachschauen, nicht unbedingt die Technologie regulieren.

[Person4]: Ein Stichwort möchte ich aufnehmen: Energieverbrauch. Marcel Salathé, man liest, dass eine ChatGPT-Anfrage zehnmal mehr Energie braucht als eine Google-Suche, oder dass in zehn Jahren so viel En- ergie gebraucht wird wie von Indien. Stimmt das eigentlich?

[Person11]: Es gibt gewisse Vergleiche, die stimmen. Es hört sich aber auch immer schlimmer an, als es wirklich ist. Wenn man 100 ChatGPT-Anfragen macht, ist das am Ende etwa so viel Energie wie wenn man 1 Std. lang TikTok-Videos streamt. Ich würde mal sagen, nach der Stunde auf ChatGPT ist man etwas smarter als nach 1 Std. TikTok. Das kommt natürlich auf den TikTok-Filter an. Die Energie steckt momentan v.a. im Training der Modelle. Das stimmt, das braucht viel Energie. In Zukunft sehen wir v.a. auch viel Energie in der Nutzung, denn auch wenn eine ChatGPT-Abfrage nicht viel ist, sind Hunderte Mio. Menschen, die es tagtäglich nutzen, schon viel. Das ist ein Energiebedarf, den wir planen müssen.

[Person4]: Es geht auch darum, KI verantwortungsvoll einzusetzen. Das wollen alle und sagen alle. Aber wie soll das aussehen? Da sind wir schnell beim Thema Regulierung. Der Bundesrat erarbeitet im Moment einen Leitfaden für den Umgang mit künstlicher Intelligenz. Bis Ende Jahr soll dieser bereit sein. Die EU ist hier schon weiter. Seit Sommer ist eine Verordnung in Kraft, die erstmals Regeln für den Einsatz von KI in den EU-Mitgliedstaaten festlegt. Darüber sprechen wir gleich, Stichwort Regulierung. Aber erst schauen wir uns an, was in der EU gemacht wurde.

[Person2]: Die KI-Verordnung der EU, auch AI Act genannt. Sie sieht für KI-Systeme verschiedene Risikostufen vor. KI-Anwendungen, von denen ein minimales Risiko ausgeht - etwa Videospiele mit KI -, dürfen weiterhin frei genutzt werden. Für KI-Systeme mit begrenztem Risiko gelten neue Transparenzpflichten. So müssen etwa Betreiber von Chatbots wie z.B. ChatGPT die Nutzerinnen und Nutzer darauf aufmerksam machen, dass sie mit Maschinen interagieren. Als hochriskant gelten beispielsweise KI-Anwendungen, die in einem Einstellungsverfahren Bewerbungen von Personen auswerten. Bei diesen Anwendungen muss die Aktivität der KI protokolliert oder auch von einem Menschen überwacht werden. KI-Anwendungen mit inakzeptablen Risiken werden ganz verboten. Etwa Systeme, die soziales Verhalten bewerten können. Unternehmen dürfen z.B. keine KI verwenden, die den Gefühlszustand von Kunden automatisiert bewertet.

[Person4]: Wie gesagt arbeitet der Bund an einem eigenen Ansatz für die Regulierung von KI. Bis Ende Jahr sollten wir mehr wissen. Das EU-Gesetz, das KI in vier Risikogruppen unterteilt, gilt also nicht für die Schweiz. Aber die Frage ist, was in der Schweiz kommen soll. Monika Rühl, ich kann mir vorstellen, dass Sie als Wirtschaftsdachverband so wenig wie möglich regulieren wollen.

[Person8]: Wir wollen v.a. keine Regulierungskeule wie die EU. Der KI-Bereich ist in Entwicklung. Es ist enorm schwierig, etwas zu regulieren, was sich weiter entwickelt. Das ist das eine. Das andere ist, dass wir in der Schweiz in einem Rechtsstaat leben. Wir haben eine Verfassung, Gesetze und Gerichte. Das Bundesgericht hat übrigens kürzlich entschieden, dass das Polizeigesetz im Kanton Luzern nicht anwendbar sein soll für die automatische Überprüfung von Autos und deren Insassen. Von daher haben wir nicht nichts. Wir glauben, es ist wichtig, dass man hinschaut und Lücken in den bestehenden Gesetzen feststellt. Dass man diese Lücken gezielt füllt, anstatt ein umfassendes KI-Gesetz aufzustellen.

[Person4]: Ihnen ist das also zu flächendeckend?- Ja. Aber Sie sehen auch Lücken, die es zu schliessen gilt.

[Person8]: Beim letzten Beispiel im Video bin ich auch dafür, dass man dort strenger reguliert oder von mir aus auch verbietet.

[Person6]: Wenn wir bei diesen Lücken sind. Man sieht das bei den EU-Regeln. Was ist von diesem Risikomodell ausgeschlossen? Es sind wieder Sicherheit und Militär. Sie sagen, es mache keinen Unterschied, ob nun ein Schweizer Kreuz auf einer Drohne ist oder ob es von irgendjemand anderem abgeschossen wird. Aber das sind Technologien, die höchst gefährlich sind. Wir sehen schon heute an der EU-Aussengrenze, dass Frontex mit KI arbeitet, um Menschen zu erkennen. Auch beim neuen Asylgesetz in Europa soll quasi ein gesamteuropäisches Überwachungssystem ausgearbeitet werden. Das ist höchst bedenklich.

[Person4]: Es ist schwierig, den Ball an Pascal Kaufmann als Unternehmer in diesem Bereich weiterzugeben. Denn ihr lebt in anderen Welten. Kann man das so sagen?

[Person10]: Ob wir nun die Vorreiterrolle besetzen und schneller als alle anderen regulieren sollen ... Ich glaube, wir haben in der Schweiz eine super Ausgangslage. Wir können schauen, was in den USA und in China passiert, können das Beste beider Welten übernehmen. Ich sehe bei uns keinen akuten Handlungsbedarf. Ich glaube auch, dass man nicht so schnell legiferieren und Gesetze anpassen sollte. Diese Technologie ist noch so jung. Ich glaube, wir haben hier eine gute gesetzliche Grundlage. Wo es Lücken gibt, sollten wir diese füllen.

[Person3]: Aber ich sehe keinen dringenden Handlungsbedarf. Es kommt in diesem Bereich zu Datenschutzverletzungen, Verletzungen der Privatsphäre. Jedes Mal, wenn wir ChatGPT nutzen, verletzen wir die Urheberrechte von jemandem. Das schmerzt vielleicht Sie nicht, aber wer als Künstler/-in von den Einnahmen der eigenen rechtlich geschützten Werke abhängig ist, den schmerzt das sehr. Das bedroht Existenzen. Hier gibt es einen grossen Handlungsbedarf. Die Nichtregierungsorganisation AlgorithmWatch hat meines Erachtens sehr sinnvolle Vorschläge gemacht. Sie sagte, man solle Schäden verhindern, an Mensch, Demokratie, Gesellschaft und Umwelt und zweitens dafür sorgen, dass alle davon profitieren und nicht nur ein paar wenige multinationale Technologiekonzerne. Es gibt auch viele Unternehmen, die sagen, da muss man dagegenhalten. Es geht auch darum, die Schweizer Wirtschaft zu schützen. Und im ganzen Bildungsbereich haben wir Wildwuchs. Auch wenn keine Studie zeigt, dass Bildschirmzeit den Bildungserfolg dient, obwohl keine Studie zeigt, dass es den Lernprozess fördert, sondern im Gegenteil kognitive Fä- higkeiten degenerieren, verringern, implementieren wir die Technologien in der Schule. Ich würde dafür argumentieren, dass man in Schulen bildschirmfreie Oasen schafft. Wieso? Eine Sorge müssen wir uns nicht mehr machen. Nämlich, dass Kinder und Jugendliche zu wenig Zeit vor dem Bildschirm verbringen.

[Person4]: Was wir sowieso nicht wollen, ist, über Kinder und Jugendliche sprechen. Wir werden in einer Viertelstunde hier hinten mit Ronny und Yuri sprechen, die sagen, was sie wirklich machen von dem, was wir hier vorne behaupten. Das gibt einen Realitätsscheck. Ich weiss, was Sie sagen wollten. Nein, ich wollte etwas anderes sagen.

[Person3]: Doch, Sie sprachen von bildschirmfreien Oasen. Ja, aber es ist interessant ... - Was heisst dass für Sie? Haben Sie sich selbst ein ChatGPT-Verbot auferlegt? Nein, ich brauche es einfach nicht und zwar aus zwei Gründen: ChatGPT und andere aktuelle Produkte in diesem Bereich haben kein Wahrheitskriterium. Es ist eigentlich völlig egal, was gesagt wird, Hauptsache, es wird etwas gesagt. Das Zweite sind Urheberrechtsverletzungen und Datenschutzverletzungen. Das kann man verbessern.

[Person8]: Das muss aber erst einmal geschehen. Frau Rühl, ich habe gehört, Sie wollen die Wirtschaft schützen. Das stimmt.- Da müssen Sie jetzt ein bisschen lachen. Nein, es ist natürlich meine Aufgabe, die Wirtschaft zu schützen und für gute Bedingungen zu sorgen. Ich meinte, dass er Sie auch schützen wollte. Das ist super, danke vielmals. Sie haben viele Beispiele gebracht. Aber wir haben ein Datenschutzgesetz, Persönlichkeitsschutz, Grundrechte in diesem Land. Die Schweiz ist kein rechtsfreier Raum. Zu dem, was Frau Hostetmann zuvor sagte: Respektieren von Menschenrechten und Demokratie, von Rechtsstaatlichkeit. Da gibt es eine Konvention des Europarates, die der Bundesrat zu Ratifizierung vorschlagen möchte. Manche Dinge muss man auf internationaler Ebene regeln. Da ist der Europarat das richtige Gremium.

[Person4]: Dazu ein Beispiel: Vor kurzem wurde der Supercomputer Alps in Lugano eingeweiht, von Bundesrat und Wirtschaftsminister Guy Parmelin am nationalen Hochleistungs- rechenzentrum in Lugano. Dieser Supercomputer kann z.B. in der Klimatologie in einem Tag so viele Rechnungen durchführen, für die ein normaler Laptop 40'000 Jahre benötigen würde. Herr Kirchschläger, Sie wollen mit angezogenen Handbremse unterwegs sein?- Überhaupt nicht. Ich möchte nur präziser arbeiten.

[Person3]: Ich wünsche mir, dass wir genauer prüfen, was die ethisch positiven Potenziale wären, auch von dem soeben beschriebenen Beispiel. Gleichzeitig muss man die ethisch negativen Risiken adressieren. Interessanterweise hat das Jugendparlament des Kantons Luzern sich auf eine Petition einigen müssen, die sie im offiziellen Parlament einbringen durften. Worauf haben sie sich geeinigt? Einen obligatorischen Elternabend, um die Erwachsenen darauf vorzubereiten, Kinder und Jugendliche besser vor Social Media zu schützen, vor der damit verbundenen Sucht. Das müssen Sie sich einmal auf der Zunge zergehen lassen. Hat es je eine Generation gegeben, die die Eltern darum gebeten hat, sie vor dem Rauchen oder vor dem Alkoholtrinken zu schützen? Das glaube ich nicht. Daran hat man aber gesehen, wie dringend das Anliegen ist. Dass man das Suchtproblem im Bereich von Social Media bekämpfen muss. Und das sagen nicht die Erwachsenen, sondern die Jugendlichen selber. Das Jugendparlament des Kantons Luzern, welches sich auf diese Petition einigte.

[Person4]: Sind Sie, Herr Kaufmann, eine Art Dealer, der die Sucht befriedigt?

[Person10]: Sie meinen die Sucht nach Social Media? Herr Kirchschläger spricht die Generation Z an. In vielen Fällen hält sie uns einen Spiegel vor. Sie fragen z.B., ob sie nicht möglicherweise ein bisschen Teilzeit arbeiten können. Oder, ob es denn sinnstiftend sei, das ganze Leben lang nur zu arbeiten. Sie stellen uns Fragen, die wir uns vorher nie gestellt haben. Ich betrachte das als Chance. Social Media, die virtuellen Welten sind so verlockend, so attraktiv, dass man sich überlegen muss ob das nicht ein interessanter Aspekt ist. Die Generation Z stellt uns Fragen, die wir vorher nicht gehört haben. Eine Chance für die Gesellschaft, diese Dinge zu überdenken.

[Person6]: Das sind keine Fragen, die so noch nicht gestellt wurde. Und es ist nicht nur die Generations Z, die gerne weniger arbeiten würde, aber ohne Einbussen beim Lohn. Bei Social Media ist das Problem, dass die Daten durch die Konzerne einfach abgezogen werden. Sie haben die bestehenden Gesetze angeführt. Diese greifen aber nicht mehr für die aktuelle Situation. Sie als JUSO haben auf die ganz grossen Fragen ganz einfache Antworten, nämlich diese: Enteignung, ernsthaft? - Ja, ernsthaft.

[Person6]: Ich glaube, dass wir als Gesellschaft die Kontrolle zurückholen müssen. Die KI hat enorme Grenzen überschritten. Ich glaube, dass wir noch zurückgehen können. Jetzt ist es eine Frage der Transparenz, das ist der erste Schritt. Die Unternehmen müssen Transparenz schaffen, wie die Algorithmen funktionieren, welche Daten verwendet werden, was mit diesen Daten gemacht wird, damit die Gesellschaft dann darüber entscheiden kann, ob sie das möchte, und wenn ja, welche Formen davon. Das wäre wichtig.

[Person8]: Die JUSO möchte einfach enteignen, KI-Unternehmen, Familienunternehmen in der Schweiz enteignen. Es ist offenbar eine flächendeckende Enteignung geplant. Die Schweizer Wirtschaft leistet jedoch einen wichtigen Beitrag zu dieser Gesellschaft. Wenn Sie die Unternehmen alle enteignen wollen, haben Sie keine Steuereinnahmen, keine Arbeitsplätze, dann wird es uns allen schlechter gehen. Wollen Sie das wirklich?

[Person6]: Es geht um die Demokratie. Ich bin der Überzeugung, dass die Menschen überall im Leben mitbestimmen können sollten. Das gilt auch für den Arbeitsplatz. Ich glaube, unsere Produkte würden besser, wenn die Menschen mitentscheiden könnten, wie diese hergestellt werden. Zusätzlich sollen Nutzer/-innen mitentscheiden, ob sie wirklich wollen, dass ihre Daten verwendet werden oder nicht.

[Person8]: Frau Hostetmann, haben Sie einmal in einem Unternehmen gearbeitet? Wissen Sie, wie dort die Arbeitsprozesse sind? Wissen Sie dass man dort zusammensitzt und gemeinsame Entscheidungen trifft? Wissen Sie, dass man Produkte gemeinsam entwickelt, dass man den Rat der Wissenschaft einholt? Da werden nicht von irgendwelchen Profiteuren einsame Entscheidungen getroffen. Solche Entscheidungen werden gemeinsam getroffen.

[Person6]: Sie skizzieren eine Weltbild, das nicht der Realität entspricht. Ich finde es ein lächerliches Argument, uns vorzuhalten, wir hätten sie gearbeitet. Ich habe nie so viel Geld verdient wie ein CEO oder auf dieser Ebene mitbestimmen können. Das stimmt. Ich möchte behaupten, dass sich dennoch gleich viel gearbeitet habe. Es geht nicht, dass solche Menschen schlechter behandelt werden.

[Person4]: Ich hole den Rat des Wissenschaftlers ein. Ich möchte nicht Ruhe reinbringen, aber trotzdem dafür sorgen, dass sich die Gemüter etwas beruhigen. Ist eine Balance zwischen Innovation und Regulierung möglich?

[Person11]: Ja, ich halte das jederzeit für möglich. Es ist nicht das erste Mal, dass wir neue Technologien erfinden. Vielleicht ist es das letzte Mal, das steht noch in den Sternen. Man muss immer eine Balance finden zwischen Innovation und Regulierung. Die Frage ist wo man da ansetzt, darüber gehen die Meinungen auseinander. Ich habe das Gefühl wir schmeissen ein paar Dinge in den gleichen Topf, soziale Medien und KI muss man schon ein bisschen unterscheiden. Die KI ist im Moment sehr stark unterwegs. Die Menschen haben ein Bedürfnis nach Transparenz. Sie haben gerade Lugano gezeigt. Das ist wirklich etwas Interessantes für die Schweiz, dass sie jetzt diese Rechner hat, die der Forschung zur Verfügung stehen. Wir trainieren nun unsere eigenen Modelle und sind völlig offen und transparent. Diese können wir dann der Gesellschaft und der Wirtschaft zur Verfügung stellen. Mir scheint, da haben wir ein gutes Mittelmass gefunden. In der Wirtschaft handelt es sich da um Geschäftsgeheimnisse, dass kann man auch verstehen.

[Person4]: Die Balance ist im Moment gesund. Sie sind ein bisschen der Schieds- richter in dieser Diskussion heute. Ich habe meine Karten vergessen. Wenn Sie das Wort Enteignung hören, sträuben sich bei Ihnen schon die Nackenhaare, oder?

[Person11]: Ja. - Okay. Wir leben in einer Gesellschaft, in der wir alle es sehr schätzen, dass es Privateigentum gibt. Durch die Demokratie findet die Schweiz immer einen guten Mittelweg. Als Gesellschaft fragen wir uns, wie wir das regeln. Wir wollen ja keine Anarchie. Das Gesundheitssystem ist ein Beispiel, an dem wir gemeinsam arbeiten, oder das Bildungssystem. Dann gibt es andere Bereiche, bei denen wir sagen, die sind in der Zuständigkeit der Einzelnen.

[Person4]: Da suchen wir immer wieder eine Balance. Was ist Ihre Erwartung an den Bundesrat bis Ende des Jahres?

[Person11]: Bis Ende des Jahres erwarten wir eigentlich nichts. Mittelfristig erwarten wir als Forscher eine gute Forschungslandschaft. Der Rotstift ist im Moment die treibende Kraft in der Politik. Das ist heikel, ich habe dennoch Verständnis für balancierte Budgets. Aber wir befinden uns in einer extrem aussergewöhnlichen Situation, wahrscheinlich historisch, wenn wir zurückschauen und dann sagen müssen, dass wir den Anschluss verpasst haben, weil gerade Rotstiftsession war, würde mir das Sorgen machen.

[Person4]: Sie sagen auch, dass wir auch die Digitalisierung schon verschlafen hätten.

[Person11]: Es ist nicht umsonst, dass wir in der Schweiz und in Europa von der digitalen Souveränität sprechen, weil wir dieses Thema ein bisschen verpasst haben, das stimmt.

[Person4]: Wie gross ist die Gefahr, Herr Kaufmann, dass wir den Anschluss verschlafen? Sie sagen, wir können genau so gut sein wie die Amerikaner auch unter Donald Trump als Präsident, und dass wir auch mit den Chinesen mithalten.

[Person10]: Da geht es um so etwas wie Wirtschaftsnationalismus, wenn man sagt, gewisse Produkte werden in einem Land eingesetzt oder nicht. Oder wenn man in der Schweiz amerikanische Systeme einsetzt, werden die plötzlich viel teurer. Wir müssen die Abhängigkeit von Technologien aus fremden Ländern reduzieren, v.a. mit Blick auf die geopolitische Lage. Als Schweiz können wir Vorbild sein, wie man es besser machen kann. Transparente Systeme, Open Source. Wir haben auch neuartige Algorithmen, die nicht so viel Energie brauchen. Für die man nicht riesige Rechenzentren und AKW bauen muss. Die Schweiz hat einige Beispieltechnologien, die wir in der Welt positionieren könnten. Zudem sind wir Vermittler, wir sind neutral in der Welt. Eine ausgezeichnete Ausgangslage, um im KI-Rennen eine Führungsrolle zu übernehmen.

[Person4]: Stehen da so Leute wie Herr Kirchschläger im Weg?

[Person3]: Nein, im Gegenteil. Gerade weil wir in der Schweiz in der KI-Forschung mitführend sind, plädiere ich für eine Verbindung mit der sog. menschenrechtsbasierten KI. Menschenrechte sind schliesslich einer der aussenpolitischen Pfeiler der Schweiz. Wir können also zeigen, wie es funktioniert, wenn man menschenrechtsbasiert KI entwickelt. Und zwar über alle Lebensphasen der KI. Da geht es um die Rohstoffschürfung, Billigproduktionsstandorte, die menschenrechtskonform betrieben werden müssten. Es geht um die Nutzung, und teils auch aus Gründen der Menschenrechte um die Nichtnutzung von KI-Möglichkeiten. Allerdings muss man auch realistisch sein. Wenn man menschenrechtsbasiert eine globale Regulierung möchte, was ich basierend auf meiner Forschung vorschlagen möchte, braucht es auch eine globale Durchsetzungsinstitution, sonst ist die Regulierung das Papier nicht wert, auf dem sie steht. Die multinationalen Techkonzerne werden nicht auf die Regulierung eingehen. Sie werden so lange die Regeln verletzen, wie der Gewinn höher ist als die Strafe. Es braucht eine Durchsetzungsinstitution. Eine internationale datenbasierte Systemagentur, Abkürzung IDA, bei der UNO. Sie würde dem Modell der Interna- tionalen Atomenergiebehörde folgen. Kurz der Vergleich: Was haben wir in der Nukleartechnologie gemacht? Wir haben geforscht, die Atombombe gebaut, sie ein paarmal eingesetzt, und dann hat man gemerkt, wenn man so weiter macht, gibt es bald die Menschheit und den Planeten nicht mehr. Dann wurde die Internationale Atomenergiebehörde geschaffen. Sie ist nicht perfekt, insbesondere von Supermächten wird sie für eigene Interessen missbraucht. Aber man muss zugeben, dass es ihr gelungen ist, Schlimmeres zu verhindern.

[Person4]: Das wäre auch eine Aufgabe der IDA. IDA wäre also die internationale Datenagentur, die Ihnen vorschwebt. Die Atombombe mit der KI zu vergleichen, ist allerdings ein steiler Vergleich.

[Person3]: Wie gesagt, es gibt ein riesiges ethisch positives Potenzial. Das sei in aller Deutlichkeit gesagt. Gleichzeitig haben wir aber auch die Herausforderung, dass jemand ein automatisiertes Waffensystem tödlicher Natur baut und damit grossen Schaden anrichtet. Wir können nicht so tun, als ob dieses Risiko nicht bestünde. Ich komme zurück zur App, die Kinderbilder sexualisiert ... Diese haben Sie ganz am Anfang der Sendung angesprochen. Wenn wir die IDA hätten, käme so etwas überhaupt nicht auf den Markt. Die IDA hätte die Marktzulassungsfunktion, die wir aus der Pharmaindustrie als selbstverständlich kennen. Dass zuerst eine Test durchlaufen werden muss, ob ein Medikament nicht schädlich ist für den Menschen oder die Natur, bevor man es auf den Markt bringen darf.

[Person4]: IDA wäre also eine Agentur, die sicherstellt, dass es menschenrechtsbasierte KI gibt. Was halten Sie davon?

[Person8]: Wir befinden uns in einer Krise des Multilateralismus. Die Geopolitik ist extrem angespannt. Ich glaube nicht, dass eine solche Institution zum jetzigen Zeitpunkt errichtet werden kann, dass sich die Länder darauf einigen könnten. Sie schiessen ja immer auf Unternehmen. (Kirchschläger) Ein paar Unternehmen. Diese Unternehmen haben ihren Sitz in den USA. Und auch die USA sind ein Rechtsstaat. Die USA muss diese Unternehmen überwachen, damit sie die amerikanischen und internationalen Gesetze einhalten. Eines dieser Unternehmen muss nun wegen seiner Monopolstellung einen Teil seiner Aktivitäten verkaufen. Statt dass man auf der multila- teralen Ebene ein Konstrukt baut, muss man, glaube ich, auf die Rechtsstaatlichkeit in den Ländern, in denen diese Unternehmen ansässig sind, setzen.

[Person3]: Mit IDA setzt man ja auf die Rechtsstaatlichkeit. KI ist jedoch ein globales Phänomen. In den USA ist es so, dass einzelne Bundesstaaten nun beginnen, eigene KI-Regulierungen zu entwickeln, um diese dann auf die Gesamtebene in den USA zu bringen. Das ist sicher nicht im Interesse der Unternehmen, dass man für jeden US-Bundesstaat ein eigenes Produkt basteln muss. Ich glaube, der grösste Teil der Unternehmen hat keine Freude daran, dass eine Kinderbilder sexualisierende App legal auf den Markt gebracht werden kann. (Rühl) Davon hat niemand gesprochen.

[Person10]: (Kirchschläger) Doch, aber es ist ein Phänomen. (Kaufmann) Zum Mittel der Regulierung greift man, wenn man die Kompetenz nicht hat. Ein Schutz, dass nicht einfach reguliert wird, weil wir die Kompetenzen nicht haben ... Und die Schweiz ist in diesen Themen extrem kompetent. Wir sind in der Lage, eine eigene Regulierung zu machen. Wenn wir die Kompetenz nicht aufbau- en und das andere geschehen lassen, dann werden wir reguliert. Ich finde, dass man selber Regulierungen entwickelt, weil solche Regulierungen kulturbestimmend sind.

[Person3]: (Hostetmann) Die Schweiz soll kein Tech-El-Dorado werden.

[Person6]: Es braucht Regeln und Rahmenbedingungen, wie bei allen anderen Dingen auch. Die Schweiz hat das einfach verpasst. Das muss möglichst schnell nachgeholt werden. Dafür müssen EU-Regeln übernommen werden, aber es müssen auch Schlupflöcher gestopft werden, damit die Menschenrechte garantiert werden können, wie wir es hier jetzt auch schon einige Male gehört haben.

[Person4]: Darf ich kurz? Vielleicht ist es auch in Ihrem Interesse. Frau Hostetmann sagte, die Schweiz solle kein Tech-El-Dorado werden.

[Person8]: Wieso eigentlich nicht? Ich will, dass die Schweiz führend wird. El Dorado ist ein komischer Begriff. Ich möchte, dass die Schweiz führend wird, und sie hat dafür alle Voraussetzungen.

[Person6]: Der Supercomputer ist ein wichtiges Element. Ich will auch, dass die Schweiz in der Forschung Fortschritte macht, aber das kann doch an öffentlichen Universitäten passieren. Es passiert heute schon an öffentlichen Universitäten. Das Problem ist, was mit dieser Technologie hinterher passiert. Da kommen wir zum wichtigsten Punkt zurück. Es geht darum, wem die Technologie gehört und wer davon profitiert. Ich finde, die KI soll für die Menschen arbeiten, nicht gegen sie. Absolut, die KI soll für, nicht gegen den Menschen arbeiten.

[Person8]: Ich sehe aber kein Problem darin, wenn die Besitzer solcher KI Privatunternehmen sind. Mich stört die Verteufelung von Privatunternehmen. Sie sprachen von Enteignung. Wenn Sie meinen, dass der Staat die Aufgabe besser erledigen könnte, setze ich grössere Fragezeichen.

[Person3]: Schauen Sie einmal die Entwicklung an, die wir bei den Social Media gehabt haben. Man hat die Technologieunternehmen schalten und walten lassen, wir haben nichts gemacht. Es gab keine Regulierung seitens des Staates. Was ist passiert? Wir haben eine wachsende Sucht unter den Jugendlichen. Die neueste WHO-Studie vom September 2024 spricht von einer wachsenden Sucht. (Rühl) Wollen Sie das wegregulieren? Jetzt darf er auch ausreden. - Er hat mehrfach unterbrochen. Ich habe es versucht ... - Ganz kurz mein Gedanke: wir haben ein wachsendes Suchtphänomen, mentale Gesundheitsprobleme bei Kindern und Jugendlichen, eine wachsende Suizidrate. Es ist auch keine gute Idee aus schweizerischer und europäischer Perspektive, die politische Bildung von Kindern und Jugendlichen TikTok zu überlassen. Wir müssen verhindern, dass Social Media, die eigentlich als asoziale Medien gebaut wurden, um Kinder und Jugendliche abhängig zu machen, das übernehmen. Es ist auch nicht im Interesse der grossen Mehrheit der Unternehmen. V.a. nicht der Unternehmerinnen und Unternehmer, denn die haben auch Kinder und Jugendliche. Ich erinnere an das Jugendparlament des Kantons Luzern, das uns sagt, sie wünschen sich, besser geschützt zu sein.

[Person4]: Danke für diesen Steilpass. Denn jetzt gehen wir zu unseren Jugendlichen. Wie andere SRF-Gefässe im Fernsehen, Radio und online nimmt sich die "Arena" in dieser Themenwoche der Frage an, was künstliche Intelligenz für uns alle bedeutet. Man könnte davon ausgehen, dass jüngere Menschen der Technologie offener gegenüberstehen und auch ein bisschen mehr Ahnung davon haben als ältere Semester wie ich. Wir machen also den Reality Check mit zwei Schülern der Kantonsschule Zürich Oberland in Wetzikon. Bei uns sind Ronny Siegenthaler, 17, aus Gossau und Yuri Kaspar, 18, aus Bauma. Beide sind im letzten Gymi-Jahr. So schnell geht es und man ist Teil dieser "Arena". Willkommen. Wir haben vorhin abgemacht, dass wir uns duzen, das gilt natürlich gegenseitig. Yuri, ist künstliche Intelligenz eine Sache, die dir das Leben einfacher macht in der Schule?

[Person5]: Ja und nein. Ich würde sagen, es hat definitiv Chancen. Man kann Gruppenarbeiten, Podcast-Konzepte, Übersetzungen, Textüberarbeitungen, Bildmaterial wie Plakate mit KI machen, man kann damit Brainstorming machen. Nur muss man es am Schluss eben doch noch selber lernen, das kann einem KI nicht abnehmen. Da sehe ich auch die grösste Herausforderung. Das Risiko, dass man genügend Eigenverantwortung hat, um doch noch zum eigenen Lernerfolg beizutragen.

[Person4]: Wie gross deine Eigenverantwortung ist, zeigt sich daran, dass du deine Maturaarbeit ohne KI geschrieben hast, oder?

[Person5]: Bewusst, ja. Es war mit gewissen Richtlinien in der Schule erlaubt, KI als Quellenangabe zu zitieren. Ich habe mich bewusst dagegen entschieden und einfach herkömmliche Studien genutzt. So kann ich am Ende sagen, dass das von mir ist.

[Person4]: Das Stichwort Weg ist genial, denn sag selbst den Titel und die Untersuchung, die du gemacht hast.

[Person5]: "Das Wandern ist der Gen Zs Lust". Ich habe das Wanderbedürfnis der jungen Generation untersucht und Vorschläge im Zürcher Oberland gemacht.

[Person4]: Ist das Wanderbedürfnis der Gen Z grösser geworden? Es ist grösser als bei älteren Generationen und grundsätzlich der erfolgreichste Volkssport in der Schweiz.

[Person4]: Das hat aber auch mit Social Media zu tun, oder? Weil dort so viel von den schönen Regionen gezeigt wird, wo man wandern kann.

[Person5]: Das ist auch ein Ergebnis meiner Maturaarbeit. Eine der Hauptinformationsquellen ist Social Media, so erreicht man die Zielgruppe am besten.

[Person4]: Ronny hat auch eine Maturaarbeit geschrieben, über das Verkehrskonzept der Stadt Wetzikon. Mit oder ohne KI?

[Person9]: Ohne KI, natürlich. - Wieso natürlich? Weil meine Lehrperson eher konservativ gegenüber KI eingestellt war. War das eher mühsam oder okay? Grundsätzlich wäre ich der Meinung, hätte ich KI benutzt, hätte ich fast mehr Aufwand betreiben müssen, als wenn ich das selbst geschrieben hätte. Weil das eine so individuelle Arbeit ist. Bis ich alle Ideen entwickelt habe ... Ich müsste der KI alles erklären, was ich genau machen will. Das bräuchte mehr Aufwand, als die Arbeit einfach selbst zu schreiben.

[Person4]: Der Lehrerdachverband hat öffentlich ausgesagt: Die Lehrer unterstellen euch, dass die Schüler wegen KI weniger selbst denken und auch weniger motiviert sein könnten, neue Dinge zu lernen. Wenn ich euch zuhöre, besteht diese Gefahr überhaupt nicht. Nun könnt ihr gegen die Lehrer und deren Meinungen wettern.

[Person5]: Ich finde diese Kritik durchaus berechtigt.- Okay. Wenn Mitschüler weniger Aufwand für das gleiche Produkt betreiben und eine bessere Note kriegen, dann ist Eigenverantwortung gut und recht, aber es braucht auch gesetzliche Rahmenbedingungen. Gerade bei benoteten Arbeiten, bei Abschlussprüfungen muss transparent deklariert werden, wo man es benutzen darf und wo nicht. Wofür ist das gut und was kann es auch nicht?

[Person4]: Ich bin fast versucht zu sagen, du sollst in diese Runde kommen, aber ich wüsste nicht, wen ich rausschicken soll. Unglaublich gut, wie ihr argumentiert und das auf den Punkt bringt. Ihr habt die Diskussion rund um die Regulierungen miterlebt.

[Person9]: Wie siehst du das? Ich sehe durchaus Probleme bei der KI, v.a. moralischer Art. Und den Aspekt, dass es ein Monopol ist, das von grossen Techkonzernen kontrolliert wird, die v.a. aus den USA kommen. Es gibt grosse moralische Bedenken, v.a. im Umgang mit Quellen. Und was es alles braucht, um die KI zu trainieren - wie bereits gesagt wurde, sind das oft Materialien von Künstler/-innen und allem Möglichem, was man im Internet findet. Dass das von der KI irgendwie auf neue Art zusammen gemischt wird, muss stark hinterfragt werden. Wenn man mit KI arbeitet, muss man auf jeden Fall hinterfragen, was das Ergebnis ist und v.a. verstehen, was sie sagt.

[Person4]: Das sagt Ronny Siegenthaler. Neben ihm ist Yuri Kaspar, vielen Dank.

[Person8]: Monika Rühl, sind Sie auch so begeistert wie ich? Es kann nicht anders sein, ihr seid von der Kantonsschule Wetzikon, die habe ich auch besucht. Super habt ihr das gemacht.

[Person4]: Er sagt also auch, da gibt es moralische Bedenken und man muss hinschauen. Man kann nicht einfach den Markt spielen lassen.

[Person8]: Ich habe nicht gesagt, dass man nicht hinschauen soll. Ich finde das absolut berechtigt. Es gibt Risiken, aber ich wollte heute Abend die Chancen betonen, denn wir sprechen immer nur über die Risiken. Man muss das genau anschauen, da hast du absolut recht, das sehe ich auch so. Was Yuri gesagt hat, hat mich natürlich total gefreut - Eigenverantwortung, dass dieses Wort auch heute noch in Mode ist, das finde ich super.

[Person4]: Was sagt der Ethiker dazu?

[Person3]: Fantastisch, ich würde gleich meinen Platz übergeben, man kann nicht besser argumentieren. Ich bin begeistert von der Art und Weise, wie ihr eure Positionen vertretet, aber auch inhaltlich gibt es eine gewisse Nähe, wenn ich das ganz bescheiden sagen darf. V.a. hat mich beeindruckt, wie ihr das vertreten habt. Ich bin nicht sicher, ob ich Ihnen zustimme, dass man immer nur von Risiken spricht. Fakt ist, dass es einen Markt gibt, der einfach läuft, wo nichts gemacht wird, wo wir einfach zuschauen. ChatGPT ist eigentlich nichts anderes - apropos Wandern -, als eine wiederkäuende Kuh. Es frisst alles, was Menschen einst geschaffen, gedacht, geschrieben und formuliert haben, spült es durch, spuckt es aus und wir sind ganz begeistert. Ich teile die Begeisterung in Bezug auf grammatikalische Korrektheit, ich teile die Begeisterung, dass die Bedeutung einigermassen Sinn macht, aber ich verstehe nicht, dass wir nicht gleichzeitig kritischer hinschauen können und denken, wir können etwas wie ChatGPT bauen ohne Urheberrechts-, Datenschutz- oder ohne Privatsphärenverletzungen. Es muss doch möglich sein, ein profitables Produkt auf den Markt zu bringen, das menschenrechtskonform ist.

[Person4]: Vielen Dank nochmals, Yuri und Ronny.

[Unknown]: Ein Spezialapplaus für euch.

[Person4]: Pascal Kaufmann, wir haben gehört, das müsste doch möglich sein ohne Urheberrechtsverletzungen usw. Ist es das, was Ihnen mit SwissGPT etwas vorschwebt?

[Person10]: Auf jeden Fall, ja. Man kann die Technologien so bauen, dass sie legal sind, dass darin unsere Werte reflektiert werden und dass sie für die Welt kompatibel werden. Unbedingt sollten wir ein solches Werkzeug bauen, ja.

[Person4]: Marcel Salathé, Co-Chef des KI- Zentrums an der EPFL in Lausanne. Zurück zu den Jugendlichen. Mit der Einführung des Lehrplans 21 ist das Thema in den Schulen sehr viel präsenter als vorher. Medien und Informatik gehören heute zum verbindlichen Inhalt auf allen Volksschulstufen. Heisst das aus Ihrer Sicht, man macht genug, oder könnte man noch mehr tun, wenn es um KI-Kompetenz geht?

[Person11]: Ich denke, man kann noch einiges mehr tun. Das höre ich auch in Diskussionen. Es gibt immer noch viele Missstände, was KI ist. Wir hören immer wieder von Apps, die überhaupt nichts mit KI zu tun haben. Wenn illegale Apps auf den Markt kommen, ist das ein Problem des Marktplatzes, nicht von der Technologie selbst. Ich denke, wir finden aktuell heraus, wie das geht, auch an den Hochschulen. In einer aktuellen Studie haben wir gefragt: Wenn jemand ein EPFL-Studium nur mit ChatGPT absolvieren würde, wie viele Prüfungen würde er bestehen? Das Resultat sind über 60 %, die einen genügenden Notenschnitt hätten. Die Idee, dass aus ChatGPT keine Wahrheit kommt, ist etwas amüsant. Natürlich wurden diese Systeme von Daten abgehend trainiert, nicht Daten sozialer Medien, sondern auch auf Daten wissenschaftlicher Arbeiten. Das wurde dann finetuned, damit es dann einigermassen wahrheitsgetreu ist. Das sehen wir nun immer mehr. Es ist nicht nur bei ChatGPT so. Erinnern wir uns an Tools, wo uns KI mit medizinischen Diagnosen hilft. Da wissen wir heute schon, dass das besser funktioniert als mit vielen Ärzten. Wenn es darum geht, Proteinfaltungen für neue Medikamente zu finden, dann geht das viel besser, als wenn man das von Hand machen wollte. Das ist alles objektiv korrekt. Ich glaube, hier muss man noch schneller auf die Jugendlichen zugehen und richtigen kritischen Optimismus vertreten. Aber man soll es auch annehmen. Am Ende will man ja die Tools auf einem globalen Werkplatz nutzen, sonst sind die anderen immer zwei Schritte voraus.

[Person4]: Wir gehen mit kritischem Optimismus in die Schlussrunde dieser Sendung. D.h., wir haben noch etwa 5 Min. Ich möchte in der Hauptrunde etwas abholen. Wir haben uns bemüht, nicht nur Schwarz und Weiss zu malen, sondern die Möglichkeiten auf den Tisch zu legen. Gleichzeitig gibt es jemanden, der im Moment eine wahnsinnige Präsenz hat in den Medien. Ein Historiker, Lehrer und Bestsellerautor, der Bücher über die Gefahr im Zusammenhang mit KI aus seiner Sicht geschrieben hat. Das ist der Einspieler zu Yuval Noah Harari:

[Person7]: Dies ist das Ende der Menschheitsgeschichte. Nicht das Ende der Geschichte, sondern das Ende der von Menschen dominierten Geschichte. Die Geschichte wird weitergehen, aber kontrolliert von jemand anderem.

[Person4]: Das wäre das Horrorszenario. Monika Rühl, machen Sie sich Sorgen, dass uns KI irgendwann dominieren wird?

[Person8]: Nein, absolut nicht. Ich bin überzeugt, dass der Mensch weiterhin Taktgeber sein wird und eine Zusammenarbeit mit der von ihm gesteuerten Maschine haben wird.

[Person4]: Peter G. Kirchschläger, macht sich der Mensch mit künstlicher Intelligenz selber überflüssig?

[Person3]: Zumindest wäre es sogar sinnvoll, dass wir gewisse Aufgaben, wo uns die Maschine massiv überlegen ist, auch der Maschine anvertrauen. Nur müssen wir genau hinschauen. Vorher wurde gesagt, eine App habe nichts mit KI zu tun. Wenn die App mit KI gebaut ist, hat sie sehr wohl etwas damit zu tun. Wenn Social Media mit KI gesteuert wird und gewisse Dinge bei Jugendlichen anrichtet, hat das sehr wohl mit KI zu tun. Das müssen wir adressieren. Mir geht es darum, dass wir präziser hinschauen, genau hinschauen, was die ethischen Chancen und Risiken sind. Wenn wir das nicht tun, besteht die Gefahr, dass wir mit den Systemen, die selbst auch dümmer werden, weil wir sie mit den eigenen Daten trainieren und nicht zwischen wissenschaftlichen Studien und Neonaziblättern unterscheiden - die werden genau gleich behandelt. Dann ist die Gefahr gross, dass wir selbst als Menschheit leider auch dümmer werden.

[Person4]: Pascal Kaufmann, KI-Unternehmer, auch Pionier in diesem Bereich. Was sagen Sie zu solchen Ängsten?

[Person10]: Ich habe null Angst vor künstlicher Intelligenz. Für mich ist künstliche Intelligenz wie eine Schaufel. Entweder kann man ein Loch mit nackter Menschenhand selber graben oder man nimmt eine Schaufel. Ich behaupte, es ist immer das gleiche Loch, eines, das man selbst gemacht hat. Genau so ist es mit einem ChatGPT- oder SwissGPT-Text. Ob ich den Text mit meinen nackten Fingern schreibe, oder ob ich Befehle diktiere und der Text genau so generiert wird, nach meinen Wünschen ... Ich finde, das sollte man unbedingt einsetzen. Ich finde, es ist eine Schaufel. Würde man einem Taschenrechner Selbsterhaltungstrieb einbauen oder Machtfantasien, dann hätte ich auch vor einem Taschenrechner Angst. Wir bauen keine Werkzeuge, die Selbsterhaltungs- oder Überlebenstriebe haben. Das ist Angstmacherei von Yuval Harari und ich halte nichts davon.

[Person4]: Mirjam Hostetmann, nehmen Sie doch die Schaufel in die Hand und graben Sie mit. Oder möchten Sie lieber das Reich der Finsternis mit propagieren?

[Person6]: Nein, ich glaube gar nicht, dass KI das Ende der Menschheit ist. Ich sehe KI als Instrument, als Werkzeug, das von den Menschen genutzt werden soll. Es muss aber von der gesamten Gesellschaft genutzt werden, nicht nur von den Mächtigen. Denn dann sehe ich Risiken, sonst sehe ich viele Chancen.

[Person4]: Die Stimme der Ausgewogenheit am Schluss: Marcel Salathé, wie gross ist die Gefahr, dass wir die Kontrolle über Maschine verlieren?

[Person11]: Das ist sehr schwer vorauszusagen. Denn wir hatten es noch nie. Es ist aber die Urangst, da gehe ich mit Ihnen einig. Es ist sicher etwas, wo wir den Finger drauf halten müssen. Ich möchte doch noch eine Gegenfrage stellen, Herr Brotz.

[Person4]: Mir? Jetzt wird es interessant.

[Person11]: Hätten Sie Harari gezeigt, wenn er gesagt hätte, die KI sei eine balancierte Sache mit Chancen und Risiken, die beide betrachtet werden müssen?

[Person4]: Nein, er hat mir eine Frage gestellt. Ich bin der, der behauptet, er stelle jeweils kritische Fragen, dann muss er auch eine kritische Frage beantworten müssen. Tendenziell weniger, ganz ehrlich. Weil es die interessantere Aus- gangslage für eine Diskussion ist. Okay? - Okay.

[Person3]: Ich finde einfach, wir müssen aufpassen, nicht zu sagen, dass es ethische Chancen und Risiken gibt, die sich abwägen. Dann machen wir einen Denkfehler. Es gibt auch ethische Risiken, die wir wirklich vermeiden müssen. Wenn Menschen- oder Kinderrechte verletzt werden, kann man das nicht aufwägen. Sie haben das so formuliert, man lasse sich sagen, wie ich denken soll etc. So wird das Denken vorgespurt. Ich würde dazu einladen, selbst zu denken.

[Person4]: Und ich lade dazu ein, die weiteren Sendungen in Zusammenhang mit KI im Rahmen der SRF-Themenwoche zu konsultieren. Das sind spannende Dinge, die man alle unter srf.ch/KI findet. Ich weiss, ich nehme etwas vorweg. Wir haben mit der Regie geplant, das nachher zu machen. Aber wenn wir schon davon sprechen, zeigen wir's jetzt und hoffen, dass man den Einblender auch sieht. Das war eine lebhafte Debatte zu Chancen und Risiken künstlicher Intelligenz, produziert von Lisa Känzig, die Leitung hat Franziska Egli. Die Zusammenfassung gibt es schon bald in der SRF News App - ohne Einsatz von KI - noch. Und auf srf.ch. Den Blick hinter die Kulissen gibt es bei mir auf Instagram. Nächste Woche begrüsst Sie an dieser Stelle mein Kollege Mario Grossniklaus. Gute Nacht aus dem Studio 8.

[Unknown]: SWISS TXT / Accessibility Services Julia Böhm, Regina Kolb,