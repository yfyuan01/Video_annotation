WEBVTT

1
00:00:01.840 --> 00:00:04.080
<font color="#00ffff">Künstliche Intelligenz, KI:</font>

2
00:00:04.160 --> 00:00:07.040
<font color="#00ffff">für die einen die wichtigste techno-</font>
<font color="#00ffff">logische Erfindung der Menschheit.</font>

3
00:00:07.120 --> 00:00:09.200
<font color="#00ffff">Für die anderen eine reale Gefahr,</font>

4
00:00:09.280 --> 00:00:11.400
<font color="#00ffff">die Kontrolle über die Maschinen</font>
<font color="#00ffff">zu verlieren.</font>

5
00:00:11.480 --> 00:00:14.320
<font color="#00ffff">KI und wir -</font>
<font color="#00ffff">was bringt es uns, was nicht?</font>

6
00:00:14.400 --> 00:00:17.040
<font color="#00ffff">Über das müssen wir reden.</font>

7
00:00:26.000 --> 00:00:29.880
<font color="#ffffff">Mit Live-Untertiteln von SWISS TXT</font>

8
00:00:29.960 --> 00:00:32.159
Heute in der "Arena":

9
00:00:32.240 --> 00:00:35.440
Pascal Kaufmann, KI-Unternehmer
und Neurowissenschaftler.

10
00:00:35.520 --> 00:00:39.240
Er sagt: "Künstliche Intelligenz
bietet enorme Chancen."

11
00:00:39.320 --> 00:00:42.600
"Die Schweiz ist weltweit führend
in der Forschung."

12
00:00:42.680 --> 00:00:45.000
"Das müssen wir nutzen."

13
00:00:45.080 --> 00:00:48.160
"Dabei hilft
eine liberale Gesetzgebung."

14
00:00:48.240 --> 00:00:53.000
Peter G. Kirchschläger, Ethiker
Universität Luzern und ETH Zürich,

15
00:00:53.080 --> 00:00:56.760
sagt: "Weil künstliche Intelligenz
auch mit Risiken verbunden ist,

16
00:00:56.840 --> 00:00:59.120
muss sie reguliert werden."

17
00:00:59.200 --> 00:01:01.400
"Die Einhaltung der Menschenrechte
ist zentral,

18
00:01:01.480 --> 00:01:04.879
um das Vertrauen in die Technologie
zu stärken."

19
00:01:04.959 --> 00:01:08.440
Monika Rühl,
Direktorin economiesuisse, sagt:

20
00:01:08.520 --> 00:01:12.120
"KI ist eine Riesenchance
für Gesellschaft und Wirtschaft."

21
00:01:12.200 --> 00:01:16.760
"Wenn wir diese mutig nutzen,
profitiert auch die Arbeitswelt."

22
00:01:16.840 --> 00:01:21.680
"Die Schweiz ist dafür in
einer exzellenten Ausgangsposition."

23
00:01:21.760 --> 00:01:25.760
Mirjam Hostetmann,
Präsidentin Juso, sagt:

24
00:01:25.840 --> 00:01:28.440
"Wir dürfen die Entwicklung
von KI-Technologien

25
00:01:28.480 --> 00:01:31.960
nicht privaten, profitorientierten
Techfirmen überlassen."

26
00:01:32.039 --> 00:01:34.560
"Diese Firmen müssen verstaatlicht

27
00:01:34.640 --> 00:01:37.680
und zu voller Transparenz
verpflichtet werden."

28
00:01:37.759 --> 00:01:39.920
Ausserdem im Studio:

29
00:01:40.000 --> 00:01:44.520
Marcel Salathé, Co-Direktor
KI-Zentrum EPFL Lausanne

30
00:01:44.600 --> 00:01:46.840
und Epidemiologe.

31
00:01:46.920 --> 00:01:50.759
Die "Arena" -
moderiert von Sandro Brotz.

32
00:01:50.840 --> 00:01:54.240
<font color="#00ffff">Guten Abend, herzlich willkommen,</font>
<font color="#00ffff">liebe Zuschauer/-innen.</font>

33
00:01:54.320 --> 00:01:57.039
<font color="#00ffff">Vielen Dank.</font>

34
00:01:57.120 --> 00:02:02.800
<font color="#00ffff">Herzlich willkommen zu Hause,</font>
<font color="#00ffff">in dieser Runde und im Publikum.</font>

35
00:02:02.880 --> 00:02:06.200
<font color="#00ffff">Wir haben u.a. junge Menschen</font>
<font color="#00ffff">von der Fachmittelschule Muttenz,</font>

36
00:02:06.280 --> 00:02:09.240
<font color="#00ffff">vom Bildungszentrum für Wirtschaft</font>
<font color="#00ffff">in Weinfelden</font>

37
00:02:09.320 --> 00:02:12.280
<font color="#00ffff">und von den Kantis Frauenfeld</font>
<font color="#00ffff">und Zürich Oberland.</font>

38
00:02:12.360 --> 00:02:16.200
<font color="#00ffff">Ist Ihnen am Anfang dieser Sendung</font>
<font color="#00ffff">etwas aufgefallen?</font>

39
00:02:16.280 --> 00:02:18.400
<font color="#00ffff">Da hat doch irgendetwas</font>
<font color="#00ffff">nicht gestimmt</font>

40
00:02:18.480 --> 00:02:20.680
<font color="#00ffff">mit dem seltsamen Moderator.</font>

41
00:02:20.760 --> 00:02:23.079
<font color="#00ffff">Schauen wir uns doch noch einmal</font>
<font color="#00ffff">kurz den Ausschnitt an.</font>

42
00:02:23.160 --> 00:02:25.840
<font color="#00ffff">KI und wir - was bringt das uns,</font>
<font color="#00ffff">was nicht?</font>

43
00:02:25.920 --> 00:02:28.240
<font color="#00ffff">Darüber müssen wir reden.</font>

44
00:02:28.360 --> 00:02:30.920
<font color="#00ffff">Der Anfang dieser "Arena"</font>
<font color="#00ffff">war KI-generiert,</font>

45
00:02:31.000 --> 00:02:33.320
<font color="#00ffff">also von künstlicher Intelligenz.</font>

46
00:02:33.400 --> 00:02:35.640
<font color="#00ffff">Erstellt wurde der Ausschnitt</font>
<font color="#00ffff">mit einem einzigen Bild</font>

47
00:02:35.720 --> 00:02:37.880
<font color="#00ffff">aus dem Internet und meiner Stimme,</font>

48
00:02:37.960 --> 00:02:40.079
<font color="#00ffff">die man natürlich</font>
<font color="#00ffff">in früheren Sendungen findet.</font>

49
00:02:40.160 --> 00:02:43.800
<font color="#00ffff">All das kann man mit einem einfachen</font>
<font color="#00ffff">Programm per Knopfdruck machen.</font>

50
00:02:43.880 --> 00:02:46.760
<font color="#00ffff">Irgendetwas hat nicht gestimmt,</font>
<font color="#00ffff">ich trage keinen Ring.</font>

51
00:02:46.840 --> 00:02:49.960
<font color="#00ffff">Vermutlich denkt die KI,</font>
<font color="#00ffff">dass jemand, der einen Anzug trägt,</font>

52
00:02:50.040 --> 00:02:53.600
<font color="#00ffff">automatisch auch einen Ring</font>
<font color="#00ffff">tragen muss. Ich weiss es nicht.</font>

53
00:02:53.680 --> 00:02:57.200
<font color="#00ffff">Eine diese Woche</font>
<font color="#00ffff">veröffentlichte Untersuchung</font>

54
00:02:57.280 --> 00:03:01.320
<font color="#00ffff">der Universität Zürich zeigt,</font>
<font color="#00ffff">dass 54 % der Befragten KI nutzen,</font>

55
00:03:01.400 --> 00:03:07.720
<font color="#00ffff">obwohl es Tools wie ChatGPT</font>
<font color="#00ffff">erst seit zwei Jahren gibt.</font>

56
00:03:07.800 --> 00:03:11.560
<font color="#00ffff">Weil wir junge Menschen hier haben,</font>
<font color="#00ffff">möchte ich einmal nachfragen.</font>

57
00:03:11.640 --> 00:03:14.480
<font color="#00ffff">Gehört ChatGPT bei Ihnen</font>
<font color="#00ffff">bereits zum Alltag?</font>

58
00:03:14.560 --> 00:03:16.640
<font color="#ffff00">Ja, v.a. in der Schule.</font>

59
00:03:16.720 --> 00:03:19.040
<font color="#ffff00">Ich benutze es häufig</font>
<font color="#ffff00">für Hausaufgaben</font>

60
00:03:19.120 --> 00:03:23.040
<font color="#ffff00">oder auch zum Lernen vor einer</font>
<font color="#ffff00">Prüfung. Damit fülle ich Lücken auf.</font>

61
00:03:23.120 --> 00:03:25.760
<font color="#00ffff">Wie ist es bei Ihnen?</font>

62
00:03:25.840 --> 00:03:29.360
<font color="#008000">Ich benutze es tagtäglich, v.a.</font>
<font color="#008000">in der Vorbereitung auf Prüfungen.</font>

63
00:03:29.440 --> 00:03:32.120
<font color="#008000">Wenn man viel Stoff lernen muss,</font>

64
00:03:32.200 --> 00:03:36.480
<font color="#008000">kann man ihn</font>
<font color="#008000">mit diesen Tools zusammenfassen.</font>

65
00:03:36.560 --> 00:03:38.880
<font color="#00ffff">Da muss ich Sie also nicht fragen,</font>

66
00:03:38.960 --> 00:03:41.840
<font color="#00ffff">ob KI eher eine Chance</font>
<font color="#00ffff">oder ein Risiko ist?</font>

67
00:03:41.920 --> 00:03:44.120
<font color="#008000">Für mich ist es definitiv</font>
<font color="#008000">eine Chance.</font>

68
00:03:44.200 --> 00:03:46.200
<font color="#ffff00">Für mich auch.</font>

69
00:03:46.280 --> 00:03:48.440
<font color="#00ffff">Zwei junge Stimmen.</font>
<font color="#00ffff">Wir werden heute noch viele hören.</font>

70
00:03:48.520 --> 00:03:49.760
<font color="#00ffff">Dankeschön.</font>

71
00:03:49.840 --> 00:03:52.800
<font color="#00ffff">Wir sind bereits bei der</font>
<font color="#00ffff">Ausgangslage der heutigen Sendung.</font>

72
00:03:52.880 --> 00:03:56.640
<font color="#00ffff">Die "Arena" anlässlich</font>
<font color="#00ffff">der SRF-Themenwoche KI.</font>

73
00:03:56.720 --> 00:03:59.800
<font color="#00ffff">Heute diskutieren wir</font>
<font color="#00ffff">in einer gemischten Runde</font>

74
00:03:59.880 --> 00:04:05.520
<font color="#00ffff">mit Vertreter/-innen der Politik,</font>
<font color="#00ffff">Wirtschaft, Ethik und Forschung.</font>

75
00:04:05.600 --> 00:04:07.560
<font color="#00ffff">Monika Rühl,</font>

76
00:04:07.640 --> 00:04:10.200
<font color="#00ffff">Direktorin des Wirtschafts-</font>
<font color="#00ffff">dachverbands economiesuisse:</font>

77
00:04:10.280 --> 00:04:13.920
<font color="#00ffff">Was lösen die beiden Buchstaben</font>
<font color="#00ffff">K und I bei Ihnen persönlich aus?</font>

78
00:04:14.000 --> 00:04:17.600
Begeisterung.
Ich finde KI eine ganz tolle Sache.

79
00:04:17.680 --> 00:04:20.680
Ich bin nicht mehr ganz 20,

80
00:04:20.760 --> 00:04:23.560
aber wir haben damit
eine riesige Herausforderung

81
00:04:23.640 --> 00:04:26.440
und gleichzeitig
eine riesige Chance.

82
00:04:26.520 --> 00:04:29.560
Wir betreten eine neue Welt
und haben die Chance,

83
00:04:29.640 --> 00:04:31.680
all das zu erleben.

84
00:04:31.760 --> 00:04:33.720
Die Schweiz
ist extrem gut aufgestellt,

85
00:04:33.800 --> 00:04:35.880
wir haben alle Voraussetzungen,

86
00:04:35.960 --> 00:04:38.240
diese Reise gemeinsam
zu unternehmen.

87
00:04:38.320 --> 00:04:41.400
Und das zu unser aller Gewinn,
der Gesellschaft und Wirtschaft.

88
00:04:41.480 --> 00:04:43.560
Ich bin begeistert.

89
00:04:43.640 --> 00:04:45.800
<font color="#00ffff">Peter G. Kirchschläger,</font>
<font color="#00ffff">Ethikprofessor,</font>

90
00:04:45.880 --> 00:04:48.040
<font color="#00ffff">u.a. Leiter des Instituts</font>
<font color="#00ffff">für Sozialethik</font>

91
00:04:48.120 --> 00:04:50.280
<font color="#00ffff">an der Universität Luzern.</font>

92
00:04:50.360 --> 00:04:53.480
<font color="#00ffff">Die grosse Frage gleich zum Anfang:</font>
<font color="#00ffff">Ist KI ein Segen oder ein Fluch?</font>

93
00:04:53.560 --> 00:04:56.680
<font color="#00ffff">Gehen Sie mit auf die</font>
<font color="#00ffff">von Frau Rühl beschriebene Reise?</font>

94
00:04:56.760 --> 00:05:00.240
Z.T. schon, es gibt durchaus
ein ethisch positives Potenzial

95
00:05:00.320 --> 00:05:03.520
der sog. KI.

96
00:05:03.600 --> 00:05:06.360
Gleichzeitig müssen wir auch ethisch
negative Risiken betrachten.

97
00:05:06.440 --> 00:05:08.640
Wir können so wie bisher
nicht weitermachen.

98
00:05:08.720 --> 00:05:11.240
Beides muss sehr präzise
identifiziert werden,

99
00:05:11.320 --> 00:05:13.480
um die ethischen Chancen zu fördern

100
00:05:13.560 --> 00:05:17.000
und die ethischen Risiken
zu minimieren

101
00:05:17.080 --> 00:05:20.640
oder auch wirklich zu vermeiden.
Ich gebe Ihnen ein Beispiel:

102
00:05:20.720 --> 00:05:24.320
Heute kann man eine Kinderbilder
sexualisierende App

103
00:05:24.400 --> 00:05:28.040
auf den Markt bringen,
so etwas Widerliches,

104
00:05:28.120 --> 00:05:31.480
und das als legal
eingetragenes Unternehmen.

105
00:05:31.560 --> 00:05:33.880
Das einzige was passiert, ist,

106
00:05:33.960 --> 00:05:36.600
dass ich damit
unglaublich viel Geld verdiene.

107
00:05:36.680 --> 00:05:39.159
Hier gibt es Handlungsbedarf.

108
00:05:39.240 --> 00:05:41.520
<font color="#00ffff">Sie beschreiben ein Spannungsfeld,</font>

109
00:05:41.600 --> 00:05:44.120
<font color="#00ffff">und das geht dann wieder</font>
<font color="#00ffff">in Richtung der Regulierung.</font>

110
00:05:44.200 --> 00:05:46.440
<font color="#00ffff">Das wird ein wichtiges Thema</font>
<font color="#00ffff">in dieser Sendung.</font>

111
00:05:46.520 --> 00:05:48.560
<font color="#00ffff">Ich begrüsse ebenfalls</font>
<font color="#00ffff">Pascal Kaufmann,</font>

112
00:05:48.640 --> 00:05:50.840
<font color="#00ffff">KI-Unternehmer</font>
<font color="#00ffff">und Neurowissenschaftler.</font>

113
00:05:50.920 --> 00:05:53.640
<font color="#00ffff">Geben Sie uns eine Vorstellung</font>
<font color="#00ffff">Ihres Unternehmens:</font>

114
00:05:53.720 --> 00:05:56.560
<font color="#00ffff">Woran arbeiten Sie in Ihrem</font>
<font color="#00ffff">Unternehmen gerade ganz konkret</font>

115
00:05:56.640 --> 00:05:59.520
<font color="#00ffff">im Zusammenhang</font>
<font color="#00ffff">mit der viel zitierten KI?</font>

116
00:05:59.600 --> 00:06:02.160
Wir bauen an SwissGPT.

117
00:06:02.240 --> 00:06:04.720
Wir finden es nicht so gut,
wenn alle auf ChatGPT setzen.

118
00:06:04.800 --> 00:06:07.160
In der Schweiz verfügen wir
über das Know-how

119
00:06:07.240 --> 00:06:09.520
und ziehen Talente
aus der ganzen Welt an.

120
00:06:09.600 --> 00:06:12.000
Das Beste Know-how
aus den USA und aus China

121
00:06:12.080 --> 00:06:14.240
können wir hier kombinieren.

122
00:06:14.320 --> 00:06:16.360
Mit unseren Produkten
und Technologien

123
00:06:16.440 --> 00:06:18.720
können wir eine Führungsposition
in der Welt übernehmen.

124
00:06:18.800 --> 00:06:21.800
<font color="#00ffff">Was verändert sich für mich, wenn</font>
<font color="#00ffff">ich SwissGPT statt ChatGPT nutze?</font>

125
00:06:21.880 --> 00:06:23.920
Z.B. ist SwissGPT legal.

126
00:06:24.040 --> 00:06:26.320
Wenn Sie z.B. in einem Spital
arbeiten und Medizinalakten

127
00:06:26.400 --> 00:06:28.600
durch ChatGPT schicken würden,
wäre das nicht so gut.

128
00:06:28.680 --> 00:06:30.680
Das gilt ebenfalls für Behörden

129
00:06:30.760 --> 00:06:32.760
oder andere
hochregulierte Umgebungen.

130
00:06:32.840 --> 00:06:35.000
Dort sollten Sie ChatGPT
nicht verwenden.

131
00:06:35.080 --> 00:06:37.240
<font color="#00ffff">Mirjam Hostetmann,</font>
<font color="#00ffff">Präsidentin der JUSO -</font>

132
00:06:37.320 --> 00:06:40.720
<font color="#00ffff">Sehen Sie neben all den Risiken,</font>
<font color="#00ffff">die es so gibt, auch Chancen?</font>

133
00:06:40.800 --> 00:06:43.480
Absolut,
ich sehe sehr viele Chancen.

134
00:06:43.560 --> 00:06:46.040
KI kann uns helfen,

135
00:06:46.120 --> 00:06:49.120
unser Zusammenleben
besser zu organisieren.

136
00:06:49.200 --> 00:06:53.320
Ich sehe eine Chance bei der
Unterstützung von Menschen.

137
00:06:53.400 --> 00:06:56.240
<font color="#00ffff">Unterstützung von Menschen -</font>
<font color="#00ffff">und Sie möchten Geld damit machen?</font>

138
00:06:56.320 --> 00:06:59.800
Wir möchten Geld damit machen,
indem wir etwas bauen,

139
00:06:59.880 --> 00:07:02.040
was der Kunde möchte.

140
00:07:02.120 --> 00:07:04.760
Es ist ein gutes Zeichen,
wenn Kunden bereit sind,

141
00:07:04.840 --> 00:07:07.440
Geld dafür zu bezahlen. Dann baut
man etwas, was der Markt braucht.

142
00:07:07.520 --> 00:07:09.800
Das sehe ich anders.

143
00:07:09.880 --> 00:07:14.080
Es ist ein riesiges Problem, dass
alles darauf ausgerichtet ist,

144
00:07:14.160 --> 00:07:16.360
mit KI Profit zu machen.

145
00:07:16.440 --> 00:07:21.000
Das sind v.a. die fünf
grossen Big-Tech-Firmen,

146
00:07:21.080 --> 00:07:23.880
die mit KI
maximalen Profit scheffeln,

147
00:07:23.960 --> 00:07:26.640
während wir keine Ahnung haben,

148
00:07:26.720 --> 00:07:29.760
was mit unseren Daten passiert,
an wen sie weitergegeben werden.

149
00:07:29.840 --> 00:07:32.760
Das ist ein grosses Risiko für uns
und unsere Demokratie.

150
00:07:32.840 --> 00:07:36.800
Das kann ganze politische Systeme
destabilisieren.

151
00:07:36.880 --> 00:07:42.280
Das ist ein grosses Risiko.

152
00:07:42.360 --> 00:07:45.200
<font color="#00ffff">Kurz die Replik,</font>
<font color="#00ffff">bevor wir einen Schritt weitergehen.</font>

153
00:07:45.280 --> 00:07:47.840
Das Monopol
ist deswegen problematisch,

154
00:07:47.920 --> 00:07:50.520
weil wir offenbar in Europa so
schlechte Software entwickeln,

155
00:07:50.600 --> 00:07:53.360
dass alle doch wieder auf WhatsApp
oder ChatGPT zurückgreifen.

156
00:07:53.440 --> 00:07:55.840
Die Ursache eines Monopols
ist eigentlich,

157
00:07:55.920 --> 00:07:58.200
dass es nicht so viele andere
Konkurrenzprodukte gibt.

158
00:07:58.280 --> 00:08:00.320
Dabei hätten wir
ausreichend Kompetenz,

159
00:08:00.400 --> 00:08:02.440
solche Tools
auch in Europa zu bauen.

160
00:08:02.520 --> 00:08:04.560
Dann gäbe es auch
diese Monopole nicht mehr.

161
00:08:04.640 --> 00:08:06.760
Der Staat könnte dabei schon
eine Rolle spielen.

162
00:08:06.840 --> 00:08:09.200
Wenn auffällt, dass es
in einem Markt ein Monopol gibt -

163
00:08:09.280 --> 00:08:11.440
und bei den Suchmaschinen
hatten sie 25-30 Jahre Zeit,

164
00:08:11.520 --> 00:08:13.960
das zu merken -, könnte man
schon einmal intervenieren.

165
00:08:14.040 --> 00:08:16.160
Das ist nicht einmal
nur eine ethische,

166
00:08:16.240 --> 00:08:18.360
sondern auch eine
ökonomische Überlegung.

167
00:08:18.440 --> 00:08:20.760
Alle, nicht nur die Konsument/-innen
und Nutzer/-innen,

168
00:08:20.840 --> 00:08:23.000
sondern auch die Unternehmen,

169
00:08:23.080 --> 00:08:25.400
sollten sich eigentlich
nicht ausbeuten lassen müssen

170
00:08:25.480 --> 00:08:28.240
von diesen fünf bis neun multi-
nationalen Technologiekonzernen.

171
00:08:28.320 --> 00:08:30.920
Ein freier Markt funktioniert
allerdings gerade ohne

172
00:08:31.000 --> 00:08:33.720
oder mit möglichst geringer
staatliche Intervention.

173
00:08:33.799 --> 00:08:39.000
Der Staat ist nicht zwingend
ein guter wirtschaftlicher Akteur.

174
00:08:39.080 --> 00:08:41.799
Welches Know-how hat der Staat?

175
00:08:41.880 --> 00:08:44.800
Das Know-how
liegt bei den Unternehmen,

176
00:08:44.880 --> 00:08:47.720
bei denen fünf grossen
und bei vielen anderen.

177
00:08:47.800 --> 00:08:51.600
Es ist nicht so, dass nur diese
vier oder fünf grossen Techfirmen

178
00:08:51.680 --> 00:08:54.280
dieses Know-how haben.

179
00:08:54.360 --> 00:08:59.600
Das haben auch viele weitere
Akteure, u.a. in der Wissenschaft.

180
00:08:59.680 --> 00:09:04.560
Mich stört Verteufelung
der wirtschaftlichen Kräfte,

181
00:09:04.640 --> 00:09:08.120
die hier spielen, denn es besteht
eine ganz klare Nachfrage

182
00:09:08.200 --> 00:09:11.560
und eine Nachfrage
generiert ein Angebot.

183
00:09:11.640 --> 00:09:14.240
Das sind die Kräfte des Marktes.

184
00:09:14.320 --> 00:09:17.080
Das ist keine Verteufelung
der Wirtschaft, im Gegenteil.

185
00:09:17.160 --> 00:09:19.440
Eigentlich müssen wir uns
um unseren Markt kümmern.

186
00:09:19.520 --> 00:09:22.000
Es kann in einem Markt
zu Monopolbildungen kommen.

187
00:09:22.080 --> 00:09:24.560
Etwas wie das Suchmaschinenmonopol

188
00:09:24.640 --> 00:09:27.040
wird sich nicht
von alleine auflösen.

189
00:09:27.120 --> 00:09:29.960
Wenn wir das träumen,
wird es ein Albtraum.

190
00:09:30.040 --> 00:09:33.040
Wir müssen aus dieser Situation
wieder herauskommen

191
00:09:33.120 --> 00:09:35.920
und zwar im Dienste
der wirtschaftlichen Kräfte.

192
00:09:36.000 --> 00:09:39.000
Der Markt wird es aber
nicht alleine bewerkstelligen,

193
00:09:39.080 --> 00:09:41.880
dass wir z.B. aus dem
Suchmaschinenmonopols rauskommen.

194
00:09:41.960 --> 00:09:44.200
Das ist eine Illusion.

195
00:09:44.280 --> 00:09:46.920
Die letzten 25, 30 Jahren haben wir
das beobachtet und gemerkt:

196
00:09:47.000 --> 00:09:49.080
Es wird nicht funktionieren.

197
00:09:49.160 --> 00:09:51.240
Da gibt es Handlungsbedarf,
wie auch bei den Biases,

198
00:09:51.320 --> 00:09:53.400
mit denen wir zu tun haben.

199
00:09:53.520 --> 00:09:56.680
In den Niederlanden beispielsweise
verhielt sich eine sog. KI

200
00:09:56.760 --> 00:09:58.880
diskriminierend.

201
00:09:59.000 --> 00:10:01.840
Menschen, die über Jahre Kinder-
betreuungsgelder bezogen haben,

202
00:10:01.920 --> 00:10:03.960
mussten diese plötzlich
wieder zurückzahlen,

203
00:10:04.040 --> 00:10:06.200
nur, weil die KI
diskriminierend war.

204
00:10:06.280 --> 00:10:08.760
Wir können nicht so tun, als ob es
diese Probleme nicht gäbe.

205
00:10:08.840 --> 00:10:11.480
Es gibt natürlich insbesondere
in der Forschung riesige Chancen.

206
00:10:11.560 --> 00:10:13.680
Bei der EPFL, bei der ETH Zürich -
fantastisch.

207
00:10:13.760 --> 00:10:16.280
Aber wir können nicht so tun,
als gäbe es die Probleme nicht.

208
00:10:16.360 --> 00:10:18.360
Das halte ich für unverantwortlich.

209
00:10:18.440 --> 00:10:21.680
<font color="#00ffff">Es geht ja schon fast mehr ab</font>
<font color="#00ffff">als in einer regulären "Arena".</font>

210
00:10:21.760 --> 00:10:24.160
<font color="#00ffff">Herr Kirchschläger erwähnte Bias -</font>

211
00:10:24.240 --> 00:10:27.360
<font color="#00ffff">wenn es also zu Vorurteilen</font>
<font color="#00ffff">oder Diskriminierung kommt -</font>

212
00:10:27.440 --> 00:10:29.800
<font color="#00ffff">darüber werden wir sprechen.</font>

213
00:10:29.880 --> 00:10:32.280
<font color="#00ffff">Wir werden auch über</font>
<font color="#00ffff">die Wirtschaftlichkeit reden.</font>

214
00:10:32.360 --> 00:10:34.920
<font color="#00ffff">Aber er hat soeben den Pass</font>
<font color="#00ffff">schön an die EPFL weitergegeben.</font>

215
00:10:35.000 --> 00:10:37.080
<font color="#00ffff">Das ist mein Stichwort.</font>

216
00:10:37.160 --> 00:10:39.960
<font color="#00ffff">"Die KI ist die wichtigste techno-</font>
<font color="#00ffff">logische Erfindung der Menschheit."</font>

217
00:10:40.040 --> 00:10:42.800
<font color="#00ffff">Das sage nicht ich,</font>
<font color="#00ffff">sondern ein Mann,</font>

218
00:10:42.880 --> 00:10:46.080
<font color="#00ffff">der bei uns heute Abend</font>
<font color="#00ffff">eine Expertenrolle einnimmt</font>

219
00:10:46.160 --> 00:10:49.320
<font color="#00ffff">und sich von der Vis-à-Vis-Position</font>

220
00:10:49.400 --> 00:10:52.320
<font color="#00ffff">immer mal wieder</font>
<font color="#00ffff">in die Debatte einschalten wird.</font>

221
00:10:52.400 --> 00:10:54.760
<font color="#00ffff">Marcel Salathé ist Professor</font>
<font color="#00ffff">an der EPFL Lausanne</font>

222
00:10:54.840 --> 00:10:57.160
<font color="#00ffff">und Co-Chef</font>
<font color="#00ffff">des dortigen neuen KI-Zentrums.</font>

223
00:10:57.240 --> 00:10:59.560
<font color="#00ffff">Sie kennen ihn wahrscheinlich noch</font>
<font color="#00ffff">als Epidemiologen</font>

224
00:10:59.640 --> 00:11:02.760
<font color="#00ffff">und Gesicht aus der Corona-Zeit.</font>
<font color="#00ffff">Heute ist aber KI das Thema.</font>

225
00:11:02.840 --> 00:11:05.320
<font color="#00ffff">Ich habe von Ihnen gelesen,</font>

226
00:11:05.400 --> 00:11:07.800
<font color="#00ffff">dass sie ChatGPT</font>
<font color="#00ffff">am Tag 40-50-mal benutzen. Wofür?</font>

227
00:11:07.880 --> 00:11:11.560
<font color="#008000">Ja, mind. so oft</font>
<font color="#008000">und für alle möglichen Zwecke.</font>

228
00:11:11.640 --> 00:11:15.080
<font color="#008000">Um Fragen zu stellen,</font>
<font color="#008000">um mir Wissen zu holen.</font>

229
00:11:15.160 --> 00:11:18.480
<font color="#008000">Ich verbessere Texte damit, mache</font>
<font color="#008000">Analysen und generiere Bilder.</font>

230
00:11:18.560 --> 00:11:20.960
<font color="#008000">Eigentlich nonstop.</font>

231
00:11:21.000 --> 00:11:23.520
<font color="#00ffff">Warum sind Sie sicher, dass die</font>
<font color="#00ffff">Texte dadurch besser werden?</font>

232
00:11:23.600 --> 00:11:25.760
<font color="#008000">Ich habe das Original ja vor mir.</font>

233
00:11:25.840 --> 00:11:28.120
<font color="#008000">Ich kann ja beurteilen,</font>
<font color="#008000">ob es am Schluss besser ist.</font>

234
00:11:28.200 --> 00:11:31.040
<font color="#00ffff">Sie sagen, die künstliche</font>
<font color="#00ffff">Intelligenz bedeute eine Revolution,</font>

235
00:11:31.120 --> 00:11:34.280
<font color="#00ffff">die alle Bereiche betreffen wird.</font>
<font color="#00ffff">Wir schauen das noch vertieft an.</font>

236
00:11:34.360 --> 00:11:36.720
<font color="#00ffff">Um es zum Anfang aber</font>
<font color="#00ffff">auf den Punkt zu bringen:</font>

237
00:11:36.800 --> 00:11:39.960
<font color="#00ffff">Wo wird sich diese Revolution</font>
<font color="#00ffff">am meisten bemerkbar machen?</font>

238
00:11:40.040 --> 00:11:42.640
<font color="#008000">Überall.</font>

239
00:11:42.720 --> 00:11:45.680
<font color="#008000">Es ist eine ähnliche Revolution</font>
<font color="#008000">wie die Industrielle Revolution.</font>

240
00:11:45.760 --> 00:11:48.480
<font color="#008000">Man baute Maschinen,</font>

241
00:11:48.560 --> 00:11:51.480
<font color="#008000">die in ihrer Kraft der menschlichen</font>
<font color="#008000">Kraft weit überlegen waren.</font>

242
00:11:51.560 --> 00:11:54.600
<font color="#008000">Nun bauen wir Maschinen,</font>
<font color="#008000">die weit über das hinausgehen,</font>

243
00:11:54.680 --> 00:11:56.920
<font color="#008000">was die menschliche Intelligenz</font>
<font color="#008000">kann.</font>

244
00:11:57.000 --> 00:11:59.320
<font color="#008000">Da wir in einer Wissensgesellschaft</font>
<font color="#008000">leben,</font>

245
00:11:59.400 --> 00:12:01.760
<font color="#008000">wird die ganze Gesellschaft</font>
<font color="#008000">davon betroffen sein.</font>

246
00:12:01.840 --> 00:12:04.200
<font color="#00ffff">Vielen Dank für den Moment.</font>

247
00:12:04.280 --> 00:12:07.080
<font color="#00ffff">Bevor wir weiter in die Welt</font>
<font color="#00ffff">dieser KI-Technologie abtauchen,</font>

248
00:12:07.160 --> 00:12:09.600
<font color="#00ffff">und uns fragen, was sie</font>
<font color="#00ffff">für den Menschen bedeutet</font>

249
00:12:09.680 --> 00:12:11.880
<font color="#00ffff">und wo man vielleicht auch</font>
<font color="#00ffff">Grenzen setzen muss,</font>

250
00:12:11.960 --> 00:12:14.560
<font color="#00ffff">schauen wir uns zunächst</font>
<font color="#00ffff">ein Erklärvideo dazu an,</font>

251
00:12:14.640 --> 00:12:17.800
<font color="#00ffff">was KI eigentlich bedeutet.</font>

252
00:12:17.880 --> 00:12:20.840
KI - kurz
für künstliche Intelligenz -

253
00:12:20.920 --> 00:12:23.880
steht für Systeme,
die Aufgaben erledigen können,

254
00:12:23.960 --> 00:12:26.760
für die sonst
menschliche Fähigkeiten nötig wären.

255
00:12:26.840 --> 00:12:30.920
Damit eine KI funktioniert, muss sie
mit Daten trainiert werden -

256
00:12:31.000 --> 00:12:33.880
sog. maschinellen Lernen.

257
00:12:33.960 --> 00:12:37.000
Ein KI-System analysiert
eine grosse Menge an Daten

258
00:12:37.080 --> 00:12:39.440
und findet selbständig Muster.

259
00:12:39.520 --> 00:12:42.520
Für das Training
und die Anwendung der KI

260
00:12:42.600 --> 00:12:45.360
werden oft
grosse Rechenzentren benötigt.

261
00:12:45.440 --> 00:12:49.880
Schon heute kommt
künstliche Intelligenz zum Einsatz.

262
00:12:49.960 --> 00:12:53.000
Beispielsweise
im Verkehr von San Francisco -

263
00:12:53.080 --> 00:12:57.760
mit selbstfahrenden Autos als Taxis.

264
00:12:58.240 --> 00:13:01.480
In der Medizin kann KI Ärztinnen
und Ärzte dabei unterstützen,

265
00:13:01.560 --> 00:13:05.120
Krankheiten zu erkennen, z.B. Krebs.

266
00:13:05.200 --> 00:13:09.000
Eine bekannte KI ist ChatGPT.

267
00:13:09.080 --> 00:13:13.040
Dieser sog. Chatbot kann in Form
einer natürlichen Unterhaltung

268
00:13:13.120 --> 00:13:15.560
Fragen beantworten,
Informationen suchen,

269
00:13:15.640 --> 00:13:19.560
Texte verfassen und bearbeiten
oder Bilder generieren.

270
00:13:19.640 --> 00:13:24.400
Künstliche Intelligenz
wird nebst zivilen Zwecken

271
00:13:24.480 --> 00:13:27.680
auch für militärische Absichten
eingesetzt:

272
00:13:27.760 --> 00:13:35.320
Im Ukrainekrieg sollen z.B. auch
KI-Drohnen zum Einsatz kommen.

273
00:13:35.400 --> 00:13:37.560
Wie wird die künstliche Intelligenz

274
00:13:37.640 --> 00:13:41.400
die Zukunft
von uns allen beeinflussen?

275
00:13:41.480 --> 00:13:46.080
<font color="#00ffff">Die KI wird natürlich einen grossen</font>
<font color="#00ffff">Einfluss auf die Arbeitswelt haben.</font>

276
00:13:46.160 --> 00:13:51.760
<font color="#00ffff">In einer Studie der economiesuisse,</font>
<font color="#00ffff">einem sog. Whitepaper, heisst es:</font>

277
00:13:59.960 --> 00:14:03.000
<font color="#00ffff">Wenn ich optimieren höre, Frau Rühl,</font>
<font color="#00ffff">klingt das durchaus positiv,</font>

278
00:14:03.080 --> 00:14:06.520
<font color="#00ffff">aber übersetzt heisst das doch:</font>
<font color="#00ffff">mehr KI, weniger Arbeitsplätze.</font>

279
00:14:06.600 --> 00:14:10.680
Das kann es heissen,
muss es aber nicht.

280
00:14:10.760 --> 00:14:14.360
Es heisst effizienter werden,
die Produktivität steigern,

281
00:14:14.440 --> 00:14:17.800
damit man
die so freigespielten Arbeitskräfte

282
00:14:17.880 --> 00:14:20.640
anderswo einsetzen kann.

283
00:14:20.720 --> 00:14:24.920
Für die Arbeitsmarktdiskussion
finde ich es wichtig,

284
00:14:25.000 --> 00:14:27.560
dass wir sie
als Chancendiskussion führen.

285
00:14:27.640 --> 00:14:30.280
Es wird immer argumentiert,

286
00:14:30.360 --> 00:14:32.920
wenn Unternehmen aus dem Ausland
in die Schweiz kommen

287
00:14:33.000 --> 00:14:35.080
und Arbeitsplätze schaffen,

288
00:14:35.160 --> 00:14:37.480
dass das - oh Hilfe -
Zuwanderung mit sich bringt.

289
00:14:37.560 --> 00:14:39.720
Und dann sieht man
Risiken ohne Ende.

290
00:14:39.800 --> 00:14:42.560
Doch wir haben eigentlich Chancen,
effizienter zu werden,

291
00:14:42.640 --> 00:14:46.440
die Produktivität zu steigern
und Arbeitsplätze einzusparen.

292
00:14:46.520 --> 00:14:49.480
Auch da heisst es wieder,
das seien Risiken.

293
00:14:49.560 --> 00:14:53.480
Wir haben aber auch
eine andere Studie durchgeführt,

294
00:14:53.560 --> 00:14:56.080
laut der uns bis in 10 Jahren
für benötigte Arbeitsplätze

295
00:14:56.160 --> 00:14:58.480
460'000 Menschen fehlen.

296
00:14:58.600 --> 00:15:01.600
Diese Menschen
können wir über KI ersetzen

297
00:15:01.680 --> 00:15:04.640
und die Arbeitsplätze
in der Schweiz halten.

298
00:15:04.720 --> 00:15:08.040
Das ist schliesslich unser Ziel.

299
00:15:08.080 --> 00:15:11.320
<font color="#00ffff">Eine Studie, die ich mir diese Woche</font>
<font color="#00ffff">u.a. angeschaut habe, sagt,</font>

300
00:15:11.400 --> 00:15:14.440
<font color="#00ffff">das KI bis zu 3,9 Mio. Arbeitsplätze</font>
<font color="#00ffff">beeinflusst</font>

301
00:15:14.520 --> 00:15:17.480
<font color="#00ffff">und dass 8 % der heute</font>
<font color="#00ffff">bestehenden Arbeitsplätze</font>

302
00:15:17.600 --> 00:15:20.800
<font color="#00ffff">durch generative KI,</font>
<font color="#00ffff">wie z.B. ChatGPT,</font>

303
00:15:20.880 --> 00:15:24.000
<font color="#00ffff">ganz oder teilweise wegfallen.</font>
<font color="#00ffff">Ist das eine gute Entwicklung?</font>

304
00:15:24.080 --> 00:15:30.160
Das sind 8 %. Das bedeutet,
wir haben 92 % andere Fälle.

305
00:15:30.240 --> 00:15:34.280
Ein grosser Wert der KI,
an den ich fest glaube,

306
00:15:34.360 --> 00:15:39.280
ist die Zusammenarbeit
zwischen der KI und dem Menschen.

307
00:15:39.360 --> 00:15:44.880
Auch die Schülerin und der Schüler
haben es gesagt:

308
00:15:44.960 --> 00:15:49.360
Man fragt ChatGPT
nach Informationen,

309
00:15:49.440 --> 00:15:53.040
am Schluss muss doch immer der
Mensch verifizieren und prüfen,

310
00:15:53.120 --> 00:15:58.640
weil ChatGPT momentan noch immer
sehr viele Fehler macht.

311
00:15:58.720 --> 00:16:01.440
Zur Arbeitsplatzsituation:

312
00:16:01.520 --> 00:16:05.200
Ich finde die Synergien zwischen
Mensch und Maschine extrem spannend.

313
00:16:05.280 --> 00:16:09.520
<font color="#00ffff">Synergien, optimieren,</font>
<font color="#00ffff">Frau Hostetmann - machen Sie da mit?</font>

314
00:16:09.600 --> 00:16:12.080
Das klingt sehr harmonisch.

315
00:16:12.160 --> 00:16:14.640
Ich kann auch verstehen,
wo Sie die Chancen sehen,

316
00:16:14.720 --> 00:16:17.040
nämlich für die Unternehmen.

317
00:16:17.120 --> 00:16:19.680
Für die Angestellten
sieht es anders aus.

318
00:16:19.760 --> 00:16:22.640
40'000 Jobs stehen auf dem Spiel.

319
00:16:22.720 --> 00:16:26.400
Auch die Digitalisierung
wurde als grosse Chance betrachtet.

320
00:16:26.480 --> 00:16:29.080
Sie hat auch viel Gutes gebracht.

321
00:16:29.160 --> 00:16:33.120
Allerdings führte sie auch dazu,
dass es jetzt Firmen wie Uber gibt,

322
00:16:33.200 --> 00:16:36.160
die unser Sozialversicherungssystem
austricksen,

323
00:16:36.240 --> 00:16:39.800
Menschen in die
Scheinselbstständigkeit treiben.

324
00:16:39.880 --> 00:16:44.880
Das sind die Gefahren, die
von Ihnen einfach verdrängt werden.

325
00:16:44.960 --> 00:16:49.720
V.a. werden Sie ja dann
keine Arbeitszeitverkürzung

326
00:16:49.800 --> 00:16:52.920
bei gleich bleibendem Lohn
einführen,

327
00:16:53.000 --> 00:16:56.280
denn dann würden die Angestellten
tatsächlich davon profitieren.

328
00:16:56.360 --> 00:16:59.920
Aber das streben Sie
in Ihrer Utopie ja nicht an.

329
00:17:00.000 --> 00:17:06.079
Ich finde, künstliche Intelligenz
ist super für Arbeitnehmer/-innen.

330
00:17:06.160 --> 00:17:10.400
Es ist doch ideal,
wenn Roboter oder KI

331
00:17:10.480 --> 00:17:14.200
langweilige und repetitive
Routinearbeiten übernehmen.

332
00:17:14.280 --> 00:17:17.200
Dann gibt es eben 10 % weniger Jobs.

333
00:17:17.280 --> 00:17:19.720
Wenn wir dafür aber
20-30 % produktiver sind,

334
00:17:19.800 --> 00:17:23.079
ist das ein super Steuersubstrat.
Davon können alle profitieren.

335
00:17:23.160 --> 00:17:25.359
Und wieso sollte man nicht

336
00:17:25.440 --> 00:17:27.920
die Tagesarbeitszeit
von 8 Std. auf 6 Std. reduzieren,

337
00:17:28.000 --> 00:17:31.080
wenn man dabei
noch produktiver wird?

338
00:17:31.160 --> 00:17:34.200
Die Produktivitätsgewinne
müssen schliesslich irgendwohin.

339
00:17:34.280 --> 00:17:36.720
Sie sollten den Arbeitnehmer/-innen
weitergegeben werden.

340
00:17:36.800 --> 00:17:38.840
<font color="#00ffff">Habe ich das richtig verstanden:</font>

341
00:17:38.920 --> 00:17:41.080
<font color="#00ffff">Dank KI müssen wir</font>
<font color="#00ffff">in Zukunft weniger arbeiten?</font>

342
00:17:41.160 --> 00:17:43.440
<font color="#00ffff">Das ist doch eine tolle Sache,</font>
<font color="#00ffff">Herr Kirchschläger?</font>

343
00:17:43.520 --> 00:17:46.040
Aus ethischer Sicht wäre das
tatsächlich nicht so schlecht.

344
00:17:46.120 --> 00:17:48.320
Die Problemlage
ist allerdings anders.

345
00:17:48.400 --> 00:17:50.480
Das Problem ist, dass wir so tun,

346
00:17:50.560 --> 00:17:52.840
als ginge alles
so weiter wie bisher,

347
00:17:52.920 --> 00:17:55.760
und das nur ein paar bezahlte
berufliche Aufgaben wegfallen.

348
00:17:55.840 --> 00:17:58.040
In Wirklichkeit wird es aber
zu einer massiven Reduktion

349
00:17:58.120 --> 00:18:00.320
bezahlter beruflicher Aufgaben
kommen,

350
00:18:00.400 --> 00:18:02.440
weil das die Zielsetzung ist.

351
00:18:02.520 --> 00:18:05.000
Man möchte mit KI ja Menschen
am Arbeitsplatz ersetzen,

352
00:18:05.080 --> 00:18:08.960
und nicht ihnen
die Arbeit erleichtern.

353
00:18:09.040 --> 00:18:12.640
Man will sie wegbekommen und es
betrifft alle beruflichen Aufgaben.

354
00:18:12.720 --> 00:18:15.520
Das verstärkt den Effekt noch.
Wenn Arbeitsplätze wegfallen,

355
00:18:15.600 --> 00:18:17.960
muss das nicht von Anfang an
eine schlechte Nachricht sein,

356
00:18:18.040 --> 00:18:20.160
auch nicht aus ethischer Sicht.

357
00:18:20.240 --> 00:18:22.240
Schlecht ist,
wenn man weiterhin vorgibt,

358
00:18:22.320 --> 00:18:24.280
nach Vollbeschäftigung zu streben,

359
00:18:24.360 --> 00:18:26.560
dies aber nicht
die Wirklichkeit ist.

360
00:18:26.640 --> 00:18:28.720
Wir stehen
vor einer systemischen Veränderung.

361
00:18:28.800 --> 00:18:30.840
Ich höre oft Politiker/-innen

362
00:18:30.920 --> 00:18:33.480
und Entscheidungsträger/-innen
in Wirtschaft und Gesellschaft,

363
00:18:33.560 --> 00:18:35.600
die sagen, man müsse sich
einfach nur weiterbilden

364
00:18:35.680 --> 00:18:37.880
und sich für die Veränderung
fit machen -

365
00:18:37.960 --> 00:18:40.080
das geht in meinen Augen so nicht.

366
00:18:40.160 --> 00:18:42.240
Man kann nicht
ein systemisches Problem

367
00:18:42.320 --> 00:18:44.360
auf den Schultern der Individuen
ablegen.

368
00:18:44.440 --> 00:18:46.520
Man muss es systemisch angehen.

369
00:18:46.600 --> 00:18:48.720
Z.B. müsste man das
Wirtschaftssystem so anpassen,

370
00:18:48.800 --> 00:18:51.600
dass es das Streben nach
Vollbeschäftigung nicht mehr gibt.

371
00:18:51.680 --> 00:18:53.880
<font color="#00ffff">Da macht wohl Frau Rühl nicht mit.</font>

372
00:18:53.960 --> 00:18:56.120
Teils, teils.

373
00:18:56.200 --> 00:18:58.760
Das Ziel ist sicher nicht,
Arbeitsplätze zu vernichten.

374
00:18:58.840 --> 00:19:01.080
Das wäre völlig falsch.

375
00:19:01.160 --> 00:19:04.240
In den nächsten zehn Jahren
sind wir damit konfrontiert,

376
00:19:04.320 --> 00:19:07.640
dass wir 460'000 Arbeitsplätze
nicht werden besetzen können.

377
00:19:07.720 --> 00:19:11.720
Das ist ja auch zyklisch bedingt.
Das kann sich auch wieder verändern.

378
00:19:11.800 --> 00:19:14.040
Ich finde das
ein schwieriges Argument.

379
00:19:14.120 --> 00:19:17.240
Bei einem automatisierten
Kassensystem frage ich mich schon,

380
00:19:17.320 --> 00:19:19.760
wo da der Job entsteht.

381
00:19:19.840 --> 00:19:22.000
<font color="#00ffff">Lassen Sie Frau Rühl bitte ausreden.</font>

382
00:19:22.080 --> 00:19:24.480
Schauen Sie sich die Demographie an.

383
00:19:24.560 --> 00:19:26.920
Wir werden immer älter,

384
00:19:27.000 --> 00:19:29.280
immer mehr Ältere
verlassen den Arbeitsmarkt,

385
00:19:29.360 --> 00:19:32.440
immer weniger Jüngere
kommen auf den Arbeitsmarkt.

386
00:19:32.520 --> 00:19:35.800
Das wird
über längere Zeit so bleiben,

387
00:19:35.880 --> 00:19:39.240
daran kann man kurzfristig
nichts ändern.

388
00:19:39.320 --> 00:19:44.640
Die Ansprüche der Gesellschaft
und der Nutzen verändern sich.

389
00:19:44.720 --> 00:19:50.120
Menschen, die heute stark
repetitive Arbeiten durchführen

390
00:19:50.200 --> 00:19:53.680
und und ihren Job verlieren ...

391
00:19:53.760 --> 00:19:56.200
Wir brauchen mehr Leute
in der Pflege,

392
00:19:56.280 --> 00:19:58.680
die sich um Menschen kümmern.

393
00:19:58.760 --> 00:20:01.680
Das ist eine
sehr sinnstiftende Arbeit.

394
00:20:01.760 --> 00:20:04.760
Man kann nicht einfach sagen,

395
00:20:04.840 --> 00:20:08.440
es gibt einen Arbeitsplatzverlust
und damit eine riesige Katastrophe.

396
00:20:08.520 --> 00:20:10.440
Es wird Verlagerungen geben.

397
00:20:10.520 --> 00:20:15.240
Dennoch glaube ich, dass wie nach
früheren Evolutionsschritten,

398
00:20:15.320 --> 00:20:19.920
unter dem Strich alle weiterhin
einen Arbeitsplatz haben werden.

399
00:20:20.000 --> 00:20:22.800
Es sind aber alle beruflichen
Aufgaben davon betroffen.

400
00:20:22.880 --> 00:20:25.000
Es ist nicht so,

401
00:20:25.080 --> 00:20:27.480
dass die Pflege oder Medizin
davon nicht betroffen wären.

402
00:20:27.560 --> 00:20:29.680
Wir schaffen Pflegeroboter,

403
00:20:29.760 --> 00:20:32.080
die Pflegefachpersonen
überflüssig machen.

404
00:20:32.160 --> 00:20:34.320
Das geht also nicht ganz auf.

405
00:20:34.400 --> 00:20:36.640
Ich fände es auch korrekter,
zu sagen,

406
00:20:36.720 --> 00:20:38.800
dass die Zielsetzung
tatsächlich so ist,

407
00:20:38.880 --> 00:20:41.360
dass man eine Effizienzsteigerung
anstrebt

408
00:20:41.440 --> 00:20:44.240
über die Reduktion von bezahlten
beruflichen Aufgaben von Menschen.

409
00:20:44.320 --> 00:20:46.840
Das muss man zugeben und dann
gemeinsam darüber nachdenken,

410
00:20:46.920 --> 00:20:49.080
wie man darauf reagieren kann.

411
00:20:49.160 --> 00:20:51.360
Was kann man machen,

412
00:20:51.440 --> 00:20:54.120
damit für alle ein menschenwürdiges
Dasein möglich ist?

413
00:20:54.200 --> 00:20:57.920
Eine Ärztin oder ein Arzt befasst
sich zu 40 % mit Dokumentation.

414
00:20:58.000 --> 00:21:01.440
Schon heute
gibt es künstliche Intelligenz,

415
00:21:01.520 --> 00:21:05.800
die eingesetzt werden kann, um
Ärztinnen und Ärzte freizuspielen.

416
00:21:05.880 --> 00:21:08.800
Das wäre etwas extrem Sinnvolles,

417
00:21:08.880 --> 00:21:11.160
es würde
unser Gesundheitssystem entlasten.

418
00:21:11.240 --> 00:21:14.520
Dort finde ich den Einsatz von KI
sehr plastisch und logisch.

419
00:21:14.600 --> 00:21:17.800
Sie wissen ja auch,
dass z.B. Bilderkennungsoftware

420
00:21:17.880 --> 00:21:20.520
heute schon medizinische Aufgaben
erfüllen kann,

421
00:21:20.600 --> 00:21:24.360
die über das Administrative
hinausgehen.

422
00:21:24.440 --> 00:21:27.560
Der Roboterchirurg kann heute schon
medizinische Aufgaben erfüllen,

423
00:21:27.640 --> 00:21:31.560
die über die repetitiven Aufgaben
hinausgehen.

424
00:21:31.640 --> 00:21:34.200
Ich finde es nicht ehrlich,
nicht einfach zu sagen,

425
00:21:34.280 --> 00:21:37.160
dass es zu einer massiven Reduktion
bezahlter beruflicher Aufgaben

426
00:21:37.240 --> 00:21:39.520
kommen wird, um dann
gemeinsam darüber nachzudenken,

427
00:21:39.600 --> 00:21:42.440
wie es gelingen kann, dass trotzdem
allen ein menschenwürdiges Dasein

428
00:21:42.520 --> 00:21:43.960
ermöglicht wird.

429
00:21:44.040 --> 00:21:46.880
Auch die Entkopplung von Einkommen
und Arbeit wäre ein Weg,

430
00:21:46.960 --> 00:21:49.240
das ethisch positiv zu gestalten.

431
00:21:49.320 --> 00:21:51.680
Mein Beispiel wäre ein anderes.

432
00:21:51.760 --> 00:21:54.400
Sie arbeiten als Kassierer bei Coop.

433
00:21:54.480 --> 00:21:58.160
Das ist eine extrem repetitive
und langweilige Arbeit.

434
00:21:58.240 --> 00:22:01.080
Dieser Job wird verschwinden.

435
00:22:01.160 --> 00:22:03.840
Schon jetzt kann man im Coop
und der Migros selber auschecken.

436
00:22:05.800 --> 00:22:09.360
Eine Person kann sich dann
weiterbilden, in die Pflege gehen,

437
00:22:09.440 --> 00:22:11.720
mit Menschen arbeiten.

438
00:22:11.800 --> 00:22:14.040
Es sind solche Verlagerungen,

439
00:22:14.120 --> 00:22:17.400
damit der Mensch
mit Menschen arbeitet,

440
00:22:17.480 --> 00:22:19.680
von der Maschine wegkommt,

441
00:22:19.760 --> 00:22:21.920
das müssen wir auch
im Auge behalten.

442
00:22:22.000 --> 00:22:24.080
<font color="#00ffff">Moment schnell.</font>

443
00:22:24.160 --> 00:22:26.320
<font color="#00ffff">Ich möchte kurz anknüpfen</font>

444
00:22:26.400 --> 00:22:28.960
<font color="#00ffff">und zwei, drei andere Beispiele</font>
<font color="#00ffff">von Branchen reinbringen,</font>

445
00:22:29.040 --> 00:22:31.520
<font color="#00ffff">die durch die KI</font>
<font color="#00ffff">besonders unter Druck geraten.</font>

446
00:22:31.600 --> 00:22:33.920
<font color="#00ffff">Das ist sicher auch eine Realität.</font>

447
00:22:34.000 --> 00:22:37.240
<font color="#00ffff">Gefährdet sind z.B. Jobs</font>
<font color="#00ffff">im Büro und in Verwaltungen,</font>

448
00:22:37.320 --> 00:22:43.040
<font color="#00ffff">in Callcentern oder in der Grafik-</font>
<font color="#00ffff">branche, dort z.B. Illustratoren.</font>

449
00:22:43.120 --> 00:22:47.280
<font color="#00ffff">Aber diese Seite sagt auch, da kämen</font>
<font color="#00ffff">neue Jobs, neue Berufsbilder.</font>

450
00:22:47.360 --> 00:22:50.240
<font color="#00ffff">Warum schauen Sie da einfach weg,</font>
<font color="#00ffff">Frau Hostetmann?</font>

451
00:22:50.320 --> 00:22:52.840
Bei Frau Rühl hört es sich so an,

452
00:22:52.920 --> 00:22:55.880
als könnte man heute das eine sein
und morgen das andere.

453
00:22:55.960 --> 00:22:58.400
KI entwickelt sich enorm schnell.

454
00:22:58.480 --> 00:23:01.720
Es geht nachher darum,

455
00:23:01.800 --> 00:23:05.280
dass Leute sehr schnell
umgeschult werden müssten.

456
00:23:05.360 --> 00:23:09.720
Es ist nicht so, dass diese Angebote
von Ihrer Seite jeweils kommen.

457
00:23:09.800 --> 00:23:12.720
Das ist das Problem.

458
00:23:12.800 --> 00:23:16.800
Sie tun so, als könne man
ganz einfach den Job wechseln,

459
00:23:16.880 --> 00:23:20.120
aber ich glaube, Ihnen
sind diese Menschen etwas egal.

460
00:23:20.200 --> 00:23:23.800
Das stimmt überhaupt nicht.

461
00:23:23.880 --> 00:23:26.120
Ich habe gerade versucht
zu erklären,

462
00:23:26.200 --> 00:23:28.680
dass uns die Menschen
überhaupt nicht egal sind.

463
00:23:28.760 --> 00:23:31.080
Ich glaube, es ist eine Chance,

464
00:23:31.160 --> 00:23:34.680
dass Menschen, die heute
repetitive Arbeiten machen müssen,

465
00:23:34.760 --> 00:23:37.800
sinnstiftendere Arbeiten
machen können.

466
00:23:37.880 --> 00:23:40.680
Gewisse dieser
sinnstiftenden Arbeiten

467
00:23:40.760 --> 00:23:46.480
kann man durchaus auch
ohne fünfjähriges Studium erledigen.

468
00:23:46.600 --> 00:23:49.160
Super, dann sind Sie auch
für die Arbeitszeitverkürzung

469
00:23:49.240 --> 00:23:51.680
bei gleichbleibenden Lohn,
nehme ich an?

470
00:23:51.760 --> 00:23:55.400
Ich verstehe nicht, was dieses Argu-
ment mit der Diskussion zu tun hat.

471
00:23:55.480 --> 00:23:57.720
<font color="#00ffff">Das wäre eine andere "Arena" -</font>

472
00:23:57.800 --> 00:24:00.080
<font color="#00ffff">eine interessante,</font>
<font color="#00ffff">aber diese machen wir heute nicht.</font>

473
00:24:00.160 --> 00:24:03.040
<font color="#00ffff">Heute Abend sprechen wir über KI,</font>
<font color="#00ffff">deren Möglichkeiten und Risiken.</font>

474
00:24:03.120 --> 00:24:05.280
<font color="#00ffff">Wir fragen auch Marcel Salathé</font>
<font color="#00ffff">immer wieder,</font>

475
00:24:05.360 --> 00:24:07.720
<font color="#00ffff">den Co-Chef am neuen KI-Zentrum</font>
<font color="#00ffff">der EPFL Lausanne.</font>

476
00:24:07.800 --> 00:24:10.440
<font color="#00ffff">Eine solche neue Technologie</font>
<font color="#00ffff">löst natürlich Ängste aus.</font>

477
00:24:10.520 --> 00:24:12.600
<font color="#00ffff">Sind diese berechtigt?</font>

478
00:24:12.680 --> 00:24:14.960
<font color="#008000">Ich glaube schon.</font>

479
00:24:15.040 --> 00:24:17.560
<font color="#008000">Wir haben gehört, dass es</font>
<font color="#008000">eine gewaltige Entwicklung ist.</font>

480
00:24:17.640 --> 00:24:19.840
<font color="#008000">Sie passiert auch extrem schnell.</font>

481
00:24:19.920 --> 00:24:22.680
<font color="#008000">Das Tempo muss durchaus</font>
<font color="#008000">realistisch betrachtet werden.</font>

482
00:24:22.800 --> 00:24:25.760
<font color="#008000">Ich glaube, der richtige Ansatz,</font>
<font color="#008000">zumindest mein persönlicher,</font>

483
00:24:25.840 --> 00:24:28.400
<font color="#008000">ist ein gewisser</font>
<font color="#008000">kritischer Optimismus.</font>

484
00:24:28.480 --> 00:24:31.200
<font color="#008000">Man will dem irgendwie</font>
<font color="#008000">offen gegenüberstehen,</font>

485
00:24:31.280 --> 00:24:34.440
<font color="#008000">will Chancen sehen, aber man darf</font>
<font color="#008000">nicht ganz blauäugig reingehen -</font>

486
00:24:34.520 --> 00:24:36.800
<font color="#008000">das werfe ich auch niemandem vor.</font>

487
00:24:36.880 --> 00:24:40.000
<font color="#008000">Es ist eine enorme Veränderung,</font>

488
00:24:40.120 --> 00:24:44.440
<font color="#008000">wie wir sie zuletzt wohl</font>
<font color="#008000">vor 200 Jahren gesehen haben.</font>

489
00:24:44.520 --> 00:24:47.640
<font color="#008000">Niemand kann sich genau erinnern,</font>
<font color="#008000">wie das gelaufen ist.</font>

490
00:24:47.720 --> 00:24:49.840
<font color="#00ffff">Kritischer Optimismus,</font>

491
00:24:49.920 --> 00:24:52.440
<font color="#00ffff">das ist schon fast das Jobprofil</font>
<font color="#00ffff">eines "Arena"-Moderators,</font>

492
00:24:52.520 --> 00:24:54.720
<font color="#00ffff">dabei bleiben wir.</font>

493
00:24:54.800 --> 00:24:57.000
<font color="#00ffff">Die Hochschule für Wirtschaft Zürich</font>

494
00:24:57.080 --> 00:24:59.520
<font color="#00ffff">hat bei Mitgliedern</font>
<font color="#00ffff">von acht unabhängigen Angestellten-</font>

495
00:24:59.600 --> 00:25:01.760
<font color="#00ffff">und Berufsverbänden</font>
<font color="#00ffff">eine Umfrage gemacht.</font>

496
00:25:01.840 --> 00:25:04.320
<font color="#00ffff">Das waren z.B. kaufmännische</font>
<font color="#00ffff">Angestellte, Personalfachleute</font>

497
00:25:04.400 --> 00:25:06.440
<font color="#00ffff">und Anwält/-innen.</font>

498
00:25:06.520 --> 00:25:09.440
<font color="#00ffff">Folgendes konnte man</font>
<font color="#00ffff">ausgehend von dieser Umfrage lesen:</font>

499
00:25:12.960 --> 00:25:15.600
<font color="#00ffff">80 % der Befragten sagten,</font>
<font color="#00ffff">sie bräuchten mehr Fachwissen,</font>

500
00:25:15.680 --> 00:25:20.080
<font color="#00ffff">um KI effektiv in ihre Arbeit</font>
<font color="#00ffff">integrieren zu können.</font>

501
00:25:20.160 --> 00:25:22.280
<font color="#00ffff">Fehlt das nun einfach an Know-how,</font>

502
00:25:22.360 --> 00:25:24.680
<font color="#00ffff">oder wird das Wissen</font>
<font color="#00ffff">zu wenig vermittelt?</font>

503
00:25:24.760 --> 00:25:27.080
<font color="#008000">Ich glaube,</font>
<font color="#008000">es hat effektiv damit zu tun,</font>

504
00:25:27.160 --> 00:25:29.440
<font color="#008000">wie man heute Wissen vermittelt.</font>

505
00:25:29.520 --> 00:25:32.000
<font color="#008000">Unsere ganzen schulischen Systeme,</font>
<font color="#008000">universitären Systeme,</font>

506
00:25:32.080 --> 00:25:34.720
<font color="#008000">Weiterbildungssysteme</font>
<font color="#008000">stammen noch aus einer Zeit,</font>

507
00:25:34.800 --> 00:25:37.720
<font color="#008000">in der sich Technologie</font>
<font color="#008000">über Jahrzehnte verändert hat.</font>

508
00:25:37.800 --> 00:25:40.080
<font color="#008000">Heute leben wir aber in einer Zeit,</font>

509
00:25:40.160 --> 00:25:42.560
<font color="#008000">wo sich die Welt</font>
<font color="#008000">innerhalb von zwei Jahren</font>

510
00:25:42.640 --> 00:25:44.880
<font color="#008000">unter unseren Füssen verändern kann.</font>

511
00:25:44.960 --> 00:25:49.560
<font color="#008000">Wir müssen neue Ausbildungsmodelle</font>
<font color="#008000">finden, um damit umzugehen.</font>

512
00:25:49.640 --> 00:25:53.520
<font color="#008000">Es scheint mir,</font>
<font color="#008000">dass diese Diskussion effektiv</font>

513
00:25:53.600 --> 00:25:56.120
<font color="#008000">in der Schweiz</font>
<font color="#008000">noch zu wenig aktiv geführt wird.</font>

514
00:25:56.200 --> 00:25:58.280
<font color="#00ffff">Und wenn man auf dieser Seite</font>
<font color="#00ffff">davon spricht,</font>

515
00:25:58.320 --> 00:26:00.480
<font color="#00ffff">dass die KI ein Jobkiller ist -</font>

516
00:26:00.560 --> 00:26:02.960
<font color="#00ffff">wie nehmen Sie das entgegen</font>
<font color="#00ffff">und beurteilen es?</font>

517
00:26:03.040 --> 00:26:05.480
<font color="#008000">Beim Tempo bin ich einverstanden,</font>
<font color="#008000">das ist heikel.</font>

518
00:26:05.560 --> 00:26:07.760
<font color="#008000">Sonst würde ich aber auch sagen,</font>

519
00:26:07.840 --> 00:26:10.160
<font color="#008000">dass wir immer wieder neue Wege</font>
<font color="#008000">gefunden haben.</font>

520
00:26:10.240 --> 00:26:13.560
<font color="#008000">Eine Technologie kommt, ersetzt</font>
<font color="#008000">einen gewissen Teil der Arbeit,</font>

521
00:26:13.640 --> 00:26:16.400
<font color="#008000">schafft aber neue Gebiete.</font>

522
00:26:16.480 --> 00:26:19.160
<font color="#008000">Jedes Mal, wenn eine solche</font>
<font color="#008000">technologische Entwicklung kommt,</font>

523
00:26:19.240 --> 00:26:21.440
<font color="#008000">haben wir</font>
<font color="#008000">noch weniger Arbeitslosigkeit,</font>

524
00:26:21.520 --> 00:26:24.120
<font color="#008000">noch höheren Fachkräftemangel.</font>

525
00:26:24.200 --> 00:26:26.400
<font color="#008000">Da bin ich also eher optimistisch.</font>

526
00:26:26.480 --> 00:26:29.520
<font color="#00ffff">Also eine Art industrielle</font>
<font color="#00ffff">Revolution auf einem neuen Level.</font>

527
00:26:29.600 --> 00:26:31.800
<font color="#00ffff">Sind Sie etwas entspannter,</font>
<font color="#00ffff">Herr Kirchschläger?</font>

528
00:26:31.880 --> 00:26:34.000
Nein, überhaupt nicht.

529
00:26:34.080 --> 00:26:36.120
Das ist überhaupt nicht
respektlos gemeint,

530
00:26:36.200 --> 00:26:38.320
aber ich glaube,
man riskiert einen Denkfehler.

531
00:26:38.400 --> 00:26:41.240
Nur weil technologischer Wandel in
anderen Epochen so abgelaufen ist,

532
00:26:41.320 --> 00:26:43.560
heisst es nicht,
dass es wieder genau gleich abläuft.

533
00:26:43.640 --> 00:26:45.880
Es kann auch sein,
dass diese Epoche einzigartig ist.

534
00:26:45.960 --> 00:26:48.040
Es gibt auch Gründe dafür.

535
00:26:48.120 --> 00:26:50.200
Es geht erstens um Ersatz,
nicht um Erleichterung.

536
00:26:50.280 --> 00:26:52.600
Es geht auch darum, selbstständige
Systeme zu entwickeln,

537
00:26:52.680 --> 00:26:54.760
die es eben genau schaffen,

538
00:26:54.840 --> 00:26:56.920
sich ohne menschlichen Input
weiterzuentwickeln.

539
00:26:57.000 --> 00:26:59.160
Zweitens betrifft es
alle beruflichen Aufgaben,

540
00:26:59.240 --> 00:27:02.240
nicht nur diejenigen, die keine oder
wenig Qualifikation voraussetzen.

541
00:27:02.320 --> 00:27:04.600
Deshalb sollten wir das
ernst nehmen und sagen:

542
00:27:04.680 --> 00:27:07.000
Okay, es gibt weniger bezahlte Jobs
für Menschen.

543
00:27:07.080 --> 00:27:09.560
Was können wir machen,
damit wir unser Wirtschaftssystem

544
00:27:09.640 --> 00:27:12.480
so umstellen, dass ein menschen-
würdiges Dasein möglich wird?

545
00:27:12.560 --> 00:27:15.800
Mein Vorschlag wäre erstens die Ent-
koppelung von Einkommen und Arbeit -

546
00:27:15.880 --> 00:27:18.720
dass alle ein Grundeinkommen
erhalten, aber kein bedingungsloses.

547
00:27:18.800 --> 00:27:21.720
Zweitens sollen alle
Society Time leisten,

548
00:27:21.800 --> 00:27:24.440
also Zeit für die Gesellschaft,

549
00:27:24.520 --> 00:27:27.160
wo sie sich in gesamtgesellschaft-
lichen Aufgaben einbringen.

550
00:27:27.240 --> 00:27:30.560
Alle gleich viel, aber frei
und selbstbestimmt gewählt.

551
00:27:30.640 --> 00:27:32.960
Und dann soll drittens
ein Anreiz gesetzt werden

552
00:27:33.040 --> 00:27:35.400
für Innovation und Unternehmertum,

553
00:27:35.480 --> 00:27:38.040
indem man Unternehmer,
innovative Leute

554
00:27:38.120 --> 00:27:40.360
von dieser Society Time befreit.

555
00:27:40.440 --> 00:27:42.560
<font color="#00ffff">Das waren einige Schlagwörter.</font>

556
00:27:42.640 --> 00:27:44.800
<font color="#00ffff">Was meinen Sie konkret</font>
<font color="#00ffff">mit Society Time?</font>

557
00:27:44.880 --> 00:27:47.520
Ich meine das in Anlehnung
an den schweizerischen Zivildienst.

558
00:27:47.600 --> 00:27:50.840
Man kann sich z.B. für Bergbauern
und Bergbäuerinnen engagieren

559
00:27:50.920 --> 00:27:53.080
oder für Menschen auf der Flucht -

560
00:27:53.160 --> 00:27:56.000
dann kann ich meine
Gesellschaftszeit dafür einsetzen.

561
00:27:56.080 --> 00:27:58.400
Mir geht es weniger
um die finanzielle Absicherung

562
00:27:58.480 --> 00:28:03.080
als darum, dass ein Arbeitsplatz
nicht nur finanzielle Absicherung

563
00:28:03.160 --> 00:28:06.040
sondern Sinnstiftung ist.

564
00:28:06.120 --> 00:28:08.400
Auch der Job als Kassierer/-in.

565
00:28:08.480 --> 00:28:10.640
Ich finde es nicht okay zu sagen,

566
00:28:10.720 --> 00:28:13.280
gewisse Arbeiten seien nicht
sinnvoll, deshalb können die weg.

567
00:28:13.360 --> 00:28:15.440
Nein, das kann für jemanden
sehr sinnerfüllend sein.

568
00:28:15.520 --> 00:28:17.440
(Rühl) Das habe ich nicht gesagt.

569
00:28:17.520 --> 00:28:19.560
Nein, aber von wegen
repetitive Aufgaben.

570
00:28:19.640 --> 00:28:21.760
Ich finde das etwas heikel.
Das ist Sinnstiftung.

571
00:28:21.840 --> 00:28:24.080
Wenn ich nie
in einen bezahlten Job komme,

572
00:28:24.160 --> 00:28:26.960
dann hat man noch die Gesellschafts-
zeit, um das einmal zu erleben.

573
00:28:27.040 --> 00:28:29.520
<font color="#00ffff">Sie haben es wohl anders gemeint</font>
<font color="#00ffff">und nicht so sehr zugespitzt,</font>

574
00:28:29.600 --> 00:28:31.640
<font color="#00ffff">wie Sie es gesagt haben, oder?</font>

575
00:28:31.720 --> 00:28:33.720
Nein, absolut.

576
00:28:33.800 --> 00:28:36.560
Ich weiss nicht, ob Sie schon einen
ganzen Tag Kasse gesessen haben

577
00:28:36.640 --> 00:28:38.760
und Kunden bedienten.

578
00:28:38.840 --> 00:28:40.560
<font color="#00ffff">Sie schon?</font>

579
00:28:40.640 --> 00:28:44.160
Meine Berufskarriere begann in einem
Migros-Selbstbedienungsrestaurant.

580
00:28:44.240 --> 00:28:47.000
Dort habe ich den Geschirrspüler
eingeräumt,

581
00:28:47.080 --> 00:28:49.760
das war auch ziemlich repetitiv.

582
00:28:49.840 --> 00:28:53.320
Für zwei Wochen ist das lustig,
aber irgendwann nicht mehr.

583
00:28:53.400 --> 00:28:56.320
So habe ich es gemeint.

584
00:28:56.400 --> 00:28:59.960
Dann gehen Sie noch davon aus, dass
es keine neuen Jobs geben wird.

585
00:29:00.040 --> 00:29:04.000
Unsere These ist, dass
gewisse Berufe, gewisse Aufgaben

586
00:29:04.080 --> 00:29:06.440
wegfallen werden, ja.

587
00:29:06.520 --> 00:29:09.720
Aber es werden andere dazukommen.

588
00:29:09.800 --> 00:29:12.840
Unter dem Strich
bin ich weiterhin überzeugt,

589
00:29:12.920 --> 00:29:15.920
dass wir gleich viele Jobs wie jetzt
haben werden.

590
00:29:16.000 --> 00:29:18.960
<font color="#00ffff">Herr Kaufmann,</font>
<font color="#00ffff">was sind das für neue Jobs?</font>

591
00:29:19.040 --> 00:29:23.080
Ich möchte noch etwas
grundsätzlich infrage stellen.

592
00:29:23.160 --> 00:29:26.520
Und zwar das Ziel, dass alle
Menschen immer schön 8 Std. pro Tag

593
00:29:26.600 --> 00:29:28.880
arbeiten müssen,
100 % Vollbeschäftigung.

594
00:29:28.960 --> 00:29:31.280
Was ist das für eine Vision
unserer Gesellschaft?

595
00:29:31.360 --> 00:29:34.240
Für mich ist künstliche Intelligenz,

596
00:29:34.320 --> 00:29:37.000
so, wie ich das auch
in der letzten Woche gesehen habe -

597
00:29:37.080 --> 00:29:39.880
das KI-Format des SRF
fand ich übrigens super -,

598
00:29:39.960 --> 00:29:42.640
etwas wie die Erfindung des Feuers
oder des Buchdrucks.

599
00:29:42.720 --> 00:29:45.360
Es gibt eine neue Perspektive
auf unsere Gesellschaft.

600
00:29:45.440 --> 00:29:47.680
Es ist wie ein Vergrösserungsglas.

601
00:29:47.760 --> 00:29:50.120
Ein Beispiel bezüglich Bias:

602
00:29:50.200 --> 00:29:53.080
Plötzlich sehen wir, wie rassistisch
und sexistisch die Gesellschaft

603
00:29:53.160 --> 00:29:55.600
in den letzten 100 Jahren war,

604
00:29:55.680 --> 00:29:57.880
weil man das mit KI
extrem deutlich sieht.

605
00:29:57.960 --> 00:30:00.280
Wir haben die Chance,
die Gesellschaft zu verbessern.

606
00:30:00.360 --> 00:30:03.160
Es wird uns
eine Art Spiegel vorgehalten.

607
00:30:03.240 --> 00:30:05.360
In der Renaissance damals

608
00:30:05.440 --> 00:30:07.720
wurden die ersten Teleskope
und Spiegel erfunden,

609
00:30:07.800 --> 00:30:10.280
und es kam zu enormen Umwälzungen.

610
00:30:10.360 --> 00:30:13.000
Ich glaube, wenn wir es richtig
machen, haben wir die Chance,

611
00:30:13.080 --> 00:30:15.640
eine neue Gesellschaft
und ein neues Zeitalter einzuläuten.

612
00:30:15.720 --> 00:30:18.320
Dort arbeitet man vielleicht
nicht mehr 8 Std. pro Tag,

613
00:30:18.400 --> 00:30:21.120
sondern nur 6 oder 5 Std. und
ist mind. so produktiv wie vorher.

614
00:30:21.200 --> 00:30:23.560
<font color="#00ffff">Und was sind das für neue Jobs,</font>
<font color="#00ffff">die kommen?</font>

615
00:30:23.640 --> 00:30:27.120
Ich finde übrigens, die neuen Jobs
könnte man auch der Maschine geben.

616
00:30:27.200 --> 00:30:29.920
Falls es neue Jobs gibt,
sind das vielleicht Datensammler,

617
00:30:30.000 --> 00:30:32.360
das haben wir auch
in der Dokumentation gesehen.

618
00:30:32.440 --> 00:30:34.680
Aber eigentlich
ist es gar nicht das Ziel,

619
00:30:34.760 --> 00:30:37.440
dass man die Menschen vom einen
in den anderen Job verfrachtet.

620
00:30:37.520 --> 00:30:39.840
Es ist doch super, wenn man
etwas weniger arbeiten muss,

621
00:30:39.920 --> 00:30:42.120
weil uns das die Maschine abnimmt.

622
00:30:42.200 --> 00:30:44.320
Langsam tönt es
wie eine Lobbyveranstaltung.

623
00:30:44.400 --> 00:30:46.880
Ich sehe auch Chancen
für die Privatwirtschaft,

624
00:30:46.960 --> 00:30:49.360
das haben jetzt lange genug gehört.

625
00:30:49.400 --> 00:30:53.760
Die Frage ist aber, was mit
der geopolitischen Lage passiert.

626
00:30:53.880 --> 00:30:58.160
KI wird enorm Schnell mit enorm
vielen Informationen gefüttert.

627
00:30:58.240 --> 00:31:01.960
Ich glaube, der Wettbewerb
ist v.a. ein Wettbewerb um Macht

628
00:31:02.040 --> 00:31:05.120
und nicht nur um Sicherheit
und sichere Systeme.

629
00:31:05.200 --> 00:31:09.200
Alle Programme wie ChatGPT
wurden zuvor nicht getestet.

630
00:31:09.280 --> 00:31:12.440
Das muss man sich einmal vorstellen.

631
00:31:12.520 --> 00:31:14.960
Wenn das bei einer Impfung
der Fall wäre,

632
00:31:15.040 --> 00:31:17.640
wenn man einfach ein Produkt
auf dem Markt brächte,

633
00:31:17.720 --> 00:31:20.320
ohne vorher lang
daran geforscht zu haben,

634
00:31:20.400 --> 00:31:23.440
dann würden die Leute das
wohl so nicht akzeptieren.

635
00:31:23.520 --> 00:31:25.600
Aber bei diesen Programmen
ist es so.

636
00:31:25.680 --> 00:31:27.840
Niemand kann garantieren,

637
00:31:27.920 --> 00:31:30.280
dass man damit nicht
sehr Gefährliches machen kann.

638
00:31:30.360 --> 00:31:31.760
Im Gegenteil.

639
00:31:31.840 --> 00:31:35.480
Dass man dann immer noch naiv nur
von den Chancen für die Wirtschaft

640
00:31:35.560 --> 00:31:38.160
spricht,
das finde ich wirklich bedenklich.

641
00:31:38.240 --> 00:31:40.640
Kurz etwas zu Geopolitik.

642
00:31:40.720 --> 00:31:43.560
Mir ist lieber, wenn die Schweizer
im Bereich AI ganz vorne sind,

643
00:31:43.640 --> 00:31:46.080
als dass man in Zürich
einen Punkt Abzug kriegt,

644
00:31:46.160 --> 00:31:49.320
wenn man bei Rot über die Strasse
geht, wie das in China der Fall ist.

645
00:31:49.400 --> 00:31:52.040
Oder ein Grosskonzern,
der sagt, was wir glauben müssen.

646
00:31:52.120 --> 00:31:54.400
Eigentlich müssen wir als Europa ...
<font color="#00ffff">- Social Scoring.</font>

647
00:31:54.480 --> 00:31:56.680
Genau, Social Scoring.

648
00:31:56.760 --> 00:31:59.640
Wenn uns unsere Werte etwas bedeu-
ten, müssen wir etwas dafür tun

649
00:31:59.720 --> 00:32:02.480
und in diesem Thema
ganz vorne mit dabei sein.

650
00:32:02.560 --> 00:32:05.720
Hier zu versuchen, zu bremsen und
die Privatwirtschaft abzuklemmen,

651
00:32:05.800 --> 00:32:08.400
das interessiert die Chinesen
und Amerikaner überhaupt nicht.

652
00:32:08.480 --> 00:32:11.200
Es geht überhaupt nicht darum,
die Privatwirtschaft abzuklemmen.

653
00:32:11.280 --> 00:32:14.080
Schön zu hören war,
dass Sie eigentlich bestätigt haben,

654
00:32:14.160 --> 00:32:17.200
dass es zu einer Reduktion von be-
zahlten beruflichen Aufgaben kommt.

655
00:32:17.280 --> 00:32:20.120
Das andere ist: Es geht gar nicht
darum, die Wirtschaft abzuklemmen,

656
00:32:20.200 --> 00:32:22.320
sondern darum, dass wir merken,

657
00:32:22.400 --> 00:32:25.120
dass es neben vielen ethischen
positiven Chancen auch Risiken gibt.

658
00:32:25.200 --> 00:32:27.200
Diese sind auch
entsprechend adressiert.

659
00:32:27.280 --> 00:32:29.400
Wir können nicht so tun,
als gäbe es sie nicht.

660
00:32:29.480 --> 00:32:31.600
Es gibt schon einen Unterschied

661
00:32:31.680 --> 00:32:33.840
in Bezug auf Vorurteile
und Verzerrungen bei Menschen.

662
00:32:33.920 --> 00:32:36.160
Wir Menschen sind dazu fähig,
selbstkritisch zu merken,

663
00:32:36.240 --> 00:32:38.400
dass wir Vorurteile haben
und daran arbeiten.

664
00:32:38.480 --> 00:32:41.240
Wenn ich z.B. einen Rekrutierungs-
prozess für eine neue Stelle starte

665
00:32:41.320 --> 00:32:43.400
und jemanden suche ...

666
00:32:43.480 --> 00:32:45.640
Wenn das eine KI macht,
kann es sein,

667
00:32:45.720 --> 00:32:47.840
dass Frauen
einfach aussortiert werden.

668
00:32:47.920 --> 00:32:50.440
Wir haben die Daten,
dass das passiert.

669
00:32:50.520 --> 00:32:52.640
(Rühl) Das haben wir aber auch
bei den Menschen,

670
00:32:52.720 --> 00:32:54.800
dass Frauen aussortiert werden.

671
00:32:54.880 --> 00:32:57.120
Ja, aber der entscheidende
Unterschied ist,

672
00:32:57.200 --> 00:32:59.600
dass mir als Mensch das Vorurteil
bewusst sein kann

673
00:32:59.680 --> 00:33:01.840
und dass ich entsprechend
reagieren kann.

674
00:33:01.960 --> 00:33:04.240
Ich kann den Bewerbungsprozess
umbauen,

675
00:33:04.320 --> 00:33:07.280
z.B. ein Vieraugenprinzip einführen

676
00:33:07.360 --> 00:33:10.240
oder mögliche Vorurteile von mir
gezielt adressieren.

677
00:33:10.320 --> 00:33:12.760
Das kann eine Maschine nicht.

678
00:33:12.840 --> 00:33:15.280
<font color="#00ffff">Zum Bereich Human Resources,</font>
<font color="#00ffff">den Sie erwähnen,</font>

679
00:33:15.360 --> 00:33:18.600
<font color="#00ffff">haben wir auch</font>
<font color="#00ffff">eine Schlagzeile vorbereitet:</font>

680
00:33:23.680 --> 00:33:27.320
<font color="#00ffff">Ist das eine Gefahr, die Sie sehen,</font>
<font color="#00ffff">oder etwas, was sich regeln lässt?</font>

681
00:33:27.400 --> 00:33:29.720
Ich glaube,
man muss die KI so trainieren,

682
00:33:29.800 --> 00:33:32.080
dass sie das eben nicht macht.

683
00:33:32.160 --> 00:33:34.880
Was mich stört
in der ganzen Diskussion:

684
00:33:34.960 --> 00:33:38.040
Wir tun, als ob wir Menschen
perfekt wären.

685
00:33:38.120 --> 00:33:40.480
Wir Menschen sind nicht perfekt.

686
00:33:40.560 --> 00:33:43.320
In der Musik hat man eingeführt,

687
00:33:43.400 --> 00:33:46.760
dass Musiker/-innen
hinter einem Vorhang spielen müssen,

688
00:33:46.840 --> 00:33:49.680
damit man nicht sieht,
ob es ein Mann oder eine Frau ist,

689
00:33:49.760 --> 00:33:52.560
weil man diesen Gender Bias hatte.

690
00:33:52.640 --> 00:33:55.720
Menschen lügen,
Menschen machen Fehler.

691
00:33:55.800 --> 00:33:59.240
Es ist also nicht so,
dass wir Menschen perfekt wären

692
00:33:59.320 --> 00:34:02.040
und die Maschine nicht perfekt.

693
00:34:02.120 --> 00:34:06.960
Wenn die Maschine
diskriminierend vorgeht,

694
00:34:07.040 --> 00:34:11.520
dann ist das ein Spiegelbild davon,
wie wir als Menschen sind.

695
00:34:11.600 --> 00:34:15.360
Das sollte eigentlich
eine heilsame Wirkung haben.

696
00:34:15.440 --> 00:34:17.760
<font color="#00ffff">Ein kleines Beispiel</font>
<font color="#00ffff">für dieses Spiegelbild.</font>

697
00:34:17.840 --> 00:34:20.480
<font color="#00ffff">Wir sagten ChatGPT diese Woche:</font>

698
00:34:20.560 --> 00:34:23.360
<font color="#00ffff">"Zeig uns das 'Arena'-Studio</font>
<font color="#00ffff">mit Moderator."</font>

699
00:34:23.440 --> 00:34:26.199
<font color="#00ffff">Das kam dabei raus.</font>

700
00:34:26.280 --> 00:34:28.760
* Lachen im Publikum *

701
00:34:28.840 --> 00:34:31.560
<font color="#00ffff">Man kann darüber reden, ob das</font>
<font color="#00ffff">futuristisch toll ist, oder nicht</font>

702
00:34:31.639 --> 00:34:33.800
<font color="#00ffff">und was der Typ in der Mitte</font>
<font color="#00ffff">mit der Krawatte macht,</font>

703
00:34:33.880 --> 00:34:36.000
<font color="#00ffff">die er sonst nicht hat.</font>

704
00:34:36.080 --> 00:34:38.520
<font color="#00ffff">Wenn man genau hinschaut -</font>
<font color="#00ffff">wie viele Frauen sehen Sie?</font>

705
00:34:38.600 --> 00:34:41.000
<font color="#00ffff">Ich sehe eine</font>
<font color="#00ffff">rechts aussen irgendwo.</font>

706
00:34:41.080 --> 00:34:43.280
<font color="#00ffff">Ist das nicht auch ein Beispiel</font>

707
00:34:43.360 --> 00:34:45.800
<font color="#00ffff">der Diskriminierung</font>
<font color="#00ffff">und des Sexismus?</font>

708
00:34:45.880 --> 00:34:48.320
Da wird uns allen völlig bewusst,
dass das so nicht geht.

709
00:34:48.400 --> 00:34:50.520
Es war in den letzten 100 Jahren so.

710
00:34:50.600 --> 00:34:53.000
In diesem Sinne hält uns KI
einen Spiegel vor

711
00:34:53.080 --> 00:34:55.719
und hilft uns,
diese Fehler zu korrigieren.

712
00:34:55.800 --> 00:34:58.640
Wir haben schon vorher
herausgefunden, dass das nicht geht.

713
00:34:58.720 --> 00:35:01.240
Wir brauchten das nicht,
um zu merken,

714
00:35:01.320 --> 00:35:03.600
dass man Frauen
nicht diskriminieren soll.

715
00:35:03.680 --> 00:35:06.040
Diese Beschönigung ...

716
00:35:06.120 --> 00:35:09.040
Ich sehe das positive Potenzial,
aber wir müssen auch bremsen.

717
00:35:09.120 --> 00:35:13.040
Wir haben drängende Probleme im
Bereich der künstlichen Intelligenz,

718
00:35:13.120 --> 00:35:15.320
die wir angehen müssen.

719
00:35:15.400 --> 00:35:18.040
Das sind Biases, die Bedrohung
demokratischer Prozesse,

720
00:35:18.120 --> 00:35:20.800
Attacken auf Menschen,
auf die Natur -

721
00:35:20.880 --> 00:35:24.160
wir haben einen enormen Energie-
verbrauch im Bereich der sog. KI.

722
00:35:24.240 --> 00:35:26.760
Ich plädiere ja auch
für positive Chancen,

723
00:35:26.840 --> 00:35:29.400
aber wir können nicht so tun,
als gäbe es die Probleme nicht.

724
00:35:29.480 --> 00:35:31.640
Wir müssen sie adressieren.

725
00:35:31.720 --> 00:35:33.840
Das ist aber kein Problem
der Technologie,

726
00:35:33.920 --> 00:35:36.040
sondern der Gesellschaft.

727
00:35:36.120 --> 00:35:38.200
Dann würde ich eher
dort nachschauen,

728
00:35:38.280 --> 00:35:40.480
nicht unbedingt
die Technologie regulieren.

729
00:35:40.560 --> 00:35:42.720
<font color="#00ffff">Ein Stichwort möchte ich aufnehmen:</font>
<font color="#00ffff">Energieverbrauch.</font>

730
00:35:42.800 --> 00:35:47.160
<font color="#00ffff">Marcel Salathé, man liest,</font>
<font color="#00ffff">dass eine ChatGPT-Anfrage</font>

731
00:35:47.240 --> 00:35:50.720
<font color="#00ffff">zehnmal mehr Energie braucht</font>
<font color="#00ffff">als eine Google-Suche,</font>

732
00:35:50.800 --> 00:35:54.320
<font color="#00ffff">oder dass in zehn Jahren so viel En-</font>
<font color="#00ffff">ergie gebraucht wird wie von Indien.</font>

733
00:35:54.400 --> 00:35:56.840
<font color="#00ffff">Stimmt das eigentlich?</font>

734
00:35:56.920 --> 00:35:59.440
<font color="#008000">Es gibt gewisse Vergleiche,</font>
<font color="#008000">die stimmen.</font>

735
00:35:59.520 --> 00:36:02.760
<font color="#008000">Es hört sich aber auch immer</font>
<font color="#008000">schlimmer an, als es wirklich ist.</font>

736
00:36:02.840 --> 00:36:06.440
<font color="#008000">Wenn man 100 ChatGPT-Anfragen macht,</font>
<font color="#008000">ist das am Ende etwa so viel Energie</font>

737
00:36:06.520 --> 00:36:09.160
<font color="#008000">wie wenn man 1 Std. lang</font>
<font color="#008000">TikTok-Videos streamt.</font>

738
00:36:09.240 --> 00:36:12.360
<font color="#008000">Ich würde mal sagen,</font>
<font color="#008000">nach der Stunde auf ChatGPT</font>

739
00:36:12.400 --> 00:36:15.920
<font color="#008000">ist man etwas smarter</font>
<font color="#008000">als nach 1 Std. TikTok.</font>

740
00:36:16.000 --> 00:36:18.440
<font color="#008000">Das kommt natürlich</font>
<font color="#008000">auf den TikTok-Filter an.</font>

741
00:36:18.520 --> 00:36:22.040
<font color="#008000">Die Energie steckt momentan</font>
<font color="#008000">v.a. im Training der Modelle.</font>

742
00:36:22.120 --> 00:36:24.360
<font color="#008000">Das stimmt,</font>
<font color="#008000">das braucht viel Energie.</font>

743
00:36:24.440 --> 00:36:27.280
<font color="#008000">In Zukunft sehen wir v.a. auch</font>
<font color="#008000">viel Energie in der Nutzung,</font>

744
00:36:27.360 --> 00:36:30.160
<font color="#008000">denn auch wenn eine ChatGPT-Abfrage</font>
<font color="#008000">nicht viel ist,</font>

745
00:36:30.240 --> 00:36:34.200
<font color="#008000">sind Hunderte Mio. Menschen, die es</font>
<font color="#008000">tagtäglich nutzen, schon viel.</font>

746
00:36:34.280 --> 00:36:37.400
<font color="#008000">Das ist ein Energiebedarf,</font>
<font color="#008000">den wir planen müssen.</font>

747
00:36:37.480 --> 00:36:40.880
<font color="#00ffff">Es geht auch darum,</font>
<font color="#00ffff">KI verantwortungsvoll einzusetzen.</font>

748
00:36:40.960 --> 00:36:45.120
<font color="#00ffff">Das wollen alle und sagen alle.</font>
<font color="#00ffff">Aber wie soll das aussehen?</font>

749
00:36:45.200 --> 00:36:47.600
<font color="#00ffff">Da sind wir schnell</font>
<font color="#00ffff">beim Thema Regulierung.</font>

750
00:36:47.680 --> 00:36:49.920
<font color="#00ffff">Der Bundesrat erarbeitet im Moment</font>

751
00:36:50.000 --> 00:36:52.760
<font color="#00ffff">einen Leitfaden für den Umgang</font>
<font color="#00ffff">mit künstlicher Intelligenz.</font>

752
00:36:52.840 --> 00:36:54.960
<font color="#00ffff">Bis Ende Jahr</font>
<font color="#00ffff">soll dieser bereit sein.</font>

753
00:36:55.040 --> 00:36:57.360
<font color="#00ffff">Die EU ist hier schon weiter.</font>

754
00:36:57.440 --> 00:36:59.760
<font color="#00ffff">Seit Sommer</font>
<font color="#00ffff">ist eine Verordnung in Kraft,</font>

755
00:36:59.840 --> 00:37:02.680
<font color="#00ffff">die erstmals Regeln</font>
<font color="#00ffff">für den Einsatz von KI</font>

756
00:37:02.760 --> 00:37:04.920
<font color="#00ffff">in den EU-Mitgliedstaaten festlegt.</font>

757
00:37:05.000 --> 00:37:07.280
<font color="#00ffff">Darüber sprechen wir gleich,</font>
<font color="#00ffff">Stichwort Regulierung.</font>

758
00:37:07.360 --> 00:37:10.920
<font color="#00ffff">Aber erst schauen wir uns an,</font>
<font color="#00ffff">was in der EU gemacht wurde.</font>

759
00:37:11.000 --> 00:37:16.800
Die KI-Verordnung der EU,
auch AI Act genannt.

760
00:37:16.880 --> 00:37:20.480
Sie sieht für KI-Systeme
verschiedene Risikostufen vor.

761
00:37:20.560 --> 00:37:25.440
KI-Anwendungen, von denen
ein minimales Risiko ausgeht -

762
00:37:25.520 --> 00:37:31.600
etwa Videospiele mit KI -, dürfen
weiterhin frei genutzt werden.

763
00:37:33.720 --> 00:37:36.360
Für KI-Systeme
mit begrenztem Risiko

764
00:37:36.440 --> 00:37:39.000
gelten neue Transparenzpflichten.

765
00:37:39.080 --> 00:37:43.520
So müssen etwa Betreiber
von Chatbots wie z.B. ChatGPT

766
00:37:43.600 --> 00:37:46.160
die Nutzerinnen und Nutzer
darauf aufmerksam machen,

767
00:37:46.240 --> 00:37:49.040
dass sie mit Maschinen interagieren.

768
00:37:50.920 --> 00:37:54.000
Als hochriskant gelten
beispielsweise KI-Anwendungen,

769
00:37:54.080 --> 00:37:59.000
die in einem Einstellungsverfahren
Bewerbungen von Personen auswerten.

770
00:37:59.080 --> 00:38:04.280
Bei diesen Anwendungen muss
die Aktivität der KI protokolliert

771
00:38:04.360 --> 00:38:08.560
oder auch von einem Menschen
überwacht werden.

772
00:38:10.160 --> 00:38:14.480
KI-Anwendungen mit inakzeptablen
Risiken werden ganz verboten.

773
00:38:14.560 --> 00:38:19.960
Etwa Systeme, die soziales Verhalten
bewerten können.

774
00:38:20.040 --> 00:38:23.080
Unternehmen dürfen z.B.
keine KI verwenden,

775
00:38:23.160 --> 00:38:28.160
die den Gefühlszustand von Kunden
automatisiert bewertet.

776
00:38:30.080 --> 00:38:32.440
<font color="#00ffff">Wie gesagt arbeitet der Bund</font>

777
00:38:32.520 --> 00:38:35.040
<font color="#00ffff">an einem eigenen Ansatz</font>
<font color="#00ffff">für die Regulierung von KI.</font>

778
00:38:35.120 --> 00:38:37.440
<font color="#00ffff">Bis Ende Jahr</font>
<font color="#00ffff">sollten wir mehr wissen.</font>

779
00:38:37.520 --> 00:38:40.400
<font color="#00ffff">Das EU-Gesetz, das KI</font>
<font color="#00ffff">in vier Risikogruppen unterteilt,</font>

780
00:38:40.480 --> 00:38:42.760
<font color="#00ffff">gilt also nicht für die Schweiz.</font>

781
00:38:42.840 --> 00:38:45.000
<font color="#00ffff">Aber die Frage ist,</font>
<font color="#00ffff">was in der Schweiz kommen soll.</font>

782
00:38:45.080 --> 00:38:47.160
<font color="#00ffff">Monika Rühl,</font>
<font color="#00ffff">ich kann mir vorstellen,</font>

783
00:38:47.240 --> 00:38:49.240
<font color="#00ffff">dass Sie als Wirtschaftsdachverband</font>

784
00:38:49.320 --> 00:38:51.560
<font color="#00ffff">so wenig wie möglich</font>
<font color="#00ffff">regulieren wollen.</font>

785
00:38:51.640 --> 00:38:53.920
Wir wollen v.a. keine
Regulierungskeule wie die EU.

786
00:38:54.000 --> 00:38:57.680
Der KI-Bereich ist in Entwicklung.

787
00:38:57.760 --> 00:38:59.800
Es ist enorm schwierig,

788
00:38:59.880 --> 00:39:01.960
etwas zu regulieren,
was sich weiter entwickelt.

789
00:39:02.040 --> 00:39:03.600
Das ist das eine.

790
00:39:03.680 --> 00:39:06.560
Das andere ist, dass wir in der
Schweiz in einem Rechtsstaat leben.

791
00:39:06.640 --> 00:39:10.720
Wir haben eine Verfassung,
Gesetze und Gerichte.

792
00:39:10.800 --> 00:39:14.760
Das Bundesgericht
hat übrigens kürzlich entschieden,

793
00:39:14.840 --> 00:39:20.840
dass das Polizeigesetz im Kanton
Luzern nicht anwendbar sein soll

794
00:39:20.920 --> 00:39:25.600
für die automatische Überprüfung
von Autos und deren Insassen.

795
00:39:25.680 --> 00:39:28.440
Von daher haben wir nicht nichts.

796
00:39:28.520 --> 00:39:31.320
Wir glauben, es ist wichtig,
dass man hinschaut

797
00:39:31.400 --> 00:39:36.080
und Lücken in den bestehenden
Gesetzen feststellt.

798
00:39:36.160 --> 00:39:40.000
Dass man diese Lücken gezielt füllt,

799
00:39:40.080 --> 00:39:43.880
anstatt ein umfassendes KI-Gesetz
aufzustellen.

800
00:39:43.960 --> 00:39:46.120
<font color="#00ffff">Ihnen ist das also</font>
<font color="#ffffff">zu flächendeckend?- Ja.</font>

801
00:39:46.200 --> 00:39:48.640
<font color="#00ffff">Aber Sie sehen auch Lücken,</font>
<font color="#00ffff">die es zu schliessen gilt.</font>

802
00:39:48.720 --> 00:39:50.400
Absolut.

803
00:39:50.480 --> 00:39:53.320
Beim letzten Beispiel im Video
bin ich auch dafür,

804
00:39:53.400 --> 00:39:57.240
dass man dort strenger reguliert
oder von mir aus auch verbietet.

805
00:39:57.320 --> 00:40:00.720
Wenn wir bei diesen Lücken sind.

806
00:40:00.800 --> 00:40:03.760
Man sieht das bei den EU-Regeln.

807
00:40:03.840 --> 00:40:06.800
Was ist von diesem Risikomodell
ausgeschlossen?

808
00:40:06.880 --> 00:40:09.560
Es sind wieder Sicherheit
und Militär.

809
00:40:09.640 --> 00:40:13.800
Sie sagen,
es mache keinen Unterschied,

810
00:40:13.880 --> 00:40:16.960
ob nun ein Schweizer Kreuz
auf einer Drohne ist

811
00:40:17.040 --> 00:40:21.160
oder ob es von irgendjemand anderem
abgeschossen wird.

812
00:40:21.240 --> 00:40:24.920
Aber das sind Technologien,
die höchst gefährlich sind.

813
00:40:25.000 --> 00:40:28.000
Wir sehen schon heute
an der EU-Aussengrenze,

814
00:40:28.080 --> 00:40:31.840
dass Frontex mit KI arbeitet,
um Menschen zu erkennen.

815
00:40:31.920 --> 00:40:35.480
Auch beim neuen Asylgesetz in Europa

816
00:40:35.560 --> 00:40:39.600
soll quasi ein gesamteuropäisches
Überwachungssystem

817
00:40:39.680 --> 00:40:41.880
ausgearbeitet werden.

818
00:40:41.960 --> 00:40:44.520
Das ist höchst bedenklich.

819
00:40:44.600 --> 00:40:47.520
<font color="#00ffff">Es ist schwierig,</font>
<font color="#00ffff">den Ball an Pascal Kaufmann</font>

820
00:40:47.600 --> 00:40:50.000
<font color="#00ffff">als Unternehmer in diesem Bereich</font>
<font color="#00ffff">weiterzugeben.</font>

821
00:40:50.080 --> 00:40:53.240
<font color="#00ffff">Denn ihr lebt in anderen Welten.</font>
<font color="#00ffff">Kann man das so sagen?</font>

822
00:40:53.320 --> 00:40:57.080
Ob wir nun
die Vorreiterrolle besetzen

823
00:40:57.160 --> 00:40:59.880
und schneller als alle anderen
regulieren sollen ...

824
00:40:59.960 --> 00:41:02.800
Ich glaube, wir haben in der Schweiz
eine super Ausgangslage.

825
00:41:02.880 --> 00:41:05.400
Wir können schauen, was in den USA
und in China passiert,

826
00:41:05.480 --> 00:41:07.760
können das Beste beider Welten
übernehmen.

827
00:41:07.840 --> 00:41:11.960
Ich sehe bei uns
keinen akuten Handlungsbedarf.

828
00:41:12.040 --> 00:41:16.080
Ich glaube auch, dass man
nicht so schnell legiferieren

829
00:41:16.160 --> 00:41:19.520
und Gesetze anpassen sollte.

830
00:41:19.600 --> 00:41:21.680
Diese Technologie ist noch so jung.

831
00:41:21.760 --> 00:41:23.920
Ich glaube, wir haben hier
eine gute gesetzliche Grundlage.

832
00:41:24.000 --> 00:41:26.120
Wo es Lücken gibt,
sollten wir diese füllen.

833
00:41:26.200 --> 00:41:28.360
Aber ich sehe keinen
dringenden Handlungsbedarf.

834
00:41:28.440 --> 00:41:30.680
Es kommt in diesem Bereich
zu Datenschutzverletzungen,

835
00:41:30.760 --> 00:41:33.000
Verletzungen der Privatsphäre.

836
00:41:33.080 --> 00:41:35.160
Jedes Mal, wenn wir ChatGPT nutzen,

837
00:41:35.240 --> 00:41:37.360
verletzen wir die Urheberrechte
von jemandem.

838
00:41:37.440 --> 00:41:39.640
Das schmerzt vielleicht Sie nicht,

839
00:41:39.720 --> 00:41:41.720
aber wer als Künstler/-in
von den Einnahmen

840
00:41:41.800 --> 00:41:43.880
der eigenen rechtlich geschützten
Werke abhängig ist,

841
00:41:43.960 --> 00:41:45.960
den schmerzt das sehr.

842
00:41:46.040 --> 00:41:48.040
Das bedroht Existenzen.

843
00:41:48.120 --> 00:41:50.200
Hier gibt es
einen grossen Handlungsbedarf.

844
00:41:50.280 --> 00:41:52.520
Die Nichtregierungsorganisation
AlgorithmWatch

845
00:41:52.600 --> 00:41:54.960
hat meines Erachtens
sehr sinnvolle Vorschläge gemacht.

846
00:41:55.040 --> 00:41:57.160
Sie sagte,
man solle Schäden verhindern,

847
00:41:57.240 --> 00:41:59.680
an Mensch, Demokratie,
Gesellschaft und Umwelt

848
00:41:59.760 --> 00:42:02.280
und zweitens dafür sorgen,
dass alle davon profitieren

849
00:42:02.360 --> 00:42:06.880
und nicht nur ein paar wenige
multinationale Technologiekonzerne.

850
00:42:06.960 --> 00:42:11.000
Es gibt auch viele Unternehmen, die
sagen, da muss man dagegenhalten.

851
00:42:11.080 --> 00:42:13.520
Es geht auch darum, die Schweizer
Wirtschaft zu schützen.

852
00:42:13.600 --> 00:42:16.760
Und im ganzen Bildungsbereich
haben wir Wildwuchs.

853
00:42:16.840 --> 00:42:19.680
Auch wenn keine Studie zeigt,

854
00:42:19.760 --> 00:42:24.160
dass Bildschirmzeit
den Bildungserfolg dient,

855
00:42:24.240 --> 00:42:28.280
obwohl keine Studie zeigt,
dass es den Lernprozess fördert,

856
00:42:28.360 --> 00:42:32.600
sondern im Gegenteil kognitive Fä-
higkeiten degenerieren, verringern,

857
00:42:32.680 --> 00:42:36.440
implementieren wir
die Technologien in der Schule.

858
00:42:36.520 --> 00:42:38.720
Ich würde dafür argumentieren,

859
00:42:38.800 --> 00:42:40.920
dass man in Schulen
bildschirmfreie Oasen schafft.

860
00:42:41.000 --> 00:42:43.880
Wieso? Eine Sorge müssen wir uns
nicht mehr machen.

861
00:42:43.960 --> 00:42:46.960
Nämlich, dass Kinder und Jugendliche

862
00:42:47.040 --> 00:42:49.320
zu wenig Zeit
vor dem Bildschirm verbringen.

863
00:42:49.400 --> 00:42:51.440
<font color="#00ffff">Was wir sowieso nicht wollen, ist,</font>

864
00:42:51.520 --> 00:42:53.600
<font color="#00ffff">über Kinder und Jugendliche</font>
<font color="#00ffff">sprechen.</font>

865
00:42:53.680 --> 00:42:55.640
<font color="#00ffff">Wir werden in einer Viertelstunde</font>

866
00:42:55.720 --> 00:42:57.880
<font color="#00ffff">hier hinten</font>
<font color="#00ffff">mit Ronny und Yuri sprechen,</font>

867
00:42:57.960 --> 00:43:00.080
<font color="#00ffff">die sagen,</font>
<font color="#00ffff">was sie wirklich machen von dem,</font>

868
00:43:00.160 --> 00:43:02.640
<font color="#00ffff">was wir hier vorne behaupten.</font>
<font color="#00ffff">Das gibt einen Realitätsscheck.</font>

869
00:43:02.720 --> 00:43:04.760
<font color="#00ffff">Ich weiss, was Sie sagen wollten.</font>

870
00:43:04.840 --> 00:43:06.920
Nein, ich wollte
etwas anderes sagen.

871
00:43:07.000 --> 00:43:09.120
<font color="#00ffff">Doch, Sie sprachen</font>
<font color="#00ffff">von bildschirmfreien Oasen.</font>

872
00:43:09.200 --> 00:43:11.600
Ja, aber es ist interessant ...
<font color="#00ffff">- Was heisst dass für Sie?</font>

873
00:43:11.680 --> 00:43:13.720
<font color="#00ffff">Haben Sie sich selbst</font>
<font color="#00ffff">ein ChatGPT-Verbot auferlegt?</font>

874
00:43:13.800 --> 00:43:16.280
Nein, ich brauche es einfach nicht
und zwar aus zwei Gründen:

875
00:43:16.360 --> 00:43:18.520
ChatGPT und andere aktuelle Produkte
in diesem Bereich

876
00:43:18.600 --> 00:43:20.600
haben kein Wahrheitskriterium.

877
00:43:20.680 --> 00:43:22.840
Es ist eigentlich völlig egal,
was gesagt wird,

878
00:43:22.920 --> 00:43:24.960
Hauptsache, es wird etwas gesagt.

879
00:43:25.040 --> 00:43:27.000
Das Zweite sind
Urheberrechtsverletzungen

880
00:43:27.080 --> 00:43:28.680
und Datenschutzverletzungen.

881
00:43:28.760 --> 00:43:30.360
Das kann man verbessern.

882
00:43:31.560 --> 00:43:33.920
Das muss aber erst einmal geschehen.

883
00:43:34.000 --> 00:43:36.760
<font color="#00ffff">Frau Rühl, ich habe gehört, Sie</font>
<font color="#00ffff">wollen die Wirtschaft schützen.</font>

884
00:43:36.840 --> 00:43:39.240
<font color="#00ffff">Das stimmt.- Da müssen Sie jetzt</font>
<font color="#00ffff">ein bisschen lachen.</font>

885
00:43:39.320 --> 00:43:42.480
Nein, es ist natürlich meine
Aufgabe, die Wirtschaft zu schützen

886
00:43:42.560 --> 00:43:44.720
und für gute Bedingungen zu sorgen.

887
00:43:44.800 --> 00:43:46.840
<font color="#00ffff">Ich meinte, dass er Sie</font>
<font color="#00ffff">auch schützen wollte.</font>

888
00:43:46.920 --> 00:43:49.360
Das ist super, danke vielmals.

889
00:43:49.440 --> 00:43:51.600
Sie haben viele Beispiele gebracht.

890
00:43:51.680 --> 00:43:53.760
Aber wir haben
ein Datenschutzgesetz,

891
00:43:53.840 --> 00:43:55.880
Persönlichkeitsschutz,
Grundrechte in diesem Land.

892
00:43:55.960 --> 00:43:57.640
* Sie reden durcheinander.*

893
00:43:57.720 --> 00:43:59.880
Die Schweiz
ist kein rechtsfreier Raum.

894
00:43:59.960 --> 00:44:02.800
Zu dem, was Frau Hostetmann
zuvor sagte:

895
00:44:02.880 --> 00:44:07.280
Respektieren von Menschenrechten und
Demokratie, von Rechtsstaatlichkeit.

896
00:44:07.360 --> 00:44:10.400
Da gibt es eine Konvention
des Europarates,

897
00:44:10.480 --> 00:44:15.640
die der Bundesrat zu Ratifizierung
vorschlagen möchte.

898
00:44:15.720 --> 00:44:20.200
Manche Dinge muss man auf
internationaler Ebene regeln.

899
00:44:20.280 --> 00:44:24.520
Da ist der Europarat
das richtige Gremium.

900
00:44:24.600 --> 00:44:29.280
<font color="#00ffff">Dazu ein Beispiel: Vor kurzem wurde</font>
<font color="#00ffff">der Supercomputer Alps in Lugano</font>

901
00:44:29.360 --> 00:44:33.400
<font color="#00ffff">eingeweiht, von Bundesrat und</font>
<font color="#00ffff">Wirtschaftsminister Guy Parmelin</font>

902
00:44:33.480 --> 00:44:36.560
<font color="#00ffff">am nationalen Hochleistungs-</font>
<font color="#00ffff">rechenzentrum in Lugano.</font>

903
00:44:36.640 --> 00:44:39.400
<font color="#00ffff">Dieser Supercomputer</font>
<font color="#00ffff">kann z.B. in der Klimatologie</font>

904
00:44:39.480 --> 00:44:43.440
<font color="#00ffff">in einem Tag</font>
<font color="#00ffff">so viele Rechnungen durchführen,</font>

905
00:44:43.520 --> 00:44:47.040
<font color="#00ffff">für die ein normaler Laptop</font>
<font color="#00ffff">40'000 Jahre benötigen würde.</font>

906
00:44:47.120 --> 00:44:49.440
<font color="#00ffff">Herr Kirchschläger, Sie wollen</font>
<font color="#00ffff">mit angezogenen Handbremse</font>

907
00:44:49.520 --> 00:44:54.640
<font color="#ffffff">unterwegs sein?- Überhaupt nicht.</font>
Ich möchte nur präziser arbeiten.

908
00:44:54.720 --> 00:44:58.440
Ich wünsche mir,
dass wir genauer prüfen,

909
00:44:58.520 --> 00:45:01.920
was die ethisch positiven Potenziale
wären,

910
00:45:02.000 --> 00:45:04.120
auch von dem soeben
beschriebenen Beispiel.

911
00:45:04.200 --> 00:45:07.160
Gleichzeitig muss man die ethisch
negativen Risiken adressieren.

912
00:45:07.240 --> 00:45:10.120
Interessanterweise hat das
Jugendparlament des Kantons Luzern

913
00:45:10.200 --> 00:45:12.640
sich auf eine Petition
einigen müssen,

914
00:45:12.720 --> 00:45:16.240
die sie im offiziellen Parlament
einbringen durften.

915
00:45:16.320 --> 00:45:18.440
Worauf haben sie sich geeinigt?

916
00:45:18.520 --> 00:45:21.120
Einen obligatorischen Elternabend,

917
00:45:21.200 --> 00:45:23.640
um die Erwachsenen
darauf vorzubereiten,

918
00:45:23.720 --> 00:45:26.800
Kinder und Jugendliche
besser vor Social Media zu schützen,

919
00:45:26.880 --> 00:45:29.000
vor der damit verbundenen Sucht.

920
00:45:29.080 --> 00:45:31.520
Das müssen Sie sich einmal
auf der Zunge zergehen lassen.

921
00:45:31.600 --> 00:45:34.920
Hat es je eine Generation gegeben,
die die Eltern darum gebeten hat,

922
00:45:35.000 --> 00:45:37.760
sie vor dem Rauchen oder vor
dem Alkoholtrinken zu schützen?

923
00:45:37.840 --> 00:45:40.240
Das glaube ich nicht.

924
00:45:40.320 --> 00:45:43.080
Daran hat man aber gesehen,
wie dringend das Anliegen ist.

925
00:45:43.160 --> 00:45:46.040
Dass man das Suchtproblem im Bereich
von Social Media bekämpfen muss.

926
00:45:46.120 --> 00:45:48.720
Und das sagen nicht die Erwachsenen,
sondern die Jugendlichen selber.

927
00:45:48.800 --> 00:45:51.520
Das Jugendparlament
des Kantons Luzern,

928
00:45:51.600 --> 00:45:53.640
welches sich
auf diese Petition einigte.

929
00:45:53.720 --> 00:45:56.440
<font color="#00ffff">Sind Sie, Herr Kaufmann, eine Art</font>
<font color="#00ffff">Dealer, der die Sucht befriedigt?</font>

930
00:45:56.520 --> 00:45:59.200
Sie meinen
die Sucht nach Social Media?

931
00:45:59.280 --> 00:46:02.000
Herr Kirchschläger
spricht die Generation Z an.

932
00:46:02.080 --> 00:46:05.240
In vielen Fällen
hält sie uns einen Spiegel vor.

933
00:46:05.320 --> 00:46:07.560
Sie fragen z.B.,

934
00:46:07.640 --> 00:46:10.440
ob sie nicht möglicherweise ein
bisschen Teilzeit arbeiten können.

935
00:46:10.520 --> 00:46:12.600
Oder, ob es denn sinnstiftend sei,

936
00:46:12.680 --> 00:46:14.880
das ganze Leben lang
nur zu arbeiten.

937
00:46:14.960 --> 00:46:18.560
Sie stellen uns Fragen, die wir uns
vorher nie gestellt haben.

938
00:46:18.640 --> 00:46:21.920
Ich betrachte das als Chance.

939
00:46:22.000 --> 00:46:25.120
Social Media, die virtuellen Welten
sind so verlockend, so attraktiv,

940
00:46:25.200 --> 00:46:28.200
dass man sich überlegen muss ob das
nicht ein interessanter Aspekt ist.

941
00:46:28.240 --> 00:46:31.880
Die Generation Z stellt uns Fragen,
die wir vorher nicht gehört haben.

942
00:46:31.960 --> 00:46:35.440
Eine Chance für die Gesellschaft,
diese Dinge zu überdenken.

943
00:46:35.520 --> 00:46:40.640
Das sind keine Fragen,
die so noch nicht gestellt wurde.

944
00:46:40.720 --> 00:46:43.920
Und es ist nicht nur
die Generations Z,

945
00:46:44.000 --> 00:46:48.480
die gerne weniger arbeiten würde,
aber ohne Einbussen beim Lohn.

946
00:46:48.560 --> 00:46:51.960
Bei Social Media ist das Problem,

947
00:46:52.040 --> 00:46:56.640
dass die Daten durch die Konzerne
einfach abgezogen werden.

948
00:46:56.720 --> 00:47:01.240
Sie haben
die bestehenden Gesetze angeführt.

949
00:47:01.320 --> 00:47:06.440
Diese greifen aber nicht mehr
für die aktuelle Situation.

950
00:47:06.520 --> 00:47:10.680
<font color="#00ffff">Sie als JUSO haben</font>
<font color="#00ffff">auf die ganz grossen Fragen</font>

951
00:47:10.760 --> 00:47:13.880
<font color="#00ffff">ganz einfache Antworten,</font>
<font color="#00ffff">nämlich diese:</font>

952
00:47:20.280 --> 00:47:23.560
<font color="#00ffff">Enteignung, ernsthaft?</font>
- Ja, ernsthaft.

953
00:47:23.640 --> 00:47:26.000
Ich glaube, dass wir
als Gesellschaft

954
00:47:26.080 --> 00:47:28.560
die Kontrolle zurückholen müssen.

955
00:47:28.640 --> 00:47:32.640
Die KI hat
enorme Grenzen überschritten.

956
00:47:32.720 --> 00:47:35.520
Ich glaube,
dass wir noch zurückgehen können.

957
00:47:35.600 --> 00:47:39.320
Jetzt ist es
eine Frage der Transparenz,

958
00:47:39.400 --> 00:47:41.560
das ist der erste Schritt.

959
00:47:41.640 --> 00:47:44.280
Die Unternehmen
müssen Transparenz schaffen,

960
00:47:44.360 --> 00:47:47.680
wie die Algorithmen funktionieren,
welche Daten verwendet werden,

961
00:47:47.760 --> 00:47:50.920
was mit diesen Daten gemacht wird,

962
00:47:51.000 --> 00:47:56.040
damit die Gesellschaft dann darüber
entscheiden kann, ob sie das möchte,

963
00:47:56.120 --> 00:47:59.760
und wenn ja, welche Formen davon.
Das wäre wichtig.

964
00:47:59.840 --> 00:48:03.440
Die JUSO möchte einfach enteignen,

965
00:48:03.520 --> 00:48:09.000
KI-Unternehmen, Familienunternehmen
in der Schweiz enteignen.

966
00:48:09.080 --> 00:48:12.160
Es ist offenbar eine
flächendeckende Enteignung geplant.

967
00:48:12.240 --> 00:48:16.280
Die Schweizer Wirtschaft leistet
jedoch einen wichtigen Beitrag

968
00:48:16.360 --> 00:48:18.760
zu dieser Gesellschaft.

969
00:48:18.840 --> 00:48:21.640
Wenn Sie die Unternehmen
alle enteignen wollen,

970
00:48:21.720 --> 00:48:24.520
haben Sie keine Steuereinnahmen,
keine Arbeitsplätze,

971
00:48:24.600 --> 00:48:30.920
dann wird es uns allen schlechter
gehen. Wollen Sie das wirklich?

972
00:48:31.000 --> 00:48:33.560
Es geht um die Demokratie.

973
00:48:33.640 --> 00:48:36.120
Ich bin der Überzeugung,

974
00:48:36.200 --> 00:48:39.600
dass die Menschen überall im Leben
mitbestimmen können sollten.

975
00:48:39.680 --> 00:48:41.960
Das gilt auch für den Arbeitsplatz.

976
00:48:42.040 --> 00:48:44.240
Ich glaube,
unsere Produkte würden besser,

977
00:48:44.320 --> 00:48:46.520
wenn die Menschen
mitentscheiden könnten,

978
00:48:46.600 --> 00:48:49.200
wie diese hergestellt werden.

979
00:48:49.280 --> 00:48:52.160
Zusätzlich sollen Nutzer/-innen
mitentscheiden,

980
00:48:52.200 --> 00:48:55.480
ob sie wirklich wollen, dass ihre
Daten verwendet werden oder nicht.

981
00:48:55.560 --> 00:48:58.480
Frau Hostetmann, haben Sie einmal
in einem Unternehmen gearbeitet?

982
00:48:58.560 --> 00:49:00.760
Wissen Sie, wie dort
die Arbeitsprozesse sind?

983
00:49:00.840 --> 00:49:02.880
Wissen Sie dass man dort
zusammensitzt

984
00:49:02.960 --> 00:49:04.680
und gemeinsame
Entscheidungen trifft?

985
00:49:04.760 --> 00:49:07.320
Wissen Sie, dass man Produkte
gemeinsam entwickelt,

986
00:49:07.400 --> 00:49:11.000
dass man den Rat
der Wissenschaft einholt?

987
00:49:11.040 --> 00:49:14.400
Da werden nicht
von irgendwelchen Profiteuren

988
00:49:14.480 --> 00:49:17.720
einsame Entscheidungen getroffen.

989
00:49:17.800 --> 00:49:20.360
Solche Entscheidungen
werden gemeinsam getroffen.

990
00:49:20.440 --> 00:49:22.360
Sie skizzieren eine Weltbild,
das nicht der Realität entspricht.

991
00:49:22.440 --> 00:49:24.720
Ich finde es
ein lächerliches Argument,

992
00:49:24.800 --> 00:49:26.440
uns vorzuhalten,
wir hätten sie gearbeitet.

993
00:49:26.520 --> 00:49:29.080
Ich habe nie so viel Geld verdient
wie ein CEO

994
00:49:29.160 --> 00:49:32.240
oder auf dieser Ebene
mitbestimmen können. Das stimmt.

995
00:49:32.320 --> 00:49:36.160
Ich möchte behaupten, dass sich
dennoch gleich viel gearbeitet habe.

996
00:49:36.240 --> 00:49:41.520
Es geht nicht, dass solche Menschen
schlechter behandelt werden.

997
00:49:43.200 --> 00:49:46.200
<font color="#00ffff">Ich hole den Rat</font>
<font color="#00ffff">des Wissenschaftlers ein.</font>

998
00:49:46.280 --> 00:49:49.440
<font color="#00ffff">Ich möchte nicht Ruhe reinbringen,</font>
<font color="#00ffff">aber trotzdem dafür sorgen,</font>

999
00:49:49.520 --> 00:49:51.760
<font color="#00ffff">dass sich die Gemüter</font>
<font color="#00ffff">etwas beruhigen.</font>

1000
00:49:51.840 --> 00:49:54.960
<font color="#00ffff">Ist eine Balance zwischen Innovation</font>
<font color="#00ffff">und Regulierung möglich?</font>

1001
00:49:55.040 --> 00:49:57.800
<font color="#008000">Ja, ich halte das</font>
<font color="#008000">jederzeit für möglich.</font>

1002
00:49:57.880 --> 00:50:00.920
<font color="#008000">Es ist nicht das erste Mal,</font>
<font color="#008000">dass wir neue Technologien erfinden.</font>

1003
00:50:01.000 --> 00:50:04.280
<font color="#008000">Vielleicht ist es das letzte Mal,</font>
<font color="#008000">das steht noch in den Sternen.</font>

1004
00:50:04.400 --> 00:50:08.240
<font color="#008000">Man muss immer eine Balance finden</font>
<font color="#008000">zwischen Innovation und Regulierung.</font>

1005
00:50:08.320 --> 00:50:12.320
<font color="#008000">Die Frage ist wo man da ansetzt,</font>

1006
00:50:12.400 --> 00:50:15.160
<font color="#008000">darüber gehen</font>
<font color="#008000">die Meinungen auseinander.</font>

1007
00:50:15.240 --> 00:50:18.920
<font color="#008000">Ich habe das Gefühl wir schmeissen</font>
<font color="#008000">ein paar Dinge in den gleichen Topf,</font>

1008
00:50:19.000 --> 00:50:22.280
<font color="#008000">soziale Medien und KI muss man schon</font>
<font color="#008000">ein bisschen unterscheiden.</font>

1009
00:50:22.360 --> 00:50:25.360
<font color="#008000">Die KI ist im Moment</font>
<font color="#008000">sehr stark unterwegs.</font>

1010
00:50:25.440 --> 00:50:28.240
<font color="#008000">Die Menschen haben</font>
<font color="#008000">ein Bedürfnis nach Transparenz.</font>

1011
00:50:28.320 --> 00:50:31.520
<font color="#008000">Sie haben gerade Lugano gezeigt.</font>

1012
00:50:31.600 --> 00:50:34.320
<font color="#008000">Das ist wirklich</font>
<font color="#008000">etwas Interessantes für die Schweiz,</font>

1013
00:50:34.400 --> 00:50:36.880
<font color="#008000">dass sie jetzt diese Rechner hat,</font>

1014
00:50:36.960 --> 00:50:39.160
<font color="#008000">die der Forschung</font>
<font color="#008000">zur Verfügung stehen.</font>

1015
00:50:39.240 --> 00:50:41.640
<font color="#008000">Wir trainieren nun</font>
<font color="#008000">unsere eigenen Modelle</font>

1016
00:50:41.720 --> 00:50:43.960
<font color="#008000">und sind völlig offen</font>
<font color="#008000">und transparent.</font>

1017
00:50:44.040 --> 00:50:46.840
<font color="#008000">Diese können wir dann der</font>
<font color="#008000">Gesellschaft und der Wirtschaft</font>

1018
00:50:46.920 --> 00:50:49.080
<font color="#008000">zur Verfügung stellen.</font>

1019
00:50:49.160 --> 00:50:51.760
<font color="#008000">Mir scheint, da haben wir</font>
<font color="#008000">ein gutes Mittelmass gefunden.</font>

1020
00:50:51.840 --> 00:50:55.560
<font color="#008000">In der Wirtschaft handelt es sich</font>
<font color="#008000">da um Geschäftsgeheimnisse,</font>

1021
00:50:55.640 --> 00:50:58.520
<font color="#008000">dass kann man auch verstehen.</font>

1022
00:50:58.600 --> 00:51:01.040
<font color="#008000">Die Balance ist im Moment gesund.</font>

1023
00:51:01.120 --> 00:51:04.840
<font color="#00ffff">Sie sind ein bisschen der Schieds-</font>
<font color="#00ffff">richter in dieser Diskussion heute.</font>

1024
00:51:04.920 --> 00:51:07.840
<font color="#008000">Ich habe meine Karten vergessen.</font>

1025
00:51:07.920 --> 00:51:10.200
<font color="#00ffff">Wenn Sie das Wort Enteignung hören,</font>

1026
00:51:10.280 --> 00:51:12.600
<font color="#00ffff">sträuben sich bei Ihnen</font>
<font color="#00ffff">schon die Nackenhaare, oder?</font>

1027
00:51:13.680 --> 00:51:16.000
<font color="#008000">Ja.</font>
<font color="#00ffff">- Okay.</font>

1028
00:51:16.080 --> 00:51:19.120
<font color="#008000">Wir leben in einer Gesellschaft,</font>
<font color="#008000">in der wir alle es sehr schätzen,</font>

1029
00:51:19.200 --> 00:51:23.880
<font color="#008000">dass es Privateigentum gibt.</font>

1030
00:51:23.960 --> 00:51:28.760
<font color="#008000">Durch die Demokratie</font>
<font color="#008000">findet die Schweiz</font>

1031
00:51:28.840 --> 00:51:33.040
<font color="#008000">immer einen guten Mittelweg.</font>

1032
00:51:33.120 --> 00:51:38.320
<font color="#008000">Als Gesellschaft fragen wir uns,</font>
<font color="#008000">wie wir das regeln.</font>

1033
00:51:38.400 --> 00:51:40.640
<font color="#008000">Wir wollen ja keine Anarchie.</font>

1034
00:51:40.720 --> 00:51:42.800
<font color="#008000">Das Gesundheitssystem</font>
<font color="#008000">ist ein Beispiel,</font>

1035
00:51:42.880 --> 00:51:45.280
<font color="#008000">an dem wir gemeinsam arbeiten,</font>
<font color="#008000">oder das Bildungssystem.</font>

1036
00:51:45.360 --> 00:51:47.400
<font color="#008000">Dann gibt es andere Bereiche,</font>
<font color="#008000">bei denen wir sagen,</font>

1037
00:51:47.440 --> 00:51:49.640
<font color="#008000">die sind in der Zuständigkeit</font>
<font color="#008000">der Einzelnen.</font>

1038
00:51:49.720 --> 00:51:51.880
<font color="#008000">Da suchen wir immer wieder</font>
<font color="#008000">eine Balance.</font>

1039
00:51:51.960 --> 00:51:54.560
<font color="#00ffff">Was ist Ihre Erwartung an den</font>
<font color="#00ffff">Bundesrat bis Ende des Jahres?</font>

1040
00:51:54.640 --> 00:51:57.320
<font color="#008000">Bis Ende des Jahres</font>
<font color="#008000">erwarten wir eigentlich nichts.</font>

1041
00:51:57.400 --> 00:52:01.120
<font color="#008000">Mittelfristig</font>
<font color="#008000">erwarten wir als Forscher</font>

1042
00:52:01.200 --> 00:52:05.200
<font color="#008000">eine gute Forschungslandschaft.</font>

1043
00:52:05.280 --> 00:52:10.800
<font color="#008000">Der Rotstift ist im Moment</font>
<font color="#008000">die treibende Kraft in der Politik.</font>

1044
00:52:10.880 --> 00:52:15.320
<font color="#008000">Das ist heikel, ich habe dennoch</font>
<font color="#008000">Verständnis für balancierte Budgets.</font>

1045
00:52:15.400 --> 00:52:20.240
<font color="#008000">Aber wir befinden uns in einer</font>
<font color="#008000">extrem aussergewöhnlichen Situation,</font>

1046
00:52:20.320 --> 00:52:23.280
<font color="#008000">wahrscheinlich historisch,</font>

1047
00:52:23.360 --> 00:52:26.240
<font color="#008000">wenn wir zurückschauen</font>
<font color="#008000">und dann sagen müssen,</font>

1048
00:52:26.320 --> 00:52:28.640
<font color="#008000">dass wir den Anschluss</font>
<font color="#008000">verpasst haben,</font>

1049
00:52:28.720 --> 00:52:31.880
<font color="#008000">weil gerade Rotstiftsession war,</font>
<font color="#008000">würde mir das Sorgen machen.</font>

1050
00:52:31.960 --> 00:52:33.960
<font color="#00ffff">Sie sagen auch,</font>

1051
00:52:34.040 --> 00:52:38.040
<font color="#00ffff">dass wir auch die Digitalisierung</font>
<font color="#00ffff">schon verschlafen hätten.</font>

1052
00:52:38.120 --> 00:52:40.800
<font color="#008000">Es ist nicht umsonst, dass wir</font>
<font color="#008000">in der Schweiz und in Europa</font>

1053
00:52:40.880 --> 00:52:43.480
<font color="#008000">von der digitalen Souveränität</font>
<font color="#008000">sprechen,</font>

1054
00:52:43.560 --> 00:52:46.200
<font color="#008000">weil wir dieses Thema ein bisschen</font>
<font color="#008000">verpasst haben, das stimmt.</font>

1055
00:52:46.280 --> 00:52:48.400
<font color="#00ffff">Wie gross ist die Gefahr,</font>
<font color="#00ffff">Herr Kaufmann,</font>

1056
00:52:48.480 --> 00:52:50.680
<font color="#00ffff">dass wir den Anschluss verschlafen?</font>

1057
00:52:50.760 --> 00:52:53.240
<font color="#00ffff">Sie sagen, wir können</font>
<font color="#00ffff">genau so gut sein wie die Amerikaner</font>

1058
00:52:53.320 --> 00:52:55.480
<font color="#00ffff">auch unter Donald Trump</font>
<font color="#00ffff">als Präsident,</font>

1059
00:52:55.560 --> 00:52:57.880
<font color="#00ffff">und dass wir</font>
<font color="#00ffff">auch mit den Chinesen mithalten.</font>

1060
00:52:57.960 --> 00:53:00.320
Da geht es um so etwas
wie Wirtschaftsnationalismus,

1061
00:53:00.400 --> 00:53:02.880
wenn man sagt, gewisse Produkte

1062
00:53:02.960 --> 00:53:05.080
werden in einem Land eingesetzt
oder nicht.

1063
00:53:05.160 --> 00:53:07.720
Oder wenn man in der Schweiz
amerikanische Systeme einsetzt,

1064
00:53:07.800 --> 00:53:10.440
werden die plötzlich viel teurer.

1065
00:53:10.520 --> 00:53:15.480
Wir müssen die Abhängigkeit
von Technologien aus fremden Ländern

1066
00:53:15.560 --> 00:53:18.200
reduzieren, v.a. mit Blick
auf die geopolitische Lage.

1067
00:53:18.280 --> 00:53:21.120
Als Schweiz können wir Vorbild sein,
wie man es besser machen kann.

1068
00:53:21.200 --> 00:53:23.360
Transparente Systeme, Open Source.

1069
00:53:23.440 --> 00:53:25.520
Wir haben auch
neuartige Algorithmen,

1070
00:53:25.600 --> 00:53:27.720
die nicht so viel Energie brauchen.

1071
00:53:27.800 --> 00:53:30.160
Für die man nicht riesige
Rechenzentren und AKW bauen muss.

1072
00:53:30.240 --> 00:53:32.360
Die Schweiz
hat einige Beispieltechnologien,

1073
00:53:32.440 --> 00:53:34.480
die wir in der Welt
positionieren könnten.

1074
00:53:34.560 --> 00:53:37.320
Zudem sind wir Vermittler,
wir sind neutral in der Welt.

1075
00:53:37.400 --> 00:53:39.680
Eine ausgezeichnete Ausgangslage,

1076
00:53:39.760 --> 00:53:42.520
um im KI-Rennen
eine Führungsrolle zu übernehmen.

1077
00:53:42.600 --> 00:53:46.080
<font color="#00ffff">Stehen da so Leute</font>
<font color="#00ffff">wie Herr Kirchschläger im Weg?</font>

1078
00:53:46.160 --> 00:53:48.440
Nein, im Gegenteil.

1079
00:53:48.520 --> 00:53:52.400
Gerade weil wir in der Schweiz
in der KI-Forschung mitführend sind,

1080
00:53:52.480 --> 00:53:56.720
plädiere ich für eine Verbindung mit
der sog. menschenrechtsbasierten KI.

1081
00:53:56.800 --> 00:53:59.800
Menschenrechte sind schliesslich

1082
00:53:59.880 --> 00:54:02.480
einer der aussenpolitischen Pfeiler
der Schweiz.

1083
00:54:02.560 --> 00:54:04.840
Wir können also zeigen,
wie es funktioniert,

1084
00:54:04.920 --> 00:54:07.200
wenn man menschenrechtsbasiert KI
entwickelt.

1085
00:54:07.280 --> 00:54:09.360
Und zwar über alle Lebensphasen
der KI.

1086
00:54:09.440 --> 00:54:12.080
Da geht es um die Rohstoffschürfung,
Billigproduktionsstandorte,

1087
00:54:12.160 --> 00:54:14.400
die menschenrechtskonform
betrieben werden müssten.

1088
00:54:14.480 --> 00:54:17.400
Es geht um die Nutzung, und teils
auch aus Gründen der Menschenrechte

1089
00:54:17.480 --> 00:54:19.680
um die Nichtnutzung
von KI-Möglichkeiten.

1090
00:54:19.760 --> 00:54:21.800
Allerdings
muss man auch realistisch sein.

1091
00:54:21.880 --> 00:54:24.480
Wenn man menschenrechtsbasiert
eine globale Regulierung möchte,

1092
00:54:24.560 --> 00:54:27.000
was ich basierend auf
meiner Forschung vorschlagen möchte,

1093
00:54:27.080 --> 00:54:29.360
braucht es auch eine globale
Durchsetzungsinstitution,

1094
00:54:29.440 --> 00:54:32.280
sonst ist die Regulierung das Papier
nicht wert, auf dem sie steht.

1095
00:54:32.360 --> 00:54:34.520
Die multinationalen Techkonzerne

1096
00:54:34.600 --> 00:54:37.720
werden nicht
auf die Regulierung eingehen.

1097
00:54:37.800 --> 00:54:40.160
Sie werden so lange
die Regeln verletzen,

1098
00:54:40.240 --> 00:54:42.440
wie der Gewinn höher ist
als die Strafe.

1099
00:54:42.520 --> 00:54:44.880
Es braucht
eine Durchsetzungsinstitution.

1100
00:54:44.960 --> 00:54:48.960
Eine internationale datenbasierte
Systemagentur, Abkürzung IDA,

1101
00:54:49.040 --> 00:54:51.240
bei der UNO.

1102
00:54:51.320 --> 00:54:54.760
Sie würde dem Modell der Interna-
tionalen Atomenergiebehörde folgen.

1103
00:54:54.840 --> 00:54:58.280
Kurz der Vergleich: Was haben wir
in der Nukleartechnologie gemacht?

1104
00:54:58.360 --> 00:55:01.400
Wir haben geforscht,
die Atombombe gebaut,

1105
00:55:01.480 --> 00:55:04.240
sie ein paarmal eingesetzt,
und dann hat man gemerkt,

1106
00:55:04.320 --> 00:55:06.680
wenn man so weiter macht,

1107
00:55:06.760 --> 00:55:09.480
gibt es bald die Menschheit
und den Planeten nicht mehr.

1108
00:55:09.560 --> 00:55:11.960
Dann wurde die Internationale
Atomenergiebehörde geschaffen.

1109
00:55:12.040 --> 00:55:14.320
Sie ist nicht perfekt,
insbesondere von Supermächten

1110
00:55:14.400 --> 00:55:16.840
wird sie
für eigene Interessen missbraucht.

1111
00:55:16.920 --> 00:55:19.160
Aber man muss zugeben,
dass es ihr gelungen ist,

1112
00:55:19.240 --> 00:55:21.320
Schlimmeres zu verhindern.

1113
00:55:21.400 --> 00:55:23.480
Das wäre auch eine Aufgabe der IDA.

1114
00:55:23.560 --> 00:55:26.320
<font color="#00ffff">IDA wäre also die internationale</font>
<font color="#00ffff">Datenagentur, die Ihnen vorschwebt.</font>

1115
00:55:26.400 --> 00:55:29.160
<font color="#00ffff">Die Atombombe mit der KI</font>
<font color="#00ffff">zu vergleichen,</font>

1116
00:55:29.240 --> 00:55:31.640
<font color="#00ffff">ist allerdings</font>
<font color="#00ffff">ein steiler Vergleich.</font>

1117
00:55:31.720 --> 00:55:35.360
Wie gesagt, es gibt ein riesiges
ethisch positives Potenzial.

1118
00:55:35.440 --> 00:55:37.840
Das sei
in aller Deutlichkeit gesagt.

1119
00:55:37.920 --> 00:55:40.480
Gleichzeitig haben wir aber
auch die Herausforderung,

1120
00:55:40.560 --> 00:55:45.000
dass jemand ein automatisiertes
Waffensystem tödlicher Natur baut

1121
00:55:45.080 --> 00:55:48.640
und damit grossen Schaden anrichtet.

1122
00:55:48.720 --> 00:55:51.920
Wir können nicht so tun, als ob
dieses Risiko nicht bestünde.

1123
00:55:52.000 --> 00:55:55.640
Ich komme zurück zur App,
die Kinderbilder sexualisiert ...

1124
00:55:55.720 --> 00:55:58.360
<font color="#00ffff">Diese haben Sie ganz am Anfang</font>
<font color="#00ffff">der Sendung angesprochen.</font>

1125
00:55:58.440 --> 00:56:01.480
Wenn wir die IDA hätten, käme so
etwas überhaupt nicht auf den Markt.

1126
00:56:01.560 --> 00:56:03.840
Die IDA hätte die
Marktzulassungsfunktion,

1127
00:56:03.920 --> 00:56:06.800
die wir aus der Pharmaindustrie
als selbstverständlich kennen.

1128
00:56:06.840 --> 00:56:09.120
Dass zuerst eine Test
durchlaufen werden muss,

1129
00:56:09.200 --> 00:56:12.160
ob ein Medikament nicht schädlich
ist für den Menschen oder die Natur,

1130
00:56:12.240 --> 00:56:14.440
bevor man es auf den Markt
bringen darf.

1131
00:56:14.520 --> 00:56:16.640
<font color="#00ffff">IDA wäre also eine Agentur,</font>

1132
00:56:16.720 --> 00:56:19.080
<font color="#00ffff">die sicherstellt, dass es</font>
<font color="#00ffff">menschenrechtsbasierte KI gibt.</font>

1133
00:56:19.160 --> 00:56:21.200
<font color="#00ffff">Was halten Sie davon?</font>

1134
00:56:21.280 --> 00:56:24.200
Wir befinden uns in einer Krise
des Multilateralismus.

1135
00:56:24.280 --> 00:56:26.880
Die Geopolitik
ist extrem angespannt.

1136
00:56:26.960 --> 00:56:31.360
Ich glaube nicht, dass eine solche
Institution zum jetzigen Zeitpunkt

1137
00:56:31.440 --> 00:56:33.600
errichtet werden kann,

1138
00:56:33.680 --> 00:56:35.960
dass sich die Länder
darauf einigen könnten.

1139
00:56:36.040 --> 00:56:39.440
Sie schiessen ja immer
auf Unternehmen.

1140
00:56:39.520 --> 00:56:41.840
(Kirchschläger)
Ein paar Unternehmen.

1141
00:56:41.920 --> 00:56:47.200
Diese Unternehmen
haben ihren Sitz in den USA.

1142
00:56:47.280 --> 00:56:50.600
Und auch die USA
sind ein Rechtsstaat.

1143
00:56:50.680 --> 00:56:53.840
Die USA muss diese Unternehmen
überwachen,

1144
00:56:53.920 --> 00:56:59.160
damit sie die amerikanischen und
internationalen Gesetze einhalten.

1145
00:56:59.240 --> 00:57:03.240
Eines dieser Unternehmen muss nun
wegen seiner Monopolstellung

1146
00:57:03.320 --> 00:57:07.640
einen Teil seiner Aktivitäten
verkaufen.

1147
00:57:07.720 --> 00:57:12.640
Statt dass man auf der multila-
teralen Ebene ein Konstrukt baut,

1148
00:57:12.720 --> 00:57:16.920
muss man, glaube ich, auf die
Rechtsstaatlichkeit in den Ländern,

1149
00:57:17.000 --> 00:57:20.000
in denen diese Unternehmen
ansässig sind, setzen.

1150
00:57:20.080 --> 00:57:25.960
Mit IDA setzt man ja
auf die Rechtsstaatlichkeit.

1151
00:57:26.040 --> 00:57:26.160
KI ist jedoch ein globales Phänomen.

1152
00:57:26.240 --> 00:57:29.480
In den USA ist es so, dass
einzelne Bundesstaaten nun beginnen,

1153
00:57:29.560 --> 00:57:32.400
eigene KI-Regulierungen
zu entwickeln,

1154
00:57:32.480 --> 00:57:34.880
um diese dann auf die Gesamtebene
in den USA zu bringen.

1155
00:57:34.960 --> 00:57:37.320
Das ist sicher nicht
im Interesse der Unternehmen,

1156
00:57:37.400 --> 00:57:41.040
dass man für jeden US-Bundesstaat
ein eigenes Produkt basteln muss.

1157
00:57:41.120 --> 00:57:46.160
Ich glaube, der grösste Teil der
Unternehmen hat keine Freude daran,

1158
00:57:46.240 --> 00:57:50.640
dass eine
Kinderbilder sexualisierende App

1159
00:57:50.720 --> 00:57:55.120
legal auf den Markt
gebracht werden kann.

1160
00:57:55.200 --> 00:57:57.400
(Rühl) Davon hat niemand gesprochen.

1161
00:57:57.480 --> 00:57:59.760
(Kirchschläger)
Doch, aber es ist ein Phänomen.

1162
00:57:59.840 --> 00:58:02.440
(Kaufmann) Zum Mittel
der Regulierung greift man,

1163
00:58:02.520 --> 00:58:05.040
wenn man die Kompetenz nicht hat.

1164
00:58:05.120 --> 00:58:07.240
Ein Schutz, dass nicht einfach
reguliert wird,

1165
00:58:07.320 --> 00:58:09.640
weil wir die Kompetenzen
nicht haben ...

1166
00:58:09.720 --> 00:58:12.120
Und die Schweiz ist in diesen Themen
extrem kompetent.

1167
00:58:12.200 --> 00:58:14.920
Wir sind in der Lage,
eine eigene Regulierung zu machen.

1168
00:58:15.000 --> 00:58:18.920
Wenn wir die Kompetenz nicht aufbau-
en und das andere geschehen lassen,

1169
00:58:19.000 --> 00:58:21.520
dann werden wir reguliert.

1170
00:58:21.600 --> 00:58:24.680
Ich finde, dass man selber
Regulierungen entwickelt,

1171
00:58:24.760 --> 00:58:27.520
weil solche Regulierungen
kulturbestimmend sind.

1172
00:58:27.600 --> 00:58:32.840
(Hostetmann) Die Schweiz
soll kein Tech-El-Dorado werden.

1173
00:58:32.920 --> 00:58:37.240
Es braucht Regeln
und Rahmenbedingungen,

1174
00:58:37.320 --> 00:58:40.080
wie bei allen anderen Dingen auch.

1175
00:58:40.160 --> 00:58:43.440
Die Schweiz
hat das einfach verpasst.

1176
00:58:43.520 --> 00:58:46.240
Das muss möglichst schnell
nachgeholt werden.

1177
00:58:46.320 --> 00:58:50.160
Dafür müssen EU-Regeln
übernommen werden,

1178
00:58:50.240 --> 00:58:53.720
aber es müssen auch Schlupflöcher
gestopft werden,

1179
00:58:53.800 --> 00:58:56.760
damit die Menschenrechte
garantiert werden können,

1180
00:58:56.840 --> 00:58:59.960
wie wir es hier jetzt auch
schon einige Male gehört haben.

1181
00:59:00.040 --> 00:59:03.040
<font color="#00ffff">Darf ich kurz? Vielleicht</font>
<font color="#00ffff">ist es auch in Ihrem Interesse.</font>

1182
00:59:03.120 --> 00:59:06.480
<font color="#00ffff">Frau Hostetmann sagte, die Schweiz</font>
<font color="#00ffff">solle kein Tech-El-Dorado werden.</font>

1183
00:59:06.560 --> 00:59:10.080
<font color="#00ffff">Wieso eigentlich nicht?</font>

1184
00:59:10.160 --> 00:59:12.480
Ich will,
dass die Schweiz führend wird.

1185
00:59:12.560 --> 00:59:16.480
El Dorado ist ein komischer Begriff.

1186
00:59:16.560 --> 00:59:18.640
Ich möchte,
dass die Schweiz führend wird,

1187
00:59:18.720 --> 00:59:20.800
und sie hat dafür
alle Voraussetzungen.

1188
00:59:20.880 --> 00:59:25.080
Der Supercomputer
ist ein wichtiges Element.

1189
00:59:25.160 --> 00:59:27.200
Ich will auch,

1190
00:59:27.280 --> 00:59:29.440
dass die Schweiz in der Forschung
Fortschritte macht,

1191
00:59:29.520 --> 00:59:31.960
aber das kann doch an öffentlichen
Universitäten passieren.

1192
00:59:32.040 --> 00:59:34.280
Es passiert heute schon
an öffentlichen Universitäten.

1193
00:59:34.320 --> 00:59:37.280
Das Problem ist, was mit dieser
Technologie hinterher passiert.

1194
00:59:37.360 --> 00:59:39.760
Da kommen wir zum wichtigsten Punkt
zurück.

1195
00:59:39.840 --> 00:59:44.800
Es geht darum, wem die Technologie
gehört und wer davon profitiert.

1196
00:59:44.880 --> 00:59:48.880
Ich finde, die KI soll für die
Menschen arbeiten, nicht gegen sie.

1197
00:59:48.960 --> 00:59:53.080
Absolut, die KI soll für,
nicht gegen den Menschen arbeiten.

1198
00:59:53.160 --> 00:59:57.200
Ich sehe aber kein Problem darin,

1199
00:59:57.280 --> 01:00:02.760
wenn die Besitzer solcher KI
Privatunternehmen sind.

1200
01:00:02.840 --> 01:00:06.280
Mich stört die Verteufelung
von Privatunternehmen.

1201
01:00:06.360 --> 01:00:10.160
Sie sprachen von Enteignung.

1202
01:00:10.240 --> 01:00:14.320
Wenn Sie meinen, dass der Staat
die Aufgabe besser erledigen könnte,

1203
01:00:14.400 --> 01:00:17.800
setze ich grössere Fragezeichen.

1204
01:00:17.880 --> 01:00:21.040
Schauen Sie einmal
die Entwicklung an,

1205
01:00:21.120 --> 01:00:23.240
die wir bei den Social Media
gehabt haben.

1206
01:00:23.360 --> 01:00:26.600
Man hat die Technologieunternehmen
schalten und walten lassen,

1207
01:00:26.680 --> 01:00:28.960
wir haben nichts gemacht.

1208
01:00:29.040 --> 01:00:31.160
Es gab keine Regulierung
seitens des Staates.

1209
01:00:31.240 --> 01:00:33.320
Was ist passiert?

1210
01:00:33.360 --> 01:00:36.480
Wir haben eine wachsende Sucht
unter den Jugendlichen.

1211
01:00:36.560 --> 01:00:38.680
Die neueste WHO-Studie
vom September 2024

1212
01:00:38.760 --> 01:00:40.840
spricht von einer wachsenden Sucht.

1213
01:00:40.920 --> 01:00:43.160
(Rühl) Wollen Sie das wegregulieren?

1214
01:00:43.240 --> 01:00:45.800
<font color="#00ffff">Jetzt darf er auch ausreden.</font>
- Er hat mehrfach unterbrochen.

1215
01:00:45.880 --> 01:00:49.280
<font color="#00ffff">Ich habe es versucht ...</font>
- Ganz kurz mein Gedanke:

1216
01:00:49.360 --> 01:00:52.440
wir haben
ein wachsendes Suchtphänomen,

1217
01:00:52.520 --> 01:00:56.680
mentale Gesundheitsprobleme
bei Kindern und Jugendlichen,

1218
01:00:56.760 --> 01:00:59.200
eine wachsende Suizidrate.

1219
01:00:59.280 --> 01:01:01.800
Es ist auch keine gute Idee

1220
01:01:01.880 --> 01:01:03.840
aus schweizerischer
und europäischer Perspektive,

1221
01:01:03.920 --> 01:01:06.360
die politische Bildung von Kindern
und Jugendlichen

1222
01:01:06.440 --> 01:01:08.480
TikTok zu überlassen.

1223
01:01:08.560 --> 01:01:10.760
Wir müssen verhindern,
dass Social Media,

1224
01:01:10.840 --> 01:01:13.440
die eigentlich
als asoziale Medien gebaut wurden,

1225
01:01:13.520 --> 01:01:16.920
um Kinder und Jugendliche abhängig
zu machen, das übernehmen.

1226
01:01:17.000 --> 01:01:20.880
Es ist auch nicht im Interesse der
grossen Mehrheit der Unternehmen.

1227
01:01:20.960 --> 01:01:23.240
V.a. nicht der Unternehmerinnen
und Unternehmer,

1228
01:01:23.320 --> 01:01:25.720
denn die haben auch Kinder
und Jugendliche.

1229
01:01:25.800 --> 01:01:29.240
Ich erinnere an das Jugendparlament
des Kantons Luzern,

1230
01:01:29.320 --> 01:01:33.200
das uns sagt, sie wünschen sich,
besser geschützt zu sein.

1231
01:01:33.280 --> 01:01:35.400
<font color="#00ffff">Danke für diesen Steilpass.</font>

1232
01:01:35.480 --> 01:01:37.800
<font color="#00ffff">Denn jetzt gehen wir</font>
<font color="#00ffff">zu unseren Jugendlichen.</font>

1233
01:01:37.880 --> 01:01:40.880
<font color="#00ffff">Wie andere SRF-Gefässe im Fernsehen,</font>
<font color="#00ffff">Radio und online nimmt sich</font>

1234
01:01:40.960 --> 01:01:43.720
<font color="#00ffff">die "Arena" in dieser Themenwoche</font>
<font color="#00ffff">der Frage an,</font>

1235
01:01:43.800 --> 01:01:46.800
<font color="#00ffff">was künstliche Intelligenz</font>
<font color="#00ffff">für uns alle bedeutet.</font>

1236
01:01:46.880 --> 01:01:49.560
<font color="#00ffff">Man könnte davon ausgehen,</font>
<font color="#00ffff">dass jüngere Menschen</font>

1237
01:01:49.640 --> 01:01:51.800
<font color="#00ffff">der Technologie</font>
<font color="#00ffff">offener gegenüberstehen</font>

1238
01:01:51.880 --> 01:01:54.040
<font color="#00ffff">und auch ein bisschen mehr Ahnung</font>
<font color="#00ffff">davon haben</font>

1239
01:01:54.120 --> 01:01:56.320
<font color="#00ffff">als ältere Semester wie ich.</font>

1240
01:01:56.400 --> 01:01:58.880
<font color="#00ffff">Wir machen also den Reality Check</font>

1241
01:01:58.960 --> 01:02:01.600
<font color="#00ffff">mit zwei Schülern der Kantonsschule</font>
<font color="#00ffff">Zürich Oberland in Wetzikon.</font>

1242
01:02:02.840 --> 01:02:05.080
<font color="#00ffff">Bei uns sind Ronny Siegenthaler, 17,</font>
<font color="#00ffff">aus Gossau</font>

1243
01:02:05.160 --> 01:02:07.320
<font color="#00ffff">und Yuri Kaspar, 18, aus Bauma.</font>

1244
01:02:07.400 --> 01:02:09.560
<font color="#00ffff">Beide sind im letzten Gymi-Jahr.</font>

1245
01:02:09.640 --> 01:02:11.680
<font color="#00ffff">So schnell geht es</font>
<font color="#00ffff">und man ist Teil dieser "Arena".</font>

1246
01:02:11.760 --> 01:02:12.960
<font color="#00ffff">Willkommen.</font>

1247
01:02:13.040 --> 01:02:15.160
<font color="#00ffff">Wir haben vorhin abgemacht,</font>
<font color="#00ffff">dass wir uns duzen,</font>

1248
01:02:15.240 --> 01:02:17.360
<font color="#00ffff">das gilt natürlich gegenseitig.</font>

1249
01:02:17.440 --> 01:02:19.560
<font color="#00ffff">Yuri, ist künstliche Intelligenz</font>
<font color="#00ffff">eine Sache,</font>

1250
01:02:19.680 --> 01:02:22.040
<font color="#00ffff">die dir das Leben</font>
<font color="#00ffff">einfacher macht in der Schule?</font>

1251
01:02:22.120 --> 01:02:24.320
<font color="#008000">Ja und nein.</font>

1252
01:02:24.400 --> 01:02:26.840
<font color="#008000">Ich würde sagen,</font>
<font color="#008000">es hat definitiv Chancen.</font>

1253
01:02:26.920 --> 01:02:29.480
<font color="#008000">Man kann Gruppenarbeiten,</font>
<font color="#008000">Podcast-Konzepte, Übersetzungen,</font>

1254
01:02:29.600 --> 01:02:34.400
<font color="#008000">Textüberarbeitungen, Bildmaterial</font>
<font color="#008000">wie Plakate mit KI machen,</font>

1255
01:02:34.480 --> 01:02:37.160
<font color="#008000">man kann damit Brainstorming machen.</font>

1256
01:02:37.240 --> 01:02:40.080
<font color="#008000">Nur muss man es am Schluss</font>
<font color="#008000">eben doch noch selber lernen,</font>

1257
01:02:40.160 --> 01:02:42.720
<font color="#008000">das kann einem KI nicht abnehmen.</font>

1258
01:02:42.800 --> 01:02:45.480
<font color="#008000">Da sehe ich auch</font>
<font color="#008000">die grösste Herausforderung.</font>

1259
01:02:45.560 --> 01:02:47.960
<font color="#008000">Das Risiko, dass man</font>
<font color="#008000">genügend Eigenverantwortung hat,</font>

1260
01:02:48.040 --> 01:02:51.440
<font color="#008000">um doch noch</font>
<font color="#008000">zum eigenen Lernerfolg beizutragen.</font>

1261
01:02:51.520 --> 01:02:53.920
<font color="#00ffff">Wie gross deine Eigenverantwortung</font>
<font color="#00ffff">ist, zeigt sich daran,</font>

1262
01:02:54.000 --> 01:02:59.120
<font color="#00ffff">dass du deine Maturaarbeit</font>
<font color="#00ffff">ohne KI geschrieben hast, oder?</font>

1263
01:02:59.200 --> 01:03:01.320
<font color="#008000">Bewusst, ja.</font>

1264
01:03:01.440 --> 01:03:03.920
<font color="#008000">Es war mit gewissen Richtlinien</font>
<font color="#008000">in der Schule erlaubt,</font>

1265
01:03:04.040 --> 01:03:06.680
<font color="#008000">KI als Quellenangabe zu zitieren.</font>

1266
01:03:06.760 --> 01:03:09.080
<font color="#008000">Ich habe mich bewusst</font>
<font color="#008000">dagegen entschieden</font>

1267
01:03:09.160 --> 01:03:12.440
<font color="#008000">und einfach herkömmliche Studien</font>
<font color="#008000">genutzt.</font>

1268
01:03:12.520 --> 01:03:16.040
<font color="#008000">So kann ich am Ende sagen,</font>
<font color="#008000">dass das von mir ist.</font>

1269
01:03:16.120 --> 01:03:19.760
<font color="#00ffff">Das Stichwort Weg ist genial,</font>
<font color="#00ffff">denn sag selbst</font>

1270
01:03:19.840 --> 01:03:23.120
<font color="#00ffff">den Titel und die Untersuchung,</font>
<font color="#00ffff">die du gemacht hast.</font>

1271
01:03:23.240 --> 01:03:26.840
<font color="#008000">"Das Wandern ist der Gen Zs Lust".</font>

1272
01:03:26.920 --> 01:03:29.720
<font color="#008000">Ich habe das Wanderbedürfnis</font>
<font color="#008000">der jungen Generation untersucht</font>

1273
01:03:29.800 --> 01:03:33.560
<font color="#008000">und Vorschläge im Zürcher Oberland</font>
<font color="#008000">gemacht.</font>

1274
01:03:33.640 --> 01:03:37.840
<font color="#00ffff">Ist das Wanderbedürfnis der Gen Z</font>
<font color="#00ffff">grösser geworden?</font>

1275
01:03:37.920 --> 01:03:40.960
<font color="#008000">Es ist grösser</font>
<font color="#008000">als bei älteren Generationen</font>

1276
01:03:41.040 --> 01:03:45.720
<font color="#008000">und grundsätzlich der erfolgreichste</font>
<font color="#008000">Volkssport in der Schweiz.</font>

1277
01:03:45.800 --> 01:03:49.240
<font color="#00ffff">Das hat aber auch</font>
<font color="#00ffff">mit Social Media zu tun, oder?</font>

1278
01:03:49.320 --> 01:03:52.240
<font color="#00ffff">Weil dort so viel von den schönen</font>
<font color="#00ffff">Regionen gezeigt wird,</font>

1279
01:03:52.320 --> 01:03:54.480
<font color="#00ffff">wo man wandern kann.</font>

1280
01:03:54.560 --> 01:03:57.160
<font color="#008000">Das ist auch ein Ergebnis</font>
<font color="#008000">meiner Maturaarbeit.</font>

1281
01:03:57.280 --> 01:04:00.760
<font color="#008000">Eine der Hauptinformationsquellen</font>
<font color="#008000">ist Social Media,</font>

1282
01:04:00.840 --> 01:04:03.440
<font color="#008000">so erreicht man die Zielgruppe</font>
<font color="#008000">am besten.</font>

1283
01:04:03.520 --> 01:04:06.280
<font color="#00ffff">Ronny hat auch</font>
<font color="#00ffff">eine Maturaarbeit geschrieben,</font>

1284
01:04:06.360 --> 01:04:08.840
<font color="#00ffff">über das Verkehrskonzept</font>
<font color="#00ffff">der Stadt Wetzikon.</font>

1285
01:04:08.920 --> 01:04:11.240
<font color="#00ffff">Mit oder ohne KI?</font>

1286
01:04:11.320 --> 01:04:14.360
<font color="#008000">Ohne KI, natürlich.</font>
<font color="#00ffff">- Wieso natürlich?</font>

1287
01:04:14.440 --> 01:04:17.960
<font color="#008000">Weil meine Lehrperson</font>
<font color="#008000">eher konservativ gegenüber KI</font>

1288
01:04:18.040 --> 01:04:20.880
<font color="#008000">eingestellt war.</font>

1289
01:04:20.960 --> 01:04:23.480
<font color="#00ffff">War das eher mühsam oder okay?</font>

1290
01:04:23.600 --> 01:04:26.600
<font color="#008000">Grundsätzlich wäre ich der Meinung,</font>
<font color="#008000">hätte ich KI benutzt,</font>

1291
01:04:26.720 --> 01:04:29.360
<font color="#008000">hätte ich fast mehr Aufwand</font>
<font color="#008000">betreiben müssen,</font>

1292
01:04:29.440 --> 01:04:31.560
<font color="#008000">als wenn ich das</font>
<font color="#008000">selbst geschrieben hätte.</font>

1293
01:04:31.640 --> 01:04:34.280
<font color="#008000">Weil das eine</font>
<font color="#008000">so individuelle Arbeit ist.</font>

1294
01:04:34.400 --> 01:04:37.520
<font color="#008000">Bis ich alle Ideen</font>
<font color="#008000">entwickelt habe ...</font>

1295
01:04:37.600 --> 01:04:41.080
<font color="#008000">Ich müsste der KI alles erklären,</font>
<font color="#008000">was ich genau machen will.</font>

1296
01:04:41.160 --> 01:04:46.720
<font color="#008000">Das bräuchte mehr Aufwand, als die</font>
<font color="#008000">Arbeit einfach selbst zu schreiben.</font>

1297
01:04:46.800 --> 01:04:51.440
<font color="#00ffff">Der Lehrerdachverband</font>
<font color="#00ffff">hat öffentlich ausgesagt:</font>

1298
01:05:01.480 --> 01:05:04.320
<font color="#00ffff">Die Lehrer unterstellen euch,</font>
<font color="#00ffff">dass die Schüler wegen KI</font>

1299
01:05:04.400 --> 01:05:07.720
<font color="#00ffff">weniger selbst denken und auch</font>
<font color="#00ffff">weniger motiviert sein könnten,</font>

1300
01:05:07.840 --> 01:05:10.040
<font color="#00ffff">neue Dinge zu lernen.</font>

1301
01:05:10.160 --> 01:05:12.760
<font color="#00ffff">Wenn ich euch zuhöre, besteht</font>
<font color="#00ffff">diese Gefahr überhaupt nicht.</font>

1302
01:05:12.840 --> 01:05:15.760
<font color="#00ffff">Nun könnt ihr gegen die Lehrer</font>
<font color="#00ffff">und deren Meinungen wettern.</font>

1303
01:05:15.840 --> 01:05:18.520
<font color="#008000">Ich finde diese Kritik</font>
<font color="#00ffff">durchaus berechtigt.- Okay.</font>

1304
01:05:18.600 --> 01:05:21.160
<font color="#008000">Wenn Mitschüler weniger Aufwand</font>
<font color="#008000">für das gleiche Produkt betreiben</font>

1305
01:05:21.240 --> 01:05:23.360
<font color="#008000">und eine bessere Note kriegen,</font>

1306
01:05:23.480 --> 01:05:25.760
<font color="#008000">dann ist Eigenverantwortung</font>
<font color="#008000">gut und recht,</font>

1307
01:05:25.840 --> 01:05:28.080
<font color="#008000">aber es braucht auch</font>
<font color="#008000">gesetzliche Rahmenbedingungen.</font>

1308
01:05:28.160 --> 01:05:30.720
<font color="#008000">Gerade bei benoteten Arbeiten,</font>
<font color="#008000">bei Abschlussprüfungen</font>

1309
01:05:30.800 --> 01:05:34.000
<font color="#008000">muss transparent deklariert werden,</font>

1310
01:05:34.080 --> 01:05:36.920
<font color="#008000">wo man es benutzen darf</font>
<font color="#008000">und wo nicht.</font>

1311
01:05:37.000 --> 01:05:40.080
<font color="#008000">Wofür ist das gut</font>
<font color="#008000">und was kann es auch nicht?</font>

1312
01:05:40.200 --> 01:05:42.920
<font color="#00ffff">Ich bin fast versucht zu sagen,</font>
<font color="#00ffff">du sollst in diese Runde kommen,</font>

1313
01:05:43.000 --> 01:05:45.160
<font color="#00ffff">aber ich wüsste nicht,</font>
<font color="#00ffff">wen ich rausschicken soll.</font>

1314
01:05:45.240 --> 01:05:47.360
<font color="#00ffff">Unglaublich gut,</font>
<font color="#00ffff">wie ihr argumentiert</font>

1315
01:05:47.440 --> 01:05:49.600
<font color="#00ffff">und das auf den Punkt bringt.</font>

1316
01:05:49.720 --> 01:05:52.200
<font color="#00ffff">Ihr habt die Diskussion</font>
<font color="#00ffff">rund um die Regulierungen miterlebt.</font>

1317
01:05:52.320 --> 01:05:54.520
<font color="#00ffff">Wie siehst du das?</font>

1318
01:05:54.600 --> 01:05:57.200
<font color="#008000">Ich sehe durchaus Probleme</font>
<font color="#008000">bei der KI, v.a. moralischer Art.</font>

1319
01:05:57.280 --> 01:05:59.560
<font color="#008000">Und den Aspekt,</font>
<font color="#008000">dass es ein Monopol ist,</font>

1320
01:05:59.640 --> 01:06:02.360
<font color="#008000">das von grossen Techkonzernen</font>
<font color="#008000">kontrolliert wird,</font>

1321
01:06:02.440 --> 01:06:05.480
<font color="#008000">die v.a. aus den USA kommen.</font>

1322
01:06:05.560 --> 01:06:08.760
<font color="#008000">Es gibt grosse moralische Bedenken,</font>
<font color="#008000">v.a. im Umgang mit Quellen.</font>

1323
01:06:08.840 --> 01:06:11.920
<font color="#008000">Und was es alles braucht,</font>
<font color="#008000">um die KI zu trainieren -</font>

1324
01:06:12.040 --> 01:06:16.840
<font color="#008000">wie bereits gesagt wurde, sind das</font>
<font color="#008000">oft Materialien von Künstler/-innen</font>

1325
01:06:16.920 --> 01:06:20.240
<font color="#008000">und allem Möglichem,</font>
<font color="#008000">was man im Internet findet.</font>

1326
01:06:20.320 --> 01:06:24.000
<font color="#008000">Dass das von der KI irgendwie</font>
<font color="#008000">auf neue Art zusammen gemischt wird,</font>

1327
01:06:24.080 --> 01:06:27.840
<font color="#008000">muss stark hinterfragt werden.</font>

1328
01:06:27.920 --> 01:06:32.680
<font color="#008000">Wenn man mit KI arbeitet, muss man</font>
<font color="#008000">auf jeden Fall hinterfragen,</font>

1329
01:06:32.760 --> 01:06:42.600
<font color="#008000">was das Ergebnis ist</font>
<font color="#008000">und v.a. verstehen, was sie sagt.</font>

1330
01:06:42.680 --> 01:06:47.240
<font color="#00ffff">Das sagt Ronny Siegenthaler.</font>

1331
01:06:47.320 --> 01:06:49.760
<font color="#00ffff">Neben ihm ist Yuri Kaspar,</font>
<font color="#00ffff">vielen Dank.</font>

1332
01:06:49.880 --> 01:06:52.640
<font color="#00ffff">Monika Rühl,</font>
<font color="#00ffff">sind Sie auch so begeistert wie ich?</font>

1333
01:06:52.720 --> 01:06:55.560
Es kann nicht anders sein, ihr seid
von der Kantonsschule Wetzikon,

1334
01:06:55.640 --> 01:06:57.800
die habe ich auch besucht.

1335
01:06:57.920 --> 01:07:00.480
Super habt ihr das gemacht.

1336
01:07:00.560 --> 01:07:03.280
<font color="#00ffff">Er sagt also auch,</font>
<font color="#00ffff">da gibt es moralische Bedenken</font>

1337
01:07:03.360 --> 01:07:06.520
<font color="#00ffff">und man muss hinschauen.</font>

1338
01:07:06.600 --> 01:07:10.040
<font color="#00ffff">Man kann nicht einfach</font>
<font color="#00ffff">den Markt spielen lassen.</font>

1339
01:07:10.120 --> 01:07:13.760
Ich habe nicht gesagt,
dass man nicht hinschauen soll.

1340
01:07:13.840 --> 01:07:17.080
Ich finde das absolut berechtigt.

1341
01:07:17.160 --> 01:07:21.360
Es gibt Risiken, aber ich wollte
heute Abend die Chancen betonen,

1342
01:07:21.480 --> 01:07:25.080
denn wir sprechen immer nur
über die Risiken.

1343
01:07:25.160 --> 01:07:28.160
Man muss das genau anschauen,
da hast du absolut recht,

1344
01:07:28.240 --> 01:07:30.800
das sehe ich auch so.

1345
01:07:30.920 --> 01:07:34.840
Was Yuri gesagt hat,
hat mich natürlich total gefreut -

1346
01:07:34.920 --> 01:07:39.640
Eigenverantwortung, dass dieses Wort
auch heute noch in Mode ist,

1347
01:07:39.720 --> 01:07:42.520
das finde ich super.

1348
01:07:42.640 --> 01:07:45.160
<font color="#00ffff">Was sagt der Ethiker dazu?</font>

1349
01:07:45.240 --> 01:07:48.040
Fantastisch, ich würde gleich
meinen Platz übergeben,

1350
01:07:48.120 --> 01:07:50.680
man kann nicht besser argumentieren.

1351
01:07:50.760 --> 01:07:53.360
Ich bin begeistert
von der Art und Weise,

1352
01:07:53.440 --> 01:07:56.000
wie ihr eure Positionen vertretet,

1353
01:07:56.080 --> 01:07:58.280
aber auch inhaltlich
gibt es eine gewisse Nähe,

1354
01:07:58.400 --> 01:08:00.600
wenn ich das
ganz bescheiden sagen darf.

1355
01:08:00.680 --> 01:08:03.240
V.a. hat mich beeindruckt,
wie ihr das vertreten habt.

1356
01:08:03.360 --> 01:08:05.560
Ich bin nicht sicher,
ob ich Ihnen zustimme,

1357
01:08:05.640 --> 01:08:08.840
dass man immer nur
von Risiken spricht.

1358
01:08:08.920 --> 01:08:11.640
Fakt ist, dass es einen Markt gibt,
der einfach läuft,

1359
01:08:11.720 --> 01:08:14.400
wo nichts gemacht wird,
wo wir einfach zuschauen.

1360
01:08:14.480 --> 01:08:17.279
ChatGPT ist eigentlich
nichts anderes - apropos Wandern -,

1361
01:08:17.399 --> 01:08:19.920
als eine wiederkäuende Kuh.

1362
01:08:20.040 --> 01:08:23.399
Es frisst alles, was Menschen einst
geschaffen, gedacht, geschrieben

1363
01:08:23.479 --> 01:08:26.359
und formuliert haben,
spült es durch, spuckt es aus

1364
01:08:26.439 --> 01:08:29.800
und wir sind ganz begeistert.

1365
01:08:29.920 --> 01:08:32.760
Ich teile die Begeisterung in Bezug
auf grammatikalische Korrektheit,

1366
01:08:32.840 --> 01:08:35.760
ich teile die Begeisterung, dass die
Bedeutung einigermassen Sinn macht,

1367
01:08:35.840 --> 01:08:37.560
aber ich verstehe nicht,

1368
01:08:37.640 --> 01:08:40.319
dass wir nicht gleichzeitig
kritischer hinschauen können

1369
01:08:40.399 --> 01:08:42.720
und denken, wir können
etwas wie ChatGPT bauen

1370
01:08:42.800 --> 01:08:45.720
ohne Urheberrechts-, Datenschutz-
oder ohne Privatsphärenverletzungen.

1371
01:08:45.800 --> 01:08:47.840
Es muss doch möglich sein,

1372
01:08:47.920 --> 01:08:49.960
ein profitables Produkt
auf den Markt zu bringen,

1373
01:08:50.040 --> 01:08:52.080
das menschenrechtskonform ist.

1374
01:08:52.200 --> 01:08:54.439
<font color="#00ffff">Vielen Dank nochmals,</font>
<font color="#00ffff">Yuri und Ronny.</font>

1375
01:08:54.520 --> 01:08:56.880
<font color="#00ffff">Ein Spezialapplaus für euch.</font>

1376
01:09:02.080 --> 01:09:05.200
<font color="#00ffff">Pascal Kaufmann, wir haben gehört,</font>
<font color="#00ffff">das müsste doch möglich sein</font>

1377
01:09:05.279 --> 01:09:07.760
<font color="#00ffff">ohne Urheberrechtsverletzungen usw.</font>

1378
01:09:07.880 --> 01:09:10.920
<font color="#00ffff">Ist es das, was Ihnen mit SwissGPT</font>
<font color="#00ffff">etwas vorschwebt?</font>

1379
01:09:11.040 --> 01:09:13.640
Auf jeden Fall, ja.

1380
01:09:13.720 --> 01:09:16.399
Man kann die Technologien so bauen,
dass sie legal sind,

1381
01:09:16.520 --> 01:09:19.120
dass darin unsere Werte
reflektiert werden

1382
01:09:19.200 --> 01:09:22.200
und dass sie für die Welt
kompatibel werden.

1383
01:09:22.279 --> 01:09:26.240
Unbedingt sollten wir
ein solches Werkzeug bauen, ja.

1384
01:09:26.359 --> 01:09:32.319
<font color="#00ffff">Marcel Salathé, Co-Chef des KI-</font>
<font color="#00ffff">Zentrums an der EPFL in Lausanne.</font>

1385
01:09:32.399 --> 01:09:35.960
<font color="#00ffff">Zurück zu den Jugendlichen.</font>

1386
01:09:36.080 --> 01:09:38.960
<font color="#00ffff">Mit der Einführung des Lehrplans 21</font>

1387
01:09:39.080 --> 01:09:42.279
<font color="#00ffff">ist das Thema in den Schulen</font>
<font color="#00ffff">sehr viel präsenter als vorher.</font>

1388
01:09:42.399 --> 01:09:44.720
<font color="#00ffff">Medien und Informatik gehören heute</font>

1389
01:09:44.800 --> 01:09:47.520
<font color="#00ffff">zum verbindlichen Inhalt</font>
<font color="#00ffff">auf allen Volksschulstufen.</font>

1390
01:09:47.600 --> 01:09:50.240
<font color="#00ffff">Heisst das aus Ihrer Sicht,</font>
<font color="#00ffff">man macht genug,</font>

1391
01:09:50.319 --> 01:09:55.680
<font color="#00ffff">oder könnte man noch mehr tun,</font>
<font color="#00ffff">wenn es um KI-Kompetenz geht?</font>

1392
01:09:55.760 --> 01:09:58.680
<font color="#008000">Ich denke,</font>
<font color="#008000">man kann noch einiges mehr tun.</font>

1393
01:09:58.760 --> 01:10:01.480
<font color="#008000">Das höre ich auch in Diskussionen.</font>

1394
01:10:01.560 --> 01:10:04.200
<font color="#008000">Es gibt immer noch viele Missstände,</font>
<font color="#008000">was KI ist.</font>

1395
01:10:04.320 --> 01:10:06.440
<font color="#008000">Wir hören immer wieder von Apps,</font>

1396
01:10:06.520 --> 01:10:08.680
<font color="#008000">die überhaupt nichts</font>
<font color="#008000">mit KI zu tun haben.</font>

1397
01:10:08.760 --> 01:10:11.160
<font color="#008000">Wenn illegale Apps</font>
<font color="#008000">auf den Markt kommen,</font>

1398
01:10:11.240 --> 01:10:13.320
<font color="#008000">ist das ein Problem</font>
<font color="#008000">des Marktplatzes,</font>

1399
01:10:13.440 --> 01:10:15.640
<font color="#008000">nicht von der Technologie selbst.</font>

1400
01:10:15.720 --> 01:10:17.760
<font color="#008000">Ich denke, wir finden</font>
<font color="#008000">aktuell heraus, wie das geht,</font>

1401
01:10:17.840 --> 01:10:19.920
<font color="#008000">auch an den Hochschulen.</font>

1402
01:10:20.000 --> 01:10:22.280
<font color="#008000">In einer aktuellen Studie</font>
<font color="#008000">haben wir gefragt:</font>

1403
01:10:22.360 --> 01:10:24.960
<font color="#008000">Wenn jemand ein EPFL-Studium</font>
<font color="#008000">nur mit ChatGPT absolvieren würde,</font>

1404
01:10:25.040 --> 01:10:28.480
<font color="#008000">wie viele Prüfungen</font>
<font color="#008000">würde er bestehen?</font>

1405
01:10:28.560 --> 01:10:30.960
<font color="#008000">Das Resultat sind über 60 %,</font>

1406
01:10:31.040 --> 01:10:33.520
<font color="#008000">die einen genügenden Notenschnitt</font>
<font color="#008000">hätten.</font>

1407
01:10:33.600 --> 01:10:38.000
<font color="#008000">Die Idee, dass aus ChatGPT keine</font>
<font color="#008000">Wahrheit kommt, ist etwas amüsant.</font>

1408
01:10:38.080 --> 01:10:43.640
<font color="#008000">Natürlich wurden diese Systeme</font>
<font color="#008000">von Daten abgehend trainiert,</font>

1409
01:10:43.720 --> 01:10:46.480
<font color="#008000">nicht Daten sozialer Medien,</font>

1410
01:10:46.560 --> 01:10:49.760
<font color="#008000">sondern auch auf Daten</font>
<font color="#008000">wissenschaftlicher Arbeiten.</font>

1411
01:10:49.840 --> 01:10:52.160
<font color="#008000">Das wurde dann finetuned,</font>

1412
01:10:52.280 --> 01:10:54.320
<font color="#008000">damit es dann einigermassen</font>
<font color="#008000">wahrheitsgetreu ist.</font>

1413
01:10:54.400 --> 01:10:56.880
<font color="#008000">Das sehen wir nun immer mehr.</font>

1414
01:10:56.960 --> 01:10:59.120
<font color="#008000">Es ist nicht nur bei ChatGPT so.</font>

1415
01:10:59.240 --> 01:11:02.600
<font color="#008000">Erinnern wir uns an Tools, wo uns KI</font>
<font color="#008000">mit medizinischen Diagnosen hilft.</font>

1416
01:11:02.680 --> 01:11:05.760
<font color="#008000">Da wissen wir heute schon,</font>
<font color="#008000">dass das besser funktioniert</font>

1417
01:11:05.840 --> 01:11:08.200
<font color="#008000">als mit vielen Ärzten.</font>

1418
01:11:08.280 --> 01:11:11.480
<font color="#008000">Wenn es darum geht, Proteinfaltungen</font>
<font color="#008000">für neue Medikamente zu finden,</font>

1419
01:11:11.560 --> 01:11:14.840
<font color="#008000">dann geht das viel besser, als wenn</font>
<font color="#008000">man das von Hand machen wollte.</font>

1420
01:11:14.920 --> 01:11:17.800
<font color="#008000">Das ist alles objektiv korrekt.</font>

1421
01:11:17.880 --> 01:11:20.440
<font color="#008000">Ich glaube,</font>
<font color="#008000">hier muss man noch schneller</font>

1422
01:11:20.520 --> 01:11:23.040
<font color="#008000">auf die Jugendlichen zugehen</font>

1423
01:11:23.120 --> 01:11:26.160
<font color="#008000">und richtigen kritischen Optimismus</font>
<font color="#008000">vertreten.</font>

1424
01:11:26.240 --> 01:11:29.920
<font color="#008000">Aber man soll es auch annehmen.</font>

1425
01:11:30.000 --> 01:11:33.680
<font color="#008000">Am Ende will man ja die Tools auf</font>
<font color="#008000">einem globalen Werkplatz nutzen,</font>

1426
01:11:33.760 --> 01:11:38.120
<font color="#008000">sonst sind die anderen</font>
<font color="#008000">immer zwei Schritte voraus.</font>

1427
01:11:38.200 --> 01:11:42.120
<font color="#00ffff">Wir gehen mit kritischem Optimismus</font>
<font color="#00ffff">in die Schlussrunde dieser Sendung.</font>

1428
01:11:42.240 --> 01:11:44.560
<font color="#00ffff">D.h., wir haben noch etwa 5 Min.</font>

1429
01:11:44.680 --> 01:11:47.480
<font color="#00ffff">Ich möchte in der Hauptrunde</font>
<font color="#00ffff">etwas abholen.</font>

1430
01:11:47.560 --> 01:11:50.840
<font color="#00ffff">Wir haben uns bemüht, nicht nur</font>
<font color="#00ffff">Schwarz und Weiss zu malen,</font>

1431
01:11:50.920 --> 01:11:55.800
<font color="#00ffff">sondern die Möglichkeiten</font>
<font color="#00ffff">auf den Tisch zu legen.</font>

1432
01:11:55.880 --> 01:11:58.240
<font color="#00ffff">Gleichzeitig gibt es jemanden,</font>

1433
01:11:58.320 --> 01:12:00.920
<font color="#00ffff">der im Moment eine wahnsinnige</font>
<font color="#00ffff">Präsenz hat in den Medien.</font>

1434
01:12:01.000 --> 01:12:03.240
<font color="#00ffff">Ein Historiker, Lehrer</font>
<font color="#00ffff">und Bestsellerautor,</font>

1435
01:12:03.320 --> 01:12:06.120
<font color="#00ffff">der Bücher über die Gefahr</font>
<font color="#00ffff">im Zusammenhang mit KI</font>

1436
01:12:06.200 --> 01:12:09.920
<font color="#00ffff">aus seiner Sicht geschrieben hat.</font>

1437
01:12:10.000 --> 01:12:13.800
<font color="#00ffff">Das ist der Einspieler</font>
<font color="#00ffff">zu Yuval Noah Harari:</font>

1438
01:12:13.880 --> 01:12:17.280
<font color="#008000">Dies ist</font>
<font color="#008000">das Ende der Menschheitsgeschichte.</font>

1439
01:12:17.360 --> 01:12:19.920
<font color="#008000">Nicht das Ende der Geschichte,</font>

1440
01:12:20.000 --> 01:12:22.560
<font color="#008000">sondern das Ende der</font>
<font color="#008000">von Menschen dominierten Geschichte.</font>

1441
01:12:22.640 --> 01:12:24.640
<font color="#008000">Die Geschichte wird weitergehen,</font>

1442
01:12:24.760 --> 01:12:27.640
<font color="#008000">aber kontrolliert</font>
<font color="#008000">von jemand anderem.</font>

1443
01:12:27.720 --> 01:12:29.760
<font color="#00ffff">Das wäre das Horrorszenario.</font>

1444
01:12:29.840 --> 01:12:31.920
<font color="#00ffff">Monika Rühl, machen Sie sich Sorgen,</font>

1445
01:12:32.000 --> 01:12:34.120
<font color="#00ffff">dass uns KI irgendwann</font>
<font color="#00ffff">dominieren wird?</font>

1446
01:12:34.200 --> 01:12:36.320
Nein, absolut nicht.

1447
01:12:36.440 --> 01:12:39.800
Ich bin überzeugt, dass der Mensch
weiterhin Taktgeber sein wird

1448
01:12:39.880 --> 01:12:44.280
und eine Zusammenarbeit
mit der von ihm gesteuerten Maschine

1449
01:12:44.360 --> 01:12:46.560
haben wird.

1450
01:12:46.640 --> 01:12:48.840
<font color="#00ffff">Peter G. Kirchschläger,</font>
<font color="#00ffff">macht sich der Mensch</font>

1451
01:12:48.920 --> 01:12:51.880
<font color="#00ffff">mit künstlicher Intelligenz</font>
<font color="#00ffff">selber überflüssig?</font>

1452
01:12:51.960 --> 01:12:54.440
Zumindest wäre es sogar sinnvoll,

1453
01:12:54.560 --> 01:12:57.680
dass wir gewisse Aufgaben, wo uns
die Maschine massiv überlegen ist,

1454
01:12:57.760 --> 01:13:02.520
auch der Maschine anvertrauen.

1455
01:13:02.600 --> 01:13:04.800
Nur müssen wir genau hinschauen.

1456
01:13:04.880 --> 01:13:07.280
Vorher wurde gesagt,
eine App habe nichts mit KI zu tun.

1457
01:13:07.400 --> 01:13:10.120
Wenn die App mit KI gebaut ist, hat
sie sehr wohl etwas damit zu tun.

1458
01:13:10.240 --> 01:13:12.240
Wenn Social Media
mit KI gesteuert wird

1459
01:13:12.320 --> 01:13:14.760
und gewisse Dinge
bei Jugendlichen anrichtet,

1460
01:13:14.840 --> 01:13:17.240
hat das sehr wohl mit KI zu tun.
Das müssen wir adressieren.

1461
01:13:17.360 --> 01:13:19.400
Mir geht es darum,
dass wir präziser hinschauen,

1462
01:13:19.480 --> 01:13:22.000
genau hinschauen, was die ethischen
Chancen und Risiken sind.

1463
01:13:22.080 --> 01:13:24.240
Wenn wir das nicht tun,
besteht die Gefahr,

1464
01:13:24.320 --> 01:13:26.760
dass wir mit den Systemen,
die selbst auch dümmer werden,

1465
01:13:26.840 --> 01:13:29.040
weil wir sie
mit den eigenen Daten trainieren

1466
01:13:29.120 --> 01:13:31.600
und nicht zwischen
wissenschaftlichen Studien

1467
01:13:31.680 --> 01:13:34.920
und Neonaziblättern unterscheiden -
die werden genau gleich behandelt.

1468
01:13:35.000 --> 01:13:37.280
Dann ist die Gefahr gross,

1469
01:13:37.360 --> 01:13:39.800
dass wir selbst als Menschheit
leider auch dümmer werden.

1470
01:13:39.880 --> 01:13:42.640
<font color="#00ffff">Pascal Kaufmann, KI-Unternehmer,</font>
<font color="#00ffff">auch Pionier in diesem Bereich.</font>

1471
01:13:42.720 --> 01:13:45.880
<font color="#00ffff">Was sagen Sie zu solchen Ängsten?</font>

1472
01:13:46.000 --> 01:13:49.480
Ich habe null Angst
vor künstlicher Intelligenz.

1473
01:13:49.560 --> 01:13:52.320
Für mich ist künstliche Intelligenz
wie eine Schaufel.

1474
01:13:52.400 --> 01:13:55.200
Entweder kann man ein Loch
mit nackter Menschenhand

1475
01:13:55.280 --> 01:13:57.520
selber graben
oder man nimmt eine Schaufel.

1476
01:13:57.600 --> 01:13:59.800
Ich behaupte,
es ist immer das gleiche Loch,

1477
01:13:59.880 --> 01:14:02.000
eines, das man selbst gemacht hat.

1478
01:14:02.120 --> 01:14:04.560
Genau so ist es mit einem
ChatGPT- oder SwissGPT-Text.

1479
01:14:04.680 --> 01:14:07.600
Ob ich den Text
mit meinen nackten Fingern schreibe,

1480
01:14:07.720 --> 01:14:10.560
oder ob ich Befehle diktiere und
der Text genau so generiert wird,

1481
01:14:10.680 --> 01:14:12.840
nach meinen Wünschen ...

1482
01:14:12.920 --> 01:14:16.360
Ich finde,
das sollte man unbedingt einsetzen.

1483
01:14:16.440 --> 01:14:18.800
Ich finde, es ist eine Schaufel.

1484
01:14:18.920 --> 01:14:22.280
Würde man einem Taschenrechner
Selbsterhaltungstrieb einbauen

1485
01:14:22.360 --> 01:14:26.520
oder Machtfantasien, dann hätte ich
auch vor einem Taschenrechner Angst.

1486
01:14:26.600 --> 01:14:28.960
Wir bauen keine Werkzeuge,

1487
01:14:29.040 --> 01:14:31.520
die Selbsterhaltungs-
oder Überlebenstriebe haben.

1488
01:14:31.600 --> 01:14:34.240
Das ist Angstmacherei
von Yuval Harari

1489
01:14:34.320 --> 01:14:36.520
und ich halte nichts davon.

1490
01:14:36.600 --> 01:14:39.240
<font color="#00ffff">Mirjam Hostetmann, nehmen Sie</font>
<font color="#00ffff">doch die Schaufel in die Hand</font>

1491
01:14:39.320 --> 01:14:41.640
<font color="#00ffff">und graben Sie mit.</font>

1492
01:14:41.720 --> 01:14:44.720
<font color="#00ffff">Oder möchten Sie lieber das Reich</font>
<font color="#00ffff">der Finsternis mit propagieren?</font>

1493
01:14:44.800 --> 01:14:47.720
Nein, ich glaube gar nicht,
dass KI das Ende der Menschheit ist.

1494
01:14:47.800 --> 01:14:50.960
Ich sehe KI als Instrument,
als Werkzeug,

1495
01:14:51.040 --> 01:14:53.640
das von den Menschen
genutzt werden soll.

1496
01:14:53.720 --> 01:14:56.760
Es muss aber von der gesamten
Gesellschaft genutzt werden,

1497
01:14:56.840 --> 01:14:59.120
nicht nur von den Mächtigen.

1498
01:14:59.200 --> 01:15:02.240
Denn dann sehe ich Risiken,
sonst sehe ich viele Chancen.

1499
01:15:02.320 --> 01:15:04.720
<font color="#00ffff">Die Stimme der Ausgewogenheit</font>
<font color="#00ffff">am Schluss:</font>

1500
01:15:04.840 --> 01:15:06.880
<font color="#00ffff">Marcel Salathé,</font>
<font color="#00ffff">wie gross ist die Gefahr,</font>

1501
01:15:06.960 --> 01:15:09.320
<font color="#00ffff">dass wir die Kontrolle</font>
<font color="#00ffff">über Maschine verlieren?</font>

1502
01:15:09.400 --> 01:15:12.760
<font color="#008000">Das ist sehr schwer vorauszusagen.</font>
<font color="#008000">Denn wir hatten es noch nie.</font>

1503
01:15:12.840 --> 01:15:16.120
<font color="#008000">Es ist aber die Urangst,</font>
<font color="#008000">da gehe ich mit Ihnen einig.</font>

1504
01:15:16.200 --> 01:15:19.960
<font color="#008000">Es ist sicher etwas, wo wir</font>
<font color="#008000">den Finger drauf halten müssen.</font>

1505
01:15:20.040 --> 01:15:23.200
<font color="#008000">Ich möchte doch noch</font>
<font color="#008000">eine Gegenfrage stellen, Herr Brotz.</font>

1506
01:15:23.320 --> 01:15:25.840
<font color="#00ffff">Mir? Jetzt wird es interessant.</font>

1507
01:15:25.920 --> 01:15:28.960
<font color="#008000">Hätten Sie Harari gezeigt,</font>
<font color="#008000">wenn er gesagt hätte,</font>

1508
01:15:29.080 --> 01:15:32.120
<font color="#008000">die KI sei eine balancierte Sache</font>
<font color="#008000">mit Chancen und Risiken,</font>

1509
01:15:32.200 --> 01:15:35.280
<font color="#008000">die beide betrachtet werden müssen?</font>

1510
01:15:35.360 --> 01:15:38.160
<font color="#00ffff">Nein,</font>
<font color="#00ffff">er hat mir eine Frage gestellt.</font>

1511
01:15:38.280 --> 01:15:41.160
<font color="#00ffff">Ich bin der, der behauptet,</font>
<font color="#00ffff">er stelle jeweils kritische Fragen,</font>

1512
01:15:41.280 --> 01:15:44.880
<font color="#00ffff">dann muss er auch eine kritische</font>
<font color="#00ffff">Frage beantworten müssen.</font>

1513
01:15:44.960 --> 01:15:47.800
<font color="#00ffff">Tendenziell weniger, ganz ehrlich.</font>

1514
01:15:47.880 --> 01:15:51.120
<font color="#00ffff">Weil es die interessantere Aus-</font>
<font color="#00ffff">gangslage für eine Diskussion ist.</font>

1515
01:15:51.200 --> 01:15:52.800
<font color="#008000">Genau.</font>

1516
01:15:52.880 --> 01:15:56.520
<font color="#00ffff">Okay?</font>
<font color="#008000">- Okay.</font>

1517
01:15:56.640 --> 01:15:59.040
Ich finde einfach,
wir müssen aufpassen,

1518
01:15:59.120 --> 01:16:02.400
nicht zu sagen, dass es ethische
Chancen und Risiken gibt,

1519
01:16:02.480 --> 01:16:04.960
die sich abwägen.
Dann machen wir einen Denkfehler.

1520
01:16:05.080 --> 01:16:07.720
Es gibt auch ethische Risiken,
die wir wirklich vermeiden müssen.

1521
01:16:07.800 --> 01:16:09.880
Wenn Menschen- oder Kinderrechte
verletzt werden,

1522
01:16:09.960 --> 01:16:12.520
kann man das nicht aufwägen.

1523
01:16:12.600 --> 01:16:17.280
Sie haben das so formuliert,
man lasse sich sagen,

1524
01:16:17.400 --> 01:16:20.400
wie ich denken soll etc.
So wird das Denken vorgespurt.

1525
01:16:20.520 --> 01:16:23.200
Ich würde dazu einladen,
selbst zu denken.

1526
01:16:23.280 --> 01:16:27.200
<font color="#00ffff">Und ich lade dazu ein, die weiteren</font>
<font color="#00ffff">Sendungen in Zusammenhang mit KI</font>

1527
01:16:27.320 --> 01:16:30.760
<font color="#00ffff">im Rahmen der SRF-Themenwoche</font>
<font color="#00ffff">zu konsultieren.</font>

1528
01:16:30.840 --> 01:16:38.880
<font color="#00ffff">Das sind spannende Dinge,</font>
<font color="#00ffff">die man alle unter srf.ch/KI findet.</font>

1529
01:16:38.960 --> 01:16:41.480
<font color="#00ffff">Ich weiss, ich nehme etwas vorweg.</font>

1530
01:16:41.560 --> 01:16:44.000
<font color="#00ffff">Wir haben mit der Regie geplant,</font>
<font color="#00ffff">das nachher zu machen.</font>

1531
01:16:44.080 --> 01:16:46.280
<font color="#00ffff">Aber wenn wir schon davon sprechen,</font>

1532
01:16:46.360 --> 01:16:50.040
<font color="#00ffff">zeigen wir's jetzt und hoffen,</font>
<font color="#00ffff">dass man den Einblender auch sieht.</font>

1533
01:16:50.120 --> 01:16:53.480
<font color="#00ffff">Das war eine lebhafte Debatte</font>
<font color="#00ffff">zu Chancen und Risiken</font>

1534
01:16:53.560 --> 01:16:55.800
<font color="#00ffff">künstlicher Intelligenz,</font>

1535
01:16:55.880 --> 01:17:00.080
<font color="#00ffff">produziert von Lisa Känzig,</font>
<font color="#00ffff">die Leitung hat Franziska Egli.</font>

1536
01:17:00.160 --> 01:17:04.080
<font color="#00ffff">Die Zusammenfassung gibt es</font>
<font color="#00ffff">schon bald in der SRF News App -</font>

1537
01:17:04.160 --> 01:17:08.360
<font color="#00ffff">ohne Einsatz von KI - noch.</font>
<font color="#00ffff">Und auf srf.ch.</font>

1538
01:17:08.480 --> 01:17:11.520
<font color="#00ffff">Den Blick hinter die Kulissen</font>
<font color="#00ffff">gibt es bei mir auf Instagram.</font>

1539
01:17:11.640 --> 01:17:13.720
<font color="#00ffff">Nächste Woche</font>
<font color="#00ffff">begrüsst Sie an dieser Stelle</font>

1540
01:17:13.800 --> 01:17:15.920
<font color="#00ffff">mein Kollege Mario Grossniklaus.</font>

1541
01:17:16.000 --> 01:17:19.040
<font color="#00ffff">Gute Nacht aus dem Studio 8.</font>

1542
01:17:19.120 --> 01:17:23.960
<font color="#ffffff">SWISS TXT / Accessibility Services</font>
<font color="#ffffff">Julia Böhm, Regina Kolb,</font>

